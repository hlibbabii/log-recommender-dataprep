{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataprep.api.corpus as api\n",
    "from vocabstudy.common import PrepFunction, calc_and_display_stats\n",
    "C_KEYWORDS = [\"auto\", \"double\", \"int\", \"struct\", \"break\", \"else\", \"long\", \n",
    "            \"switch\", \"case\", \"enum\", \"register\", \"typedef\", \"char\", \n",
    "            \"extern\", \"return\", \"union\", \"continue\", \"for\", \"signed\", \n",
    "            \"void\", \"do\", \"if\", \"static\", \"while\", \"default\", \"goto\", \n",
    "            \"sizeof\", \"volatile\", \"const\", \"float\", \"short\", \"unsigned\"]\n",
    "\n",
    "C_DATASETS = ('rafael/c-minus-test',\n",
    "            'rafael/c-test'\n",
    "           )\n",
    "\n",
    "def run(prep_function: PrepFunction, description: str) -> None:\n",
    "    calc_and_display_stats(prep_function, description, C_DATASETS, C_KEYWORDS, 'c')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.0.0-alpha.8'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dataprep\n",
    "\n",
    "dataprep.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l31.vsc3plus.xcat\r\n"
     ]
    }
   ],
   "source": [
    "!hostname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unsplit, with comments and vocabulary. No filtering.\n",
      "\n",
      "2019-08-17 12:28:34,666 [dataprep.infrastructure.stages] INFO: Checking first if vocabulary file exists: /home/lv71161/hlibbabii/.config/dataprep/1.0.0-alpha.8/vocab/c-minus-test_19-08-16T14-29-19_c_-_uc10su/vocab\n",
      "2019-08-17 12:28:34,668 [dataprep.infrastructure.stages] INFO: Vocabulary is already computed and up-to-date\n",
      "2019-08-17 12:28:34,669 [dataprep.api.corpus] INFO: Preprocessed dataset is ready at /tmp/scratch/prep-datasets/c-minus-test_19-08-16T14-29-19_c_-_uc10su_-_prep\n",
      "2019-08-17 12:29:09,301 [dataprep.infrastructure.stages] INFO: Checking first if vocabulary file exists: /home/lv71161/hlibbabii/.config/dataprep/1.0.0-alpha.8/vocab/c-test_13-07-12T06-20-12_c_-_uc10su/vocab\n",
      "2019-08-17 12:29:09,304 [dataprep.infrastructure.stages] INFO: Vocabulary is already computed and up-to-date\n",
      "2019-08-17 12:29:09,305 [dataprep.api.corpus] INFO: Preprocessed dataset is ready at /tmp/scratch/prep-datasets/c-test_13-07-12T06-20-12_c_-_uc10su_-_prep\n",
      "2019-08-17 12:29:10,159 [vocabstudy.common] DEBUG: Checking if train dataset exists: /tmp/scratch/prep-datasets/c-minus-test_19-08-16T14-29-19_c_-_uc10su_-_prep\n",
      "2019-08-17 12:29:10,160 [vocabstudy.common] INFO: Train dataset is found and is going to be removed to save space: /tmp/scratch/prep-datasets/c-minus-test_19-08-16T14-29-19_c_-_uc10su_-_prep. Removing ...\n",
      "2019-08-17 12:29:10,161 [vocabstudy.common] INFO: Moving test dataset from tmp storage: /tmp/scratch/prep-datasets/c-test_13-07-12T06-20-12_c_-_uc10su_-_prep -> /home/lv71161/hlibbabii/prep-datasets\n",
      "2019-08-17 12:29:10,162 [vocabstudy.common] WARNING: Not moving. Path already exists: /home/lv71161/hlibbabii/prep-datasets/c-test_13-07-12T06-20-12_c_-_uc10su_-_prep\n",
      "\n",
      "========================   Split example   =========================\n",
      "\n",
      "['void', 'test_WordUeberraschungPrinter', '(', ')', '{', '\\n', '\\t', 'if', '(', 'eps', '>', '=', '0.345e+4', ')', '{', '/', '/', 'FIXME', '10l', '\\n', '<EOL>', '\\t', '\\t', 'printWord', '(', '\"', '.', '.', '.', 'Ãœberraschung', '0x12', '\"', ')', ';', '\\n', '\\t', '}', '\\n', '}']\n",
      "\n",
      "========================   Stats           =========================\n",
      "\n",
      "Train vocab: 13221586\n",
      "Test vocab : 336644, identifiers: 231731 (0.69%)\n",
      "\n",
      "Train corpus size: 3737950475\n",
      "Test corpus size : 39259258, identifiers: 9493899 (0.24%)\n",
      "\n",
      "OOV in test set (top 9223372036854775807): 59586 (17.70%), oov tokens number: 548276 (1.40%)\n",
      "OOV in test set (top 200000): 278122 (82.62%), oov tokens number: 1821403 (4.64%)\n",
      "OOV in test set (top 100000): 295646 (87.82%), oov tokens number: 2180057 (5.55%)\n",
      "OOV in test set (top 75000): 302015 (89.71%), oov tokens number: 2330818 (5.94%)\n",
      "OOV in test set (top 50000): 309641 (91.98%), oov tokens number: 2537213 (6.46%)\n",
      "OOV in test set (top 25000): 319822 (95.00%), oov tokens number: 3026778 (7.71%)\n",
      "\n",
      "For identifiers: \n",
      "\n",
      "OOV in test set (top 9223372036854775807): 55224 (23.83%), oov tokens number: 533950 (5.62%)\n",
      "OOV in test set (top 200000): 180920 (78.07%), oov tokens number: 1637591 (17.25%)\n",
      "OOV in test set (top 100000): 195085 (84.19%), oov tokens number: 1959938 (20.64%)\n",
      "OOV in test set (top 75000): 200626 (86.58%), oov tokens number: 2088095 (21.99%)\n",
      "OOV in test set (top 50000): 207474 (89.53%), oov tokens number: 2255823 (23.76%)\n",
      "OOV in test set (top 25000): 216604 (93.47%), oov tokens number: 2644015 (27.85%)\n",
      "[2829359, 7055001, 2837641, 443369, 56216]\n"
     ]
    }
   ],
   "source": [
    "prep_function = PrepFunction(api.nosplit)\n",
    "description = \"unsplit, with comments and vocabulary. No filtering.\"\n",
    "\n",
    "run(prep_function, description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering  strings (+ comments, + whitespace, + non-ascii)\n",
      "\n",
      "2019-08-17 12:30:24,634 [dataprep.infrastructure.stages] INFO: Checking first if vocabulary file exists: /home/lv71161/hlibbabii/.config/dataprep/1.0.0-alpha.8/vocab/c-minus-test_19-08-16T14-29-19_c_-_U0000u/vocab\n",
      "2019-08-17 12:30:24,650 [dataprep.infrastructure.stages] INFO: Vocabulary is already computed and up-to-date\n",
      "2019-08-17 12:30:24,651 [dataprep.api.corpus] INFO: Preprocessed dataset is ready at /tmp/scratch/prep-datasets/c-minus-test_19-08-16T14-29-19_c_-_U0000u_-_prep\n",
      "2019-08-17 12:30:52,648 [dataprep.infrastructure.stages] INFO: Checking first if vocabulary file exists: /home/lv71161/hlibbabii/.config/dataprep/1.0.0-alpha.8/vocab/c-test_13-07-12T06-20-12_c_-_U0000u/vocab\n",
      "2019-08-17 12:30:52,659 [dataprep.infrastructure.stages] INFO: Vocabulary is already computed and up-to-date\n",
      "2019-08-17 12:30:52,660 [dataprep.api.corpus] INFO: Preprocessed dataset is ready at /tmp/scratch/prep-datasets/c-test_13-07-12T06-20-12_c_-_U0000u_-_prep\n",
      "2019-08-17 12:30:53,406 [vocabstudy.common] DEBUG: Checking if train dataset exists: /tmp/scratch/prep-datasets/c-minus-test_19-08-16T14-29-19_c_-_U0000u_-_prep\n",
      "2019-08-17 12:30:53,408 [vocabstudy.common] INFO: Train dataset is found and is going to be removed to save space: /tmp/scratch/prep-datasets/c-minus-test_19-08-16T14-29-19_c_-_U0000u_-_prep. Removing ...\n",
      "2019-08-17 12:30:53,410 [vocabstudy.common] INFO: Moving test dataset from tmp storage: /tmp/scratch/prep-datasets/c-test_13-07-12T06-20-12_c_-_U0000u_-_prep -> /home/lv71161/hlibbabii/prep-datasets\n",
      "2019-08-17 12:30:53,438 [vocabstudy.common] WARNING: Not moving. Path already exists: /home/lv71161/hlibbabii/prep-datasets/c-test_13-07-12T06-20-12_c_-_U0000u_-_prep\n",
      "\n",
      "========================   Split example   =========================\n",
      "\n",
      "['void', 'test_WordUeberraschungPrinter', '(', ')', '{', 'if', '(', 'eps', '>', '=', '0.345e+4', ')', '{', '<comment>', 'printWord', '(', '<str-literal>', ')', ';', '}', '}']\n",
      "\n",
      "========================   Stats           =========================\n",
      "\n",
      "Train vocab: 10876491\n",
      "Test vocab : 276302, identifiers: 176153 (0.64%)\n",
      "\n",
      "Train corpus size: 2091010818\n",
      "Test corpus size : 22804343, identifiers: 5477086 (0.24%)\n",
      "\n",
      "OOV in test set (top 9223372036854775807): 51809 (18.75%), oov tokens number: 422517 (1.85%)\n",
      "OOV in test set (top 200000): 235064 (85.08%), oov tokens number: 1437814 (6.31%)\n",
      "OOV in test set (top 100000): 247448 (89.56%), oov tokens number: 1636705 (7.18%)\n",
      "OOV in test set (top 75000): 251711 (91.10%), oov tokens number: 1745437 (7.65%)\n",
      "OOV in test set (top 50000): 257049 (93.03%), oov tokens number: 1890959 (8.29%)\n",
      "OOV in test set (top 25000): 264041 (95.56%), oov tokens number: 2232171 (9.79%)\n",
      "\n",
      "For identifiers: \n",
      "\n",
      "OOV in test set (top 9223372036854775807): 47769 (27.12%), oov tokens number: 408949 (7.47%)\n",
      "OOV in test set (top 200000): 142103 (80.67%), oov tokens number: 1285564 (23.47%)\n",
      "OOV in test set (top 100000): 151290 (85.89%), oov tokens number: 1471855 (26.87%)\n",
      "OOV in test set (top 75000): 154932 (87.95%), oov tokens number: 1573297 (28.73%)\n",
      "OOV in test set (top 50000): 159515 (90.55%), oov tokens number: 1706459 (31.16%)\n",
      "OOV in test set (top 25000): 165623 (94.02%), oov tokens number: 2021676 (36.91%)\n",
      "[1930629, 6146379, 2389714, 369351, 40418]\n"
     ]
    }
   ],
   "source": [
    "prep_function = PrepFunction(api.nosplit, [], {\"no_unicode\": True, \"no_spaces\": True, \"no_com\": True, \"no_str\": True})\n",
    "description = \"Filtering  strings (+ comments, + whitespace, + non-ascii)\"\n",
    "\n",
    "run(prep_function, description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An additional choice, the model from Hellendoorn and Devanbu: keep strings shorter than 15 char (check SLP-core code), remove others, remove comments\n",
      "\n",
      "2019-08-17 12:31:28,854 [dataprep.infrastructure.stages] INFO: Checking first if vocabulary file exists: /home/lv71161/hlibbabii/.config/dataprep/1.0.0-alpha.8/vocab/c-minus-test_19-08-16T14-29-19_c_-_u0EFsu/vocab\n",
      "2019-08-17 12:31:28,863 [dataprep.infrastructure.stages] INFO: Vocabulary is already computed and up-to-date\n",
      "2019-08-17 12:31:28,864 [dataprep.api.corpus] INFO: Preprocessed dataset is ready at /tmp/scratch/prep-datasets/c-minus-test_19-08-16T14-29-19_c_-_u0EFsu_-_prep\n",
      "2019-08-17 12:32:00,566 [dataprep.infrastructure.stages] INFO: Checking first if vocabulary file exists: /home/lv71161/hlibbabii/.config/dataprep/1.0.0-alpha.8/vocab/c-test_13-07-12T06-20-12_c_-_u0EFsu/vocab\n",
      "2019-08-17 12:32:00,612 [dataprep.infrastructure.stages] INFO: Vocabulary is already computed and up-to-date\n",
      "2019-08-17 12:32:00,613 [dataprep.api.corpus] INFO: Preprocessed dataset is ready at /tmp/scratch/prep-datasets/c-test_13-07-12T06-20-12_c_-_u0EFsu_-_prep\n",
      "2019-08-17 12:32:01,425 [vocabstudy.common] DEBUG: Checking if train dataset exists: /tmp/scratch/prep-datasets/c-minus-test_19-08-16T14-29-19_c_-_u0EFsu_-_prep\n",
      "2019-08-17 12:32:01,427 [vocabstudy.common] INFO: Train dataset is found and is going to be removed to save space: /tmp/scratch/prep-datasets/c-minus-test_19-08-16T14-29-19_c_-_u0EFsu_-_prep. Removing ...\n",
      "2019-08-17 12:32:01,428 [vocabstudy.common] INFO: Moving test dataset from tmp storage: /tmp/scratch/prep-datasets/c-test_13-07-12T06-20-12_c_-_u0EFsu_-_prep -> /home/lv71161/hlibbabii/prep-datasets\n",
      "2019-08-17 12:32:01,442 [vocabstudy.common] WARNING: Not moving. Path already exists: /home/lv71161/hlibbabii/prep-datasets/c-test_13-07-12T06-20-12_c_-_u0EFsu_-_prep\n",
      "\n",
      "========================   Split example   =========================\n",
      "\n",
      "['void', 'test_WordUeberraschungPrinter', '(', ')', '{', '\\n', '\\t', 'if', '(', 'eps', '>', '=', '0.345e+4', ')', '{', '<comment>', '\\t', '\\t', 'printWord', '(', '\"\"', ')', ';', '\\n', '\\t', '}', '\\n', '}']\n",
      "\n",
      "========================   Stats           =========================\n",
      "\n",
      "Train vocab: 12177936\n",
      "Test vocab : 298073, identifiers: 184072 (0.62%)\n",
      "\n",
      "Train corpus size: 2704596458\n",
      "Test corpus size : 29196908, identifiers: 5551239 (0.19%)\n",
      "\n",
      "OOV in test set (top 9223372036854775807): 56951 (19.11%), oov tokens number: 435900 (1.49%)\n",
      "OOV in test set (top 200000): 254826 (85.49%), oov tokens number: 1510026 (5.17%)\n",
      "OOV in test set (top 100000): 267913 (89.88%), oov tokens number: 1714222 (5.87%)\n",
      "OOV in test set (top 75000): 272444 (91.40%), oov tokens number: 1827598 (6.26%)\n",
      "OOV in test set (top 50000): 278106 (93.30%), oov tokens number: 1974589 (6.76%)\n",
      "OOV in test set (top 25000): 285368 (95.74%), oov tokens number: 2322442 (7.95%)\n",
      "\n",
      "For identifiers: \n",
      "\n",
      "OOV in test set (top 9223372036854775807): 48630 (26.42%), oov tokens number: 410133 (7.39%)\n",
      "OOV in test set (top 200000): 148860 (80.87%), oov tokens number: 1310471 (23.61%)\n",
      "OOV in test set (top 100000): 158477 (86.10%), oov tokens number: 1498396 (26.99%)\n",
      "OOV in test set (top 75000): 162299 (88.17%), oov tokens number: 1603615 (28.89%)\n",
      "OOV in test set (top 50000): 167091 (90.77%), oov tokens number: 1737293 (31.30%)\n",
      "OOV in test set (top 25000): 173373 (94.19%), oov tokens number: 2056892 (37.05%)\n",
      "[2585389, 6671856, 2500891, 378029, 41771]\n"
     ]
    }
   ],
   "source": [
    "prep_function = PrepFunction(api.nosplit, [], {\"no_com\": True, \"full_strings\": True, \"max_str_length\": 14})\n",
    "description = \"An additional choice, the model from Hellendoorn and Devanbu: keep strings shorter than 15 char (check SLP-core code), remove others, remove comments\"\n",
    "\n",
    "run(prep_function, description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Unsplit, remove non-ascii, remove whitespace, remove comments, remove strings longer than 15 chars] + Word splitting via conventions\n",
      "\n",
      "2019-08-17 12:32:38,360 [dataprep.infrastructure.stages] INFO: Checking first if vocabulary file exists: /home/lv71161/hlibbabii/.config/dataprep/1.0.0-alpha.8/vocab/c-minus-test_19-08-16T14-29-19_c_-_U0E10u/vocab\n",
      "2019-08-17 12:32:38,374 [dataprep.infrastructure.stages] INFO: Vocabulary is already computed and up-to-date\n",
      "2019-08-17 12:32:38,375 [dataprep.api.corpus] INFO: Preprocessed dataset is ready at /tmp/scratch/prep-datasets/c-minus-test_19-08-16T14-29-19_c_-_U0E10u_-_prep\n",
      "2019-08-17 12:32:46,123 [dataprep.infrastructure.stages] INFO: Checking first if vocabulary file exists: /home/lv71161/hlibbabii/.config/dataprep/1.0.0-alpha.8/vocab/c-test_13-07-12T06-20-12_c_-_U0E10u/vocab\n",
      "2019-08-17 12:32:46,147 [dataprep.infrastructure.stages] INFO: Vocabulary is already computed and up-to-date\n",
      "2019-08-17 12:32:46,148 [dataprep.api.corpus] INFO: Preprocessed dataset is ready at /tmp/scratch/prep-datasets/c-test_13-07-12T06-20-12_c_-_U0E10u_-_prep\n",
      "2019-08-17 12:32:46,531 [vocabstudy.common] DEBUG: Checking if train dataset exists: /tmp/scratch/prep-datasets/c-minus-test_19-08-16T14-29-19_c_-_U0E10u_-_prep\n",
      "2019-08-17 12:32:46,533 [vocabstudy.common] INFO: Train dataset is found and is going to be removed to save space: /tmp/scratch/prep-datasets/c-minus-test_19-08-16T14-29-19_c_-_U0E10u_-_prep. Removing ...\n",
      "2019-08-17 12:32:46,534 [vocabstudy.common] INFO: Moving test dataset from tmp storage: /tmp/scratch/prep-datasets/c-test_13-07-12T06-20-12_c_-_U0E10u_-_prep -> /home/lv71161/hlibbabii/prep-datasets\n",
      "2019-08-17 12:32:46,555 [vocabstudy.common] WARNING: Not moving. Path already exists: /home/lv71161/hlibbabii/prep-datasets/c-test_13-07-12T06-20-12_c_-_U0E10u_-_prep\n",
      "\n",
      "========================   Split example   =========================\n",
      "\n",
      "['void', '<w>', 'test', '_', 'Word', 'Ueberraschung', 'Printer', '</w>', '(', ')', '{', 'if', '(', 'eps', '>', '=', '0.345e+4', ')', '{', '<comment>', '<w>', 'print', 'Word', '</w>', '(', '\"', '\"', ')', ';', '}', '}']\n",
      "\n",
      "========================   Stats           =========================\n",
      "\n",
      "Train vocab: 3161429\n",
      "Test vocab : 153172, identifiers: 52877 (0.35%)\n",
      "\n",
      "Train corpus size: 3385643033\n",
      "Test corpus size : 40024405, identifiers: 15503909 (0.39%)\n",
      "\n",
      "OOV in test set (top 9223372036854775807): 8165 (5.33%), oov tokens number: 85029 (0.21%)\n",
      "OOV in test set (top 200000): 107904 (70.45%), oov tokens number: 388547 (0.97%)\n",
      "OOV in test set (top 100000): 119389 (77.94%), oov tokens number: 496867 (1.24%)\n",
      "OOV in test set (top 75000): 123561 (80.67%), oov tokens number: 548260 (1.37%)\n",
      "OOV in test set (top 50000): 129091 (84.28%), oov tokens number: 653906 (1.63%)\n",
      "OOV in test set (top 25000): 137179 (89.56%), oov tokens number: 932038 (2.33%)\n",
      "\n",
      "For identifiers: \n",
      "\n",
      "OOV in test set (top 9223372036854775807): 4110 (7.77%), oov tokens number: 71422 (0.46%)\n",
      "OOV in test set (top 200000): 22659 (42.85%), oov tokens number: 256976 (1.66%)\n",
      "OOV in test set (top 100000): 27241 (51.52%), oov tokens number: 342512 (2.21%)\n",
      "OOV in test set (top 75000): 29240 (55.30%), oov tokens number: 383400 (2.47%)\n",
      "OOV in test set (top 50000): 32865 (62.15%), oov tokens number: 468672 (3.02%)\n",
      "OOV in test set (top 25000): 39086 (73.92%), oov tokens number: 701375 (4.52%)\n",
      "[1111490, 1324546, 514231, 171944, 39218]\n"
     ]
    }
   ],
   "source": [
    "prep_function = PrepFunction(api.basic, [],\n",
    "                             {\"no_unicode\": True, \"no_spaces\": True, \"no_com\": True, \"max_str_length\": 14})\n",
    "description = \"[Unsplit, remove non-ascii, remove whitespace, remove comments, remove strings longer than 15 chars] + Word splitting via conventions\"\n",
    "\n",
    "run(prep_function, description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Unsplit, remove non-ascii, remove whitespace, remove comments, remove strings longer than 15 chars] + split via conventions, but keep case. + Split numbers + Ronin\n",
      "\n",
      "2019-08-17 12:32:56,162 [dataprep.infrastructure.stages] INFO: Checking first if vocabulary file exists: /home/lv71161/hlibbabii/.config/dataprep/1.0.0-alpha.8/vocab/c-minus-test_19-08-16T14-29-19_c_-_U0E30l/vocab\n",
      "2019-08-17 12:32:56,170 [dataprep.infrastructure.stages] INFO: Vocabulary is already computed and up-to-date\n",
      "2019-08-17 12:32:56,171 [dataprep.api.corpus] INFO: Preprocessed dataset is ready at /tmp/scratch/prep-datasets/c-minus-test_19-08-16T14-29-19_c_-_U0E30l_-_prep\n",
      "2019-08-17 12:32:57,496 [dataprep.infrastructure.stages] INFO: Checking first if vocabulary file exists: /home/lv71161/hlibbabii/.config/dataprep/1.0.0-alpha.8/vocab/c-test_13-07-12T06-20-12_c_-_U0E30l/vocab\n",
      "2019-08-17 12:32:57,505 [dataprep.infrastructure.stages] INFO: Vocabulary is already computed and up-to-date\n",
      "2019-08-17 12:32:57,506 [dataprep.api.corpus] INFO: Preprocessed dataset is ready at /tmp/scratch/prep-datasets/c-test_13-07-12T06-20-12_c_-_U0E30l_-_prep\n",
      "2019-08-17 12:32:57,652 [vocabstudy.common] DEBUG: Checking if train dataset exists: /tmp/scratch/prep-datasets/c-minus-test_19-08-16T14-29-19_c_-_U0E30l_-_prep\n",
      "2019-08-17 12:32:57,654 [vocabstudy.common] INFO: Train dataset is found and is going to be removed to save space: /tmp/scratch/prep-datasets/c-minus-test_19-08-16T14-29-19_c_-_U0E30l_-_prep. Removing ...\n",
      "2019-08-17 12:32:57,656 [vocabstudy.common] INFO: Moving test dataset from tmp storage: /tmp/scratch/prep-datasets/c-test_13-07-12T06-20-12_c_-_U0E30l_-_prep -> /home/lv71161/hlibbabii/prep-datasets\n",
      "2019-08-17 12:32:57,681 [vocabstudy.common] WARNING: Not moving. Path already exists: /home/lv71161/hlibbabii/prep-datasets/c-test_13-07-12T06-20-12_c_-_U0E30l_-_prep\n",
      "\n",
      "========================   Split example   =========================\n",
      "\n",
      "['void', '<w>', 'test', '_', '<Cap>', 'word', '<Cap>', 'ueberraschung', '<Cap>', 'printer', '</w>', '(', ')', '{', 'if', '(', 'eps', '>', '=', '<w>', '0', '.', '3', '4', '5', 'e', '+', '4', '</w>', ')', '{', '<comment>', '<w>', 'print', '<Cap>', 'word', '</w>', '(', '\"', '\"', ')', ';', '}', '}']\n",
      "\n",
      "========================   Stats           =========================\n",
      "\n",
      "Train vocab: 507372\n",
      "Test vocab : 24102, identifiers: 20796 (0.86%)\n",
      "\n",
      "Train corpus size: 4460504358\n",
      "Test corpus size : 47602233, identifiers: 16777157 (0.35%)\n",
      "\n",
      "OOV in test set (top 9223372036854775807): 1312 (5.44%), oov tokens number: 14181 (0.03%)\n",
      "OOV in test set (top 200000): 3014 (12.51%), oov tokens number: 26400 (0.06%)\n",
      "OOV in test set (top 100000): 4665 (19.36%), oov tokens number: 43716 (0.09%)\n",
      "OOV in test set (top 75000): 6192 (25.69%), oov tokens number: 59560 (0.13%)\n",
      "OOV in test set (top 50000): 8582 (35.61%), oov tokens number: 88093 (0.19%)\n",
      "OOV in test set (top 25000): 11983 (49.72%), oov tokens number: 172165 (0.36%)\n",
      "\n",
      "For identifiers: \n",
      "\n",
      "OOV in test set (top 9223372036854775807): 1308 (6.29%), oov tokens number: 14175 (0.08%)\n",
      "OOV in test set (top 200000): 3007 (14.46%), oov tokens number: 26369 (0.16%)\n",
      "OOV in test set (top 100000): 4596 (22.10%), oov tokens number: 43215 (0.26%)\n",
      "OOV in test set (top 75000): 5630 (27.07%), oov tokens number: 54553 (0.33%)\n",
      "OOV in test set (top 50000): 7519 (36.16%), oov tokens number: 76188 (0.45%)\n",
      "OOV in test set (top 25000): 10151 (48.81%), oov tokens number: 146071 (0.87%)\n",
      "[81683, 236899, 130081, 39763, 18946]\n"
     ]
    }
   ],
   "source": [
    "prep_function = PrepFunction(api.basic, [],\n",
    "                             {\"no_unicode\": True, \"no_spaces\": True, \"no_com\": True, \"max_str_length\": 14,\n",
    "                              \"no_case\": True, \"split_numbers\": True, \"ronin\": True})\n",
    "description = \"[Unsplit, remove non-ascii, remove whitespace, remove comments, remove strings longer than 15 chars] + split via conventions, but keep case. + Split numbers + Ronin\"\n",
    "run(prep_function, description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_function = PrepFunction(api.bpe, ['c-bpe-training_nounicode-2000'], {\"no_com\": True, \"max_str_length\": 14})\n",
    "description = \"bpe 2k Hellendoorn and Devanbu strings no comments\"\n",
    "run(prep_function, description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_function = PrepFunction(api.bpe, ['c-bpe-training_nounicode-5000'], {\"no_com\": True, \"max_str_length\": 14})\n",
    "description = \"bpe 5k Hellendoorn and Devanbu strings no comments\"\n",
    "run(prep_function, description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prep_function = PrepFunction(api.bpe, ['c-bpe-training_nounicode-10000'], {\"no_com\": True, \"max_str_length\": 14})\n",
    "description = \"bpe 10k Hellendoorn and Devanbu strings no comments\"\n",
    "run(prep_function, description)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
