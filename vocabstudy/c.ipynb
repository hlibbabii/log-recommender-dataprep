{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataprep.api.corpus as api\n",
    "import os\n",
    "from vocabstudy.common import PrepFunction, calc_and_display_stats, VocabStatsCsvWriter, HEADER, HOME\n",
    "C_KEYWORDS = [\"auto\", \"double\", \"int\", \"struct\", \"break\", \"else\", \"long\", \n",
    "            \"switch\", \"case\", \"enum\", \"register\", \"typedef\", \"char\", \n",
    "            \"extern\", \"return\", \"union\", \"continue\", \"for\", \"signed\", \n",
    "            \"void\", \"do\", \"if\", \"static\", \"while\", \"default\", \"goto\", \n",
    "            \"sizeof\", \"volatile\", \"const\", \"float\", \"short\", \"unsigned\"]\n",
    "\n",
    "C_DATASETS = ('rafael/c-minus-test',\n",
    "            'rafael/c-test'\n",
    "           )\n",
    "\n",
    "writer = VocabStatsCsvWriter(os.path.join(HOME, 'c-stats.csv'), HEADER)\n",
    "\n",
    "def run(prep_function: PrepFunction, description: str) -> None:\n",
    "    row = calc_and_display_stats(prep_function, description, C_DATASETS, C_KEYWORDS, 'c')\n",
    "    writer.write_line(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.0.0-alpha.8'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dataprep\n",
    "\n",
    "dataprep.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l31.vsc3plus.xcat\r\n"
     ]
    }
   ],
   "source": [
    "!hostname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unsplit, with comments and vocabulary. No filtering.\n",
      "\n",
      "2019-08-26 12:07:19,812 [dataprep.infrastructure.stages] INFO: Checking first if vocabulary file exists: /home/lv71161/hlibbabii/.config/dataprep/1.0.0-alpha.8/vocab/c-minus-test_19-08-16T14-29-19_c_-_uc10su/vocab\n",
      "2019-08-26 12:07:19,814 [dataprep.infrastructure.stages] INFO: Vocabulary is already computed and up-to-date\n",
      "2019-08-26 12:07:19,815 [dataprep.api.corpus] INFO: Preprocessed dataset is ready at /tmp/scratch/prep-datasets/c-minus-test_19-08-16T14-29-19_c_-_uc10su_-_prep\n",
      "2019-08-26 12:07:56,309 [dataprep.infrastructure.stages] INFO: Checking first if vocabulary file exists: /home/lv71161/hlibbabii/.config/dataprep/1.0.0-alpha.8/vocab/c-test_13-07-12T06-20-12_c_-_uc10su/vocab\n",
      "2019-08-26 12:07:56,313 [dataprep.infrastructure.stages] INFO: Vocabulary is already computed and up-to-date\n",
      "2019-08-26 12:07:56,313 [dataprep.api.corpus] INFO: Preprocessed dataset is ready at /tmp/scratch/prep-datasets/c-test_13-07-12T06-20-12_c_-_uc10su_-_prep\n",
      "2019-08-26 12:07:57,135 [vocabstudy.common] DEBUG: Checking if train dataset exists: /tmp/scratch/prep-datasets/c-minus-test_19-08-16T14-29-19_c_-_uc10su_-_prep\n",
      "2019-08-26 12:07:57,137 [vocabstudy.common] INFO: Train dataset is found and is going to be removed to save space: /tmp/scratch/prep-datasets/c-minus-test_19-08-16T14-29-19_c_-_uc10su_-_prep. Removing ...\n",
      "2019-08-26 12:07:57,138 [vocabstudy.common] INFO: Moving test dataset from tmp storage: /tmp/scratch/prep-datasets/c-test_13-07-12T06-20-12_c_-_uc10su_-_prep -> /home/lv71161/hlibbabii/prep-datasets\n",
      "2019-08-26 12:07:57,139 [vocabstudy.common] WARNING: Not moving. Path already exists: /home/lv71161/hlibbabii/prep-datasets/c-test_13-07-12T06-20-12_c_-_uc10su_-_prep\n",
      "\n",
      "========================   Split example   =========================\n",
      "\n",
      "['void', 'test_WordUeberraschungPrinter', '(', ')', '{', '\\n', '\\t', 'if', '(', 'eps', '>', '=', '0.345e+4', ')', '{', '/', '/', 'FIXME', '10l', '\\n', '<EOL>', '\\t', '\\t', 'printWord', '(', '\"', '.', '.', '.', 'Ãœberraschung', '0x12', '\"', ')', ';', '\\n', '\\t', '}', '\\n', '}']\n",
      "\n",
      "========================   Stats           =========================\n",
      "\n",
      "Train vocab: 13221586\n",
      "Test vocab : 336644, identifiers: 231731 (0.69%)\n",
      "\n",
      "Train corpus size: 3737950475\n",
      "Test corpus size : 39259258, identifiers: 9493899 (0.24%)\n",
      "\n",
      "OOV in test set (top 9223372036854775807): 59586 (17.70%), oov tokens number: 548276 (1.40%)\n",
      "OOV in test set (top 200000): 278122 (82.62%), oov tokens number: 1821403 (4.64%)\n",
      "OOV in test set (top 100000): 295646 (87.82%), oov tokens number: 2180057 (5.55%)\n",
      "OOV in test set (top 75000): 302015 (89.71%), oov tokens number: 2330818 (5.94%)\n",
      "OOV in test set (top 50000): 309641 (91.98%), oov tokens number: 2537213 (6.46%)\n",
      "OOV in test set (top 25000): 319822 (95.00%), oov tokens number: 3026778 (7.71%)\n",
      "Variation coeff: 1.7312001316895984e-05\n",
      "[2829359, 7055001, 2837641, 443369, 56216]\n"
     ]
    }
   ],
   "source": [
    "prep_function = PrepFunction(api.nosplit)\n",
    "description = \"unsplit, with comments and vocabulary. No filtering.\"\n",
    "\n",
    "run(prep_function, description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering  strings (+ comments, + whitespace, + non-ascii)\n",
      "\n",
      "2019-08-26 12:08:31,510 [dataprep.infrastructure.stages] INFO: Checking first if vocabulary file exists: /home/lv71161/hlibbabii/.config/dataprep/1.0.0-alpha.8/vocab/c-minus-test_19-08-16T14-29-19_c_-_U0000u/vocab\n",
      "2019-08-26 12:08:31,512 [dataprep.infrastructure.stages] INFO: Vocabulary is already computed and up-to-date\n",
      "2019-08-26 12:08:31,512 [dataprep.api.corpus] INFO: Preprocessed dataset is ready at /tmp/scratch/prep-datasets/c-minus-test_19-08-16T14-29-19_c_-_U0000u_-_prep\n",
      "2019-08-26 12:09:00,094 [dataprep.infrastructure.stages] INFO: Checking first if vocabulary file exists: /home/lv71161/hlibbabii/.config/dataprep/1.0.0-alpha.8/vocab/c-test_13-07-12T06-20-12_c_-_U0000u/vocab\n",
      "2019-08-26 12:09:00,096 [dataprep.infrastructure.stages] INFO: Vocabulary is already computed and up-to-date\n",
      "2019-08-26 12:09:00,096 [dataprep.api.corpus] INFO: Preprocessed dataset is ready at /tmp/scratch/prep-datasets/c-test_13-07-12T06-20-12_c_-_U0000u_-_prep\n",
      "2019-08-26 12:09:00,779 [vocabstudy.common] DEBUG: Checking if train dataset exists: /tmp/scratch/prep-datasets/c-minus-test_19-08-16T14-29-19_c_-_U0000u_-_prep\n",
      "2019-08-26 12:09:00,780 [vocabstudy.common] INFO: Train dataset is found and is going to be removed to save space: /tmp/scratch/prep-datasets/c-minus-test_19-08-16T14-29-19_c_-_U0000u_-_prep. Removing ...\n",
      "2019-08-26 12:09:00,782 [vocabstudy.common] INFO: Moving test dataset from tmp storage: /tmp/scratch/prep-datasets/c-test_13-07-12T06-20-12_c_-_U0000u_-_prep -> /home/lv71161/hlibbabii/prep-datasets\n",
      "2019-08-26 12:09:00,783 [vocabstudy.common] WARNING: Not moving. Path already exists: /home/lv71161/hlibbabii/prep-datasets/c-test_13-07-12T06-20-12_c_-_U0000u_-_prep\n",
      "\n",
      "========================   Split example   =========================\n",
      "\n",
      "['void', 'test_WordUeberraschungPrinter', '(', ')', '{', 'if', '(', 'eps', '>', '=', '0.345e+4', ')', '{', '<comment>', 'printWord', '(', '<str-literal>', ')', ';', '}', '}']\n",
      "\n",
      "========================   Stats           =========================\n",
      "\n",
      "Train vocab: 10876491\n",
      "Test vocab : 276302, identifiers: 176153 (0.64%)\n",
      "\n",
      "Train corpus size: 2091010818\n",
      "Test corpus size : 22804343, identifiers: 5477086 (0.24%)\n",
      "\n",
      "OOV in test set (top 9223372036854775807): 51809 (18.75%), oov tokens number: 422517 (1.85%)\n",
      "OOV in test set (top 200000): 235064 (85.08%), oov tokens number: 1437814 (6.31%)\n",
      "OOV in test set (top 100000): 247448 (89.56%), oov tokens number: 1636705 (7.18%)\n",
      "OOV in test set (top 75000): 251711 (91.10%), oov tokens number: 1745437 (7.65%)\n",
      "OOV in test set (top 50000): 257049 (93.03%), oov tokens number: 1890959 (8.29%)\n",
      "OOV in test set (top 25000): 264041 (95.56%), oov tokens number: 2232171 (9.79%)\n",
      "Variation coeff: 2.2608846993278185e-05\n",
      "[1930629, 6146379, 2389714, 369351, 40418]\n"
     ]
    }
   ],
   "source": [
    "prep_function = PrepFunction(api.nosplit, [], {\"no_unicode\": True, \"no_spaces\": True, \"no_com\": True, \"no_str\": True})\n",
    "description = \"Filtering  strings (+ comments, + whitespace, + non-ascii)\"\n",
    "\n",
    "run(prep_function, description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An additional choice, the model from Hellendoorn and Devanbu: keep strings shorter than 15 char (check SLP-core code), remove others, remove comments\n",
      "\n",
      "2019-08-26 12:09:28,248 [dataprep.infrastructure.stages] INFO: Checking first if vocabulary file exists: /home/lv71161/hlibbabii/.config/dataprep/1.0.0-alpha.8/vocab/c-minus-test_19-08-16T14-29-19_c_-_u0EFsu/vocab\n",
      "2019-08-26 12:09:28,249 [dataprep.infrastructure.stages] INFO: Vocabulary is already computed and up-to-date\n",
      "2019-08-26 12:09:28,250 [dataprep.api.corpus] INFO: Preprocessed dataset is ready at /tmp/scratch/prep-datasets/c-minus-test_19-08-16T14-29-19_c_-_u0EFsu_-_prep\n",
      "2019-08-26 12:10:00,609 [dataprep.infrastructure.stages] INFO: Checking first if vocabulary file exists: /home/lv71161/hlibbabii/.config/dataprep/1.0.0-alpha.8/vocab/c-test_13-07-12T06-20-12_c_-_u0EFsu/vocab\n",
      "2019-08-26 12:10:00,611 [dataprep.infrastructure.stages] INFO: Vocabulary is already computed and up-to-date\n",
      "2019-08-26 12:10:00,611 [dataprep.api.corpus] INFO: Preprocessed dataset is ready at /tmp/scratch/prep-datasets/c-test_13-07-12T06-20-12_c_-_u0EFsu_-_prep\n",
      "2019-08-26 12:10:01,357 [vocabstudy.common] DEBUG: Checking if train dataset exists: /tmp/scratch/prep-datasets/c-minus-test_19-08-16T14-29-19_c_-_u0EFsu_-_prep\n",
      "2019-08-26 12:10:01,358 [vocabstudy.common] INFO: Train dataset is found and is going to be removed to save space: /tmp/scratch/prep-datasets/c-minus-test_19-08-16T14-29-19_c_-_u0EFsu_-_prep. Removing ...\n",
      "2019-08-26 12:10:01,360 [vocabstudy.common] INFO: Moving test dataset from tmp storage: /tmp/scratch/prep-datasets/c-test_13-07-12T06-20-12_c_-_u0EFsu_-_prep -> /home/lv71161/hlibbabii/prep-datasets\n",
      "2019-08-26 12:10:01,360 [vocabstudy.common] WARNING: Not moving. Path already exists: /home/lv71161/hlibbabii/prep-datasets/c-test_13-07-12T06-20-12_c_-_u0EFsu_-_prep\n",
      "\n",
      "========================   Split example   =========================\n",
      "\n",
      "['void', 'test_WordUeberraschungPrinter', '(', ')', '{', '\\n', '\\t', 'if', '(', 'eps', '>', '=', '0.345e+4', ')', '{', '<comment>', '\\t', '\\t', 'printWord', '(', '\"\"', ')', ';', '\\n', '\\t', '}', '\\n', '}']\n",
      "\n",
      "========================   Stats           =========================\n",
      "\n",
      "Train vocab: 12177936\n",
      "Test vocab : 298073, identifiers: 184072 (0.62%)\n",
      "\n",
      "Train corpus size: 2704596458\n",
      "Test corpus size : 29196908, identifiers: 5551239 (0.19%)\n",
      "\n",
      "OOV in test set (top 9223372036854775807): 56951 (19.11%), oov tokens number: 435900 (1.49%)\n",
      "OOV in test set (top 200000): 254826 (85.49%), oov tokens number: 1510026 (5.17%)\n",
      "OOV in test set (top 100000): 267913 (89.88%), oov tokens number: 1714222 (5.87%)\n",
      "OOV in test set (top 75000): 272444 (91.40%), oov tokens number: 1827598 (6.26%)\n",
      "OOV in test set (top 50000): 278106 (93.30%), oov tokens number: 1974589 (6.76%)\n",
      "OOV in test set (top 25000): 285368 (95.74%), oov tokens number: 2322442 (7.95%)\n",
      "Variation coeff: 1.9335272098866625e-05\n",
      "[2585389, 6671856, 2500891, 378029, 41771]\n"
     ]
    }
   ],
   "source": [
    "prep_function = PrepFunction(api.nosplit, [], {\"no_com\": True, \"full_strings\": True, \"max_str_length\": 14})\n",
    "description = \"An additional choice, the model from Hellendoorn and Devanbu: keep strings shorter than 15 char (check SLP-core code), remove others, remove comments\"\n",
    "\n",
    "run(prep_function, description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Unsplit, remove non-ascii, remove whitespace, remove comments, remove strings longer than 15 chars] + Word splitting via conventions\n",
      "\n",
      "2019-08-26 12:10:32,381 [dataprep.infrastructure.stages] INFO: Checking first if vocabulary file exists: /home/lv71161/hlibbabii/.config/dataprep/1.0.0-alpha.8/vocab/c-minus-test_19-08-16T14-29-19_c_-_U0E10u/vocab\n",
      "2019-08-26 12:10:32,382 [dataprep.infrastructure.stages] INFO: Vocabulary is already computed and up-to-date\n",
      "2019-08-26 12:10:32,383 [dataprep.api.corpus] INFO: Preprocessed dataset is ready at /tmp/scratch/prep-datasets/c-minus-test_19-08-16T14-29-19_c_-_U0E10u_-_prep\n",
      "2019-08-26 12:10:40,309 [dataprep.infrastructure.stages] INFO: Checking first if vocabulary file exists: /home/lv71161/hlibbabii/.config/dataprep/1.0.0-alpha.8/vocab/c-test_13-07-12T06-20-12_c_-_U0E10u/vocab\n",
      "2019-08-26 12:10:40,311 [dataprep.infrastructure.stages] INFO: Vocabulary is already computed and up-to-date\n",
      "2019-08-26 12:10:40,312 [dataprep.api.corpus] INFO: Preprocessed dataset is ready at /tmp/scratch/prep-datasets/c-test_13-07-12T06-20-12_c_-_U0E10u_-_prep\n",
      "2019-08-26 12:10:40,667 [vocabstudy.common] DEBUG: Checking if train dataset exists: /tmp/scratch/prep-datasets/c-minus-test_19-08-16T14-29-19_c_-_U0E10u_-_prep\n",
      "2019-08-26 12:10:40,668 [vocabstudy.common] INFO: Train dataset is found and is going to be removed to save space: /tmp/scratch/prep-datasets/c-minus-test_19-08-16T14-29-19_c_-_U0E10u_-_prep. Removing ...\n",
      "2019-08-26 12:10:40,669 [vocabstudy.common] INFO: Moving test dataset from tmp storage: /tmp/scratch/prep-datasets/c-test_13-07-12T06-20-12_c_-_U0E10u_-_prep -> /home/lv71161/hlibbabii/prep-datasets\n",
      "2019-08-26 12:10:40,670 [vocabstudy.common] WARNING: Not moving. Path already exists: /home/lv71161/hlibbabii/prep-datasets/c-test_13-07-12T06-20-12_c_-_U0E10u_-_prep\n",
      "\n",
      "========================   Split example   =========================\n",
      "\n",
      "['void', '<w>', 'test', '_', 'Word', 'Ueberraschung', 'Printer', '</w>', '(', ')', '{', 'if', '(', 'eps', '>', '=', '0.345e+4', ')', '{', '<comment>', '<w>', 'print', 'Word', '</w>', '(', '\"', '\"', ')', ';', '}', '}']\n",
      "\n",
      "========================   Stats           =========================\n",
      "\n",
      "Train vocab: 3161429\n",
      "Test vocab : 153172, identifiers: 52877 (0.35%)\n",
      "\n",
      "Train corpus size: 3385643033\n",
      "Test corpus size : 40024405, identifiers: 15503909 (0.39%)\n",
      "\n",
      "OOV in test set (top 9223372036854775807): 8165 (5.33%), oov tokens number: 85029 (0.21%)\n",
      "OOV in test set (top 200000): 107904 (70.45%), oov tokens number: 388547 (0.97%)\n",
      "OOV in test set (top 100000): 119389 (77.94%), oov tokens number: 496867 (1.24%)\n",
      "OOV in test set (top 75000): 123561 (80.67%), oov tokens number: 548260 (1.37%)\n",
      "OOV in test set (top 50000): 129091 (84.28%), oov tokens number: 653906 (1.63%)\n",
      "OOV in test set (top 25000): 137179 (89.56%), oov tokens number: 932038 (2.33%)\n",
      "Variation coeff: 1.7814581672776916e-05\n",
      "[1111490, 1324546, 514231, 171944, 39218]\n"
     ]
    }
   ],
   "source": [
    "prep_function = PrepFunction(api.basic, [],\n",
    "                             {\"no_unicode\": True, \"no_spaces\": True, \"no_com\": True, \"max_str_length\": 14})\n",
    "description = \"[Unsplit, remove non-ascii, remove whitespace, remove comments, remove strings longer than 15 chars] + Word splitting via conventions\"\n",
    "\n",
    "run(prep_function, description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Unsplit, remove non-ascii, remove whitespace, remove comments, remove strings longer than 15 chars] + split via conventions, but keep case. + Split numbers + Ronin\n",
      "\n",
      "2019-08-26 12:10:49,763 [dataprep.infrastructure.stages] INFO: Checking first if vocabulary file exists: /home/lv71161/hlibbabii/.config/dataprep/1.0.0-alpha.8/vocab/c-minus-test_19-08-16T14-29-19_c_-_U0E30l/vocab\n",
      "2019-08-26 12:10:49,765 [dataprep.infrastructure.stages] INFO: Vocabulary is already computed and up-to-date\n",
      "2019-08-26 12:10:49,766 [dataprep.api.corpus] INFO: Preprocessed dataset is ready at /tmp/scratch/prep-datasets/c-minus-test_19-08-16T14-29-19_c_-_U0E30l_-_prep\n",
      "2019-08-26 12:10:51,302 [dataprep.infrastructure.stages] INFO: Checking first if vocabulary file exists: /home/lv71161/hlibbabii/.config/dataprep/1.0.0-alpha.8/vocab/c-test_13-07-12T06-20-12_c_-_U0E30l/vocab\n",
      "2019-08-26 12:10:51,303 [dataprep.infrastructure.stages] INFO: Vocabulary is already computed and up-to-date\n",
      "2019-08-26 12:10:51,303 [dataprep.api.corpus] INFO: Preprocessed dataset is ready at /tmp/scratch/prep-datasets/c-test_13-07-12T06-20-12_c_-_U0E30l_-_prep\n",
      "2019-08-26 12:10:51,360 [vocabstudy.common] DEBUG: Checking if train dataset exists: /tmp/scratch/prep-datasets/c-minus-test_19-08-16T14-29-19_c_-_U0E30l_-_prep\n",
      "2019-08-26 12:10:51,361 [vocabstudy.common] INFO: Train dataset is found and is going to be removed to save space: /tmp/scratch/prep-datasets/c-minus-test_19-08-16T14-29-19_c_-_U0E30l_-_prep. Removing ...\n",
      "2019-08-26 12:10:51,362 [vocabstudy.common] INFO: Moving test dataset from tmp storage: /tmp/scratch/prep-datasets/c-test_13-07-12T06-20-12_c_-_U0E30l_-_prep -> /home/lv71161/hlibbabii/prep-datasets\n",
      "2019-08-26 12:10:51,363 [vocabstudy.common] WARNING: Not moving. Path already exists: /home/lv71161/hlibbabii/prep-datasets/c-test_13-07-12T06-20-12_c_-_U0E30l_-_prep\n",
      "\n",
      "========================   Split example   =========================\n",
      "\n",
      "['void', '<w>', 'test', '_', '<Cap>', 'word', '<Cap>', 'ueberraschung', '<Cap>', 'printer', '</w>', '(', ')', '{', 'if', '(', 'eps', '>', '=', '<w>', '0', '.', '3', '4', '5', 'e', '+', '4', '</w>', ')', '{', '<comment>', '<w>', 'print', '<Cap>', 'word', '</w>', '(', '\"', '\"', ')', ';', '}', '}']\n",
      "\n",
      "========================   Stats           =========================\n",
      "\n",
      "Train vocab: 507372\n",
      "Test vocab : 24102, identifiers: 20796 (0.86%)\n",
      "\n",
      "Train corpus size: 4460504358\n",
      "Test corpus size : 47602233, identifiers: 16777157 (0.35%)\n",
      "\n",
      "OOV in test set (top 9223372036854775807): 1312 (5.44%), oov tokens number: 14181 (0.03%)\n",
      "OOV in test set (top 200000): 3014 (12.51%), oov tokens number: 26400 (0.06%)\n",
      "OOV in test set (top 100000): 4665 (19.36%), oov tokens number: 43716 (0.09%)\n",
      "OOV in test set (top 75000): 6192 (25.69%), oov tokens number: 59560 (0.13%)\n",
      "OOV in test set (top 50000): 8582 (35.61%), oov tokens number: 88093 (0.19%)\n",
      "OOV in test set (top 25000): 11983 (49.72%), oov tokens number: 172165 (0.36%)\n",
      "Variation coeff: 1.4793395950291147e-05\n",
      "[81683, 236899, 130081, 39763, 18946]\n"
     ]
    }
   ],
   "source": [
    "prep_function = PrepFunction(api.basic, [],\n",
    "                             {\"no_unicode\": True, \"no_spaces\": True, \"no_com\": True, \"max_str_length\": 14,\n",
    "                              \"no_case\": True, \"split_numbers\": True, \"ronin\": True})\n",
    "description = \"[Unsplit, remove non-ascii, remove whitespace, remove comments, remove strings longer than 15 chars] + split via conventions, but keep case. + Split numbers + Ronin\"\n",
    "run(prep_function, description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bpe 2k Hellendoorn and Devanbu strings no comments no unicode\n",
      "\n",
      "2019-08-26 12:10:53,350 [dataprep.infrastructure.stages] INFO: Checking first if vocabulary file exists: /home/lv71161/hlibbabii/.config/dataprep/1.0.0-alpha.8/vocab/c-minus-test_19-08-16T14-29-19_c_-_U0E9su_c-bpe-training_nounicode-2000/vocab\n",
      "2019-08-26 12:10:53,351 [dataprep.infrastructure.stages] INFO: Vocabulary is already computed and up-to-date\n",
      "2019-08-26 12:10:53,351 [dataprep.api.corpus] INFO: Preprocessed dataset is ready at /tmp/scratch/prep-datasets/c-minus-test_19-08-16T14-29-19_c_-_U0E9su_c-bpe-training_nounicode-2000_-_prep\n",
      "2019-08-26 12:10:53,397 [dataprep.infrastructure.stages] INFO: Checking first if vocabulary file exists: /home/lv71161/hlibbabii/.config/dataprep/1.0.0-alpha.8/vocab/c-test_13-07-12T06-20-12_c_-_U0E9su_c-bpe-training_nounicode-2000/vocab\n",
      "2019-08-26 12:10:53,398 [dataprep.infrastructure.stages] INFO: Vocabulary is already computed and up-to-date\n",
      "2019-08-26 12:10:53,398 [dataprep.api.corpus] INFO: Preprocessed dataset is ready at /tmp/scratch/prep-datasets/c-test_13-07-12T06-20-12_c_-_U0E9su_c-bpe-training_nounicode-2000_-_prep\n",
      "2019-08-26 12:10:53,405 [vocabstudy.common] DEBUG: Checking if train dataset exists: /tmp/scratch/prep-datasets/c-minus-test_19-08-16T14-29-19_c_-_U0E9su_c-bpe-training_nounicode-2000_-_prep\n",
      "2019-08-26 12:10:53,405 [vocabstudy.common] INFO: Train dataset is found and is going to be removed to save space: /tmp/scratch/prep-datasets/c-minus-test_19-08-16T14-29-19_c_-_U0E9su_c-bpe-training_nounicode-2000_-_prep. Removing ...\n",
      "2019-08-26 12:10:53,407 [vocabstudy.common] INFO: Moving test dataset from tmp storage: /tmp/scratch/prep-datasets/c-test_13-07-12T06-20-12_c_-_U0E9su_c-bpe-training_nounicode-2000_-_prep -> /home/lv71161/hlibbabii/prep-datasets\n",
      "2019-08-26 12:10:53,407 [vocabstudy.common] WARNING: Not moving. Path already exists: /home/lv71161/hlibbabii/prep-datasets/c-test_13-07-12T06-20-12_c_-_U0E9su_c-bpe-training_nounicode-2000_-_prep\n",
      "\n",
      "========================   Split example   =========================\n",
      "\n",
      "2019-08-26 12:10:53,411 [dataprep.to_repr] INFO: Using bpe merges file: /home/lv71161/hlibbabii/.config/dataprep/1.0.0-alpha.8/bpe/c-bpe-training_13-07-12T06-23-32_c_-_nounicode/2000/merges.txt\n",
      "2019-08-26 12:10:53,423 [dataprep.to_repr] INFO: Using first 2000 merges.\n",
      "['void</t>', 'test_', 'W', 'or', 'd', 'U', 'e', 'b', 'err', 'as', 'chun', 'g', 'P', 'r', 'int', 'er</t>', '(</t>', ')</t>', '{</t>', '\\n', '\\t', 'if</t>', '(</t>', 'e', 'ps</t>', '></t>', '=</t>', '0.', '3', '45', 'e', '+', '4</t>', ')</t>', '{</t>', '<comment>', '\\t', '\\t', 'print', 'W', 'or', 'd</t>', '(</t>', '\"', '\"', ')</t>', ';</t>', '\\n', '\\t', '}</t>', '\\n', '}</t>']\n",
      "\n",
      "========================   Stats           =========================\n",
      "\n",
      "Train vocab: 2372\n",
      "Test vocab : 2191, identifiers: 1255 (0.57%)\n",
      "\n",
      "Train corpus size: 4233982066\n",
      "Test corpus size : 44446212, identifiers: 13577500 (0.31%)\n",
      "\n",
      "OOV in test set (top 9223372036854775807): 0 (0.00%), oov tokens number: 0 (0.00%)\n",
      "OOV in test set (top 200000): 0 (0.00%), oov tokens number: 0 (0.00%)\n",
      "OOV in test set (top 100000): 0 (0.00%), oov tokens number: 0 (0.00%)\n",
      "OOV in test set (top 75000): 0 (0.00%), oov tokens number: 0 (0.00%)\n",
      "OOV in test set (top 50000): 0 (0.00%), oov tokens number: 0 (0.00%)\n",
      "OOV in test set (top 25000): 0 (0.00%), oov tokens number: 0 (0.00%)\n",
      "Variation coeff: 2.1491911464385295e-05\n",
      "[19, 46, 54, 40, 2213]\n"
     ]
    }
   ],
   "source": [
    "prep_function = PrepFunction(api.bpe, ['c-bpe-training_nounicode-2000'], {\"no_com\": True, \"max_str_length\": 14, \"no_unicode\": True})\n",
    "description = \"bpe 2k Hellendoorn and Devanbu strings no comments no unicode\"\n",
    "run(prep_function, description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bpe 5k Hellendoorn and Devanbu strings no comments no unicode \n",
      "\n",
      "2019-08-26 12:10:53,528 [dataprep.infrastructure.stages] INFO: Checking first if vocabulary file exists: /home/lv71161/hlibbabii/.config/dataprep/1.0.0-alpha.8/vocab/c-minus-test_19-08-16T14-29-19_c_-_U0E9su_c-bpe-training_nounicode-5000/vocab\n",
      "2019-08-26 12:10:53,528 [dataprep.infrastructure.stages] INFO: Vocabulary is already computed and up-to-date\n",
      "2019-08-26 12:10:53,529 [dataprep.api.corpus] INFO: Preprocessed dataset is ready at /tmp/scratch/prep-datasets/c-minus-test_19-08-16T14-29-19_c_-_U0E9su_c-bpe-training_nounicode-5000_-_prep\n",
      "2019-08-26 12:10:53,588 [dataprep.infrastructure.stages] INFO: Checking first if vocabulary file exists: /home/lv71161/hlibbabii/.config/dataprep/1.0.0-alpha.8/vocab/c-test_13-07-12T06-20-12_c_-_U0E9su_c-bpe-training_nounicode-5000/vocab\n",
      "2019-08-26 12:10:53,589 [dataprep.infrastructure.stages] INFO: Vocabulary is already computed and up-to-date\n",
      "2019-08-26 12:10:53,589 [dataprep.api.corpus] INFO: Preprocessed dataset is ready at /tmp/scratch/prep-datasets/c-test_13-07-12T06-20-12_c_-_U0E9su_c-bpe-training_nounicode-5000_-_prep\n",
      "2019-08-26 12:10:53,602 [vocabstudy.common] DEBUG: Checking if train dataset exists: /tmp/scratch/prep-datasets/c-minus-test_19-08-16T14-29-19_c_-_U0E9su_c-bpe-training_nounicode-5000_-_prep\n",
      "2019-08-26 12:10:53,603 [vocabstudy.common] INFO: Train dataset is found and is going to be removed to save space: /tmp/scratch/prep-datasets/c-minus-test_19-08-16T14-29-19_c_-_U0E9su_c-bpe-training_nounicode-5000_-_prep. Removing ...\n",
      "2019-08-26 12:10:53,604 [vocabstudy.common] INFO: Moving test dataset from tmp storage: /tmp/scratch/prep-datasets/c-test_13-07-12T06-20-12_c_-_U0E9su_c-bpe-training_nounicode-5000_-_prep -> /home/lv71161/hlibbabii/prep-datasets\n",
      "2019-08-26 12:10:53,605 [vocabstudy.common] WARNING: Not moving. Path already exists: /home/lv71161/hlibbabii/prep-datasets/c-test_13-07-12T06-20-12_c_-_U0E9su_c-bpe-training_nounicode-5000_-_prep\n",
      "\n",
      "========================   Split example   =========================\n",
      "\n",
      "2019-08-26 12:10:53,609 [dataprep.to_repr] INFO: Using bpe merges file: /home/lv71161/hlibbabii/.config/dataprep/1.0.0-alpha.8/bpe/c-bpe-training_13-07-12T06-23-32_c_-_nounicode/5000/merges.txt\n",
      "2019-08-26 12:10:53,637 [dataprep.to_repr] INFO: Using first 5000 merges.\n",
      "['void</t>', 'test_', 'W', 'ord', 'U', 'eb', 'err', 'as', 'chun', 'g', 'Pr', 'inter</t>', '(</t>', ')</t>', '{</t>', '\\n', '\\t', 'if</t>', '(</t>', 'e', 'ps</t>', '></t>', '=</t>', '0.', '3', '45', 'e+', '4</t>', ')</t>', '{</t>', '<comment>', '\\t', '\\t', 'print', 'W', 'ord</t>', '(</t>', '\"', '\"', ')</t>', ';</t>', '\\n', '\\t', '}</t>', '\\n', '}</t>']\n",
      "\n",
      "========================   Stats           =========================\n",
      "\n",
      "Train vocab: 5358\n",
      "Test vocab : 4985, identifiers: 2824 (0.57%)\n",
      "\n",
      "Train corpus size: 3868044998\n",
      "Test corpus size : 40670840, identifiers: 10071931 (0.25%)\n",
      "\n",
      "OOV in test set (top 9223372036854775807): 0 (0.00%), oov tokens number: 0 (0.00%)\n",
      "OOV in test set (top 200000): 0 (0.00%), oov tokens number: 0 (0.00%)\n",
      "OOV in test set (top 100000): 0 (0.00%), oov tokens number: 0 (0.00%)\n",
      "OOV in test set (top 75000): 0 (0.00%), oov tokens number: 0 (0.00%)\n",
      "OOV in test set (top 50000): 0 (0.00%), oov tokens number: 0 (0.00%)\n",
      "OOV in test set (top 25000): 0 (0.00%), oov tokens number: 0 (0.00%)\n",
      "Variation coeff: 2.1556921407105194e-05\n",
      "[19, 47, 58, 48, 5186]\n"
     ]
    }
   ],
   "source": [
    "prep_function = PrepFunction(api.bpe, ['c-bpe-training_nounicode-5000'], {\"no_com\": True, \"max_str_length\": 14, \"no_unicode\": True})\n",
    "description = \"bpe 5k Hellendoorn and Devanbu strings no comments no unicode \"\n",
    "run(prep_function, description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bpe 10k Hellendoorn and Devanbu strings no comments no unicode \n",
      "\n",
      "2019-08-26 12:10:53,778 [dataprep.infrastructure.stages] INFO: Checking first if vocabulary file exists: /home/lv71161/hlibbabii/.config/dataprep/1.0.0-alpha.8/vocab/c-minus-test_19-08-16T14-29-19_c_-_U0E9su_c-bpe-training_nounicode-10000/vocab\n",
      "2019-08-26 12:10:53,779 [dataprep.infrastructure.stages] INFO: Vocabulary is already computed and up-to-date\n",
      "2019-08-26 12:10:53,780 [dataprep.api.corpus] INFO: Preprocessed dataset is ready at /tmp/scratch/prep-datasets/c-minus-test_19-08-16T14-29-19_c_-_U0E9su_c-bpe-training_nounicode-10000_-_prep\n",
      "2019-08-26 12:10:53,849 [dataprep.infrastructure.stages] INFO: Checking first if vocabulary file exists: /home/lv71161/hlibbabii/.config/dataprep/1.0.0-alpha.8/vocab/c-test_13-07-12T06-20-12_c_-_U0E9su_c-bpe-training_nounicode-10000/vocab\n",
      "2019-08-26 12:10:53,849 [dataprep.infrastructure.stages] INFO: Vocabulary is already computed and up-to-date\n",
      "2019-08-26 12:10:53,850 [dataprep.api.corpus] INFO: Preprocessed dataset is ready at /tmp/scratch/prep-datasets/c-test_13-07-12T06-20-12_c_-_U0E9su_c-bpe-training_nounicode-10000_-_prep\n",
      "2019-08-26 12:10:53,873 [vocabstudy.common] DEBUG: Checking if train dataset exists: /tmp/scratch/prep-datasets/c-minus-test_19-08-16T14-29-19_c_-_U0E9su_c-bpe-training_nounicode-10000_-_prep\n",
      "2019-08-26 12:10:53,874 [vocabstudy.common] INFO: Train dataset is found and is going to be removed to save space: /tmp/scratch/prep-datasets/c-minus-test_19-08-16T14-29-19_c_-_U0E9su_c-bpe-training_nounicode-10000_-_prep. Removing ...\n",
      "2019-08-26 12:10:53,876 [vocabstudy.common] INFO: Moving test dataset from tmp storage: /tmp/scratch/prep-datasets/c-test_13-07-12T06-20-12_c_-_U0E9su_c-bpe-training_nounicode-10000_-_prep -> /home/lv71161/hlibbabii/prep-datasets\n",
      "2019-08-26 12:10:53,877 [vocabstudy.common] WARNING: Not moving. Path already exists: /home/lv71161/hlibbabii/prep-datasets/c-test_13-07-12T06-20-12_c_-_U0E9su_c-bpe-training_nounicode-10000_-_prep\n",
      "\n",
      "========================   Split example   =========================\n",
      "\n",
      "2019-08-26 12:10:53,881 [dataprep.to_repr] INFO: Using bpe merges file: /home/lv71161/hlibbabii/.config/dataprep/1.0.0-alpha.8/bpe/c-bpe-training_13-07-12T06-23-32_c_-_nounicode/10000/merges.txt\n",
      "2019-08-26 12:10:53,934 [dataprep.to_repr] INFO: Using first 10000 merges.\n",
      "['void</t>', 'test_', 'W', 'ord', 'U', 'eb', 'err', 'as', 'chun', 'g', 'Pr', 'inter</t>', '(</t>', ')</t>', '{</t>', '\\n', '\\t', 'if</t>', '(</t>', 'e', 'ps</t>', '></t>', '=</t>', '0.3', '45', 'e+', '4</t>', ')</t>', '{</t>', '<comment>', '\\t', '\\t', 'print', 'W', 'ord</t>', '(</t>', '\"', '\"', ')</t>', ';</t>', '\\n', '\\t', '}</t>', '\\n', '}</t>']\n",
      "\n",
      "========================   Stats           =========================\n",
      "\n",
      "Train vocab: 10338\n",
      "Test vocab : 9343, identifiers: 5059 (0.54%)\n",
      "\n",
      "Train corpus size: 3626805509\n",
      "Test corpus size : 37991089, identifiers: 7678266 (0.20%)\n",
      "\n",
      "OOV in test set (top 9223372036854775807): 0 (0.00%), oov tokens number: 0 (0.00%)\n",
      "OOV in test set (top 200000): 0 (0.00%), oov tokens number: 0 (0.00%)\n",
      "OOV in test set (top 100000): 0 (0.00%), oov tokens number: 0 (0.00%)\n",
      "OOV in test set (top 75000): 0 (0.00%), oov tokens number: 0 (0.00%)\n",
      "OOV in test set (top 50000): 0 (0.00%), oov tokens number: 0 (0.00%)\n",
      "OOV in test set (top 25000): 0 (0.00%), oov tokens number: 0 (0.00%)\n",
      "Variation coeff: 2.137796819093209e-05\n",
      "[19, 49, 68, 87, 10115]\n"
     ]
    }
   ],
   "source": [
    "prep_function = PrepFunction(api.bpe, ['c-bpe-training_nounicode-10000'], {\"no_com\": True, \"max_str_length\": 14, \"no_unicode\": True})\n",
    "description = \"bpe 10k Hellendoorn and Devanbu strings no comments no unicode \"\n",
    "run(prep_function, description)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "metrics",
   "language": "python",
   "name": "metrics"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
