{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataprep.api.corpus as api\n",
    "import keyword\n",
    "from vocabstudy.common import PrepFunction, calc_and_display_stats\n",
    "PYTHON_KEYWORDS = keyword.kwlist\n",
    "\n",
    "PYTHON_DATASETS = ('rafael/python-minus-test',\n",
    "            'rafael/python-test'\n",
    "           )\n",
    "\n",
    "def run(prep_function: PrepFunction, description: str) -> None:\n",
    "    calc_and_display_stats(prep_function, description, PYTHON_DATASETS, PYTHON_KEYWORDS, 'py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.0.0-alpha.8'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dataprep\n",
    "\n",
    "dataprep.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unsplit, with comments and vocabulary. No filtering.\n",
      "\n",
      "2019-08-16 11:22:22,693 [dataprep.infrastructure.stages] INFO: Checking first if vocabulary file exists: /home/lv71161/hlibbabii/.config/dataprep/1.0.0-alpha.8/vocab/python-minus-test_15-07-11T19-11-25_py_-_uc10su/vocab\n",
      "2019-08-16 11:22:22,725 [dataprep.infrastructure.stages] INFO: Vocabulary is already computed and up-to-date\n",
      "2019-08-16 11:22:22,726 [dataprep.api.corpus] INFO: Preprocessed dataset is ready at /home/lv71161/hlibbabii/prep-datasets/python-minus-test_15-07-11T19-11-25_py_-_uc10su_-_prep\n",
      "2019-08-16 11:23:12,256 [dataprep.infrastructure.stages] INFO: Checking first if vocabulary file exists: /home/lv71161/hlibbabii/.config/dataprep/1.0.0-alpha.8/vocab/python-test_15-07-11T19-08-23_py_-_uc10su/vocab\n",
      "2019-08-16 11:23:12,270 [dataprep.infrastructure.stages] INFO: Vocabulary is already computed and up-to-date\n",
      "2019-08-16 11:23:12,271 [dataprep.api.corpus] INFO: Preprocessed dataset is ready at /home/lv71161/hlibbabii/prep-datasets/python-test_15-07-11T19-08-23_py_-_uc10su_-_prep\n",
      "Removing prepped dataset at /home/lv71161/hlibbabii/prep-datasets/python-minus-test_15-07-11T19-11-25_py_-_uc10su_-_prep\n",
      "\n",
      "========================   Split example   =========================\n",
      "\n",
      "['void', 'test_WordUeberraschungPrinter', '(', ')', '{', '\\n', '\\t', 'if', '(', 'eps', '>', '=', '0.345e+4', ')', '{', '/', '/', 'FIXME', '10l', '\\n', '<EOL>', '\\t', '\\t', 'printWord', '(', '\"', '.', '.', '.', 'Ãœberraschung', '0x12', '\"', ')', ';', '\\n', '\\t', '}', '\\n', '}']\n",
      "\n",
      "========================   Stats           =========================\n",
      "\n",
      "Train vocab: 15983347\n",
      "Test vocab : 414860, identifiers: 370968 (0.89%)\n",
      "\n",
      "Train corpus size: 2863151236\n",
      "Test corpus size : 37368820, identifiers: 11323692 (0.30%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prep_function = PrepFunction(api.nosplit, [], {\"no_unicode\": True})\n",
    "description = \"unsplit, with comments and vocabulary. Filtering non-ascii.\"\n",
    "\n",
    "run(prep_function, description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_function = PrepFunction(api.nosplit, [], {\"no_unicode\": True, \"no_spaces\": True, \"no_com\": True})\n",
    "description = \"Filtering  comments ( + whitespace, + non-ascii)\"\n",
    "\n",
    "run(prep_function, description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_function = PrepFunction(api.nosplit, [], {\"no_com\": True, \"full_strings\": True, \"max_str_length\": 14})\n",
    "description = \"An additional choice, the model from Hellendoorn and Devanbu: keep strings shorter than 15 char (check SLP-core code), remove others, remove comments\"\n",
    "\n",
    "run(prep_function, description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_function = PrepFunction(api.basic, [],\n",
    "                             {\"no_unicode\": True, \"no_spaces\": True, \"no_com\": True, \"max_str_length\": 14})\n",
    "description = \"[Unsplit, remove non-ascii, remove whitespace, remove comments, remove strings longer than 15 chars] + Word splitting via conventions\"\n",
    "\n",
    "run(prep_function, description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_function = PrepFunction(api.basic, [],\n",
    "                             {\"no_unicode\": True, \"no_spaces\": True, \"no_com\": True, \"max_str_length\": 14,\n",
    "                              \"no_case\": True, \"split_numbers\": True, \"ronin\": True})\n",
    "description = \"[Unsplit, remove non-ascii, remove whitespace, remove comments, remove strings longer than 15 chars] + split via conventions, but keep case. + Split numbers + Ronin\"\n",
    "run(prep_function, description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_function = PrepFunction(api.bpe, ['python-bpe-training_nounicode-2000'], {\"no_com\": True, \"max_str_length\": 14})\n",
    "description = \"bpe 2k Hellendoorn and Devanbu strings no comments\"\n",
    "run(prep_function, description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_function = PrepFunction(api.bpe, ['python-bpe-training_nounicode-5000'], {\"no_com\": True, \"max_str_length\": 14})\n",
    "description = \"bpe 5k Hellendoorn and Devanbu strings no comments\"\n",
    "run(prep_function, description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_function = PrepFunction(api.bpe, ['python-bpe-training_nounicode-10000'], {\"no_com\": True, \"max_str_length\": 14})\n",
    "description = \"bpe 10k Hellendoorn and Devanbu strings no comments\"\n",
    "run(prep_function, description)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
