{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataprep.api.corpus as api\n",
    "import os\n",
    "from vocabstudy.common import PrepFunction, calc_and_display_stats, VocabStatsCsvWriter, HEADER, HOME\n",
    "import keyword\n",
    "PYTHON_KEYWORDS = keyword.kwlist\n",
    "\n",
    "PYTHON_DATASETS = ('rafael/python-minus-test',\n",
    "            'rafael/python-test'\n",
    "           )\n",
    "\n",
    "writer = VocabStatsCsvWriter(os.path.join(HOME, 'python-stats.csv'), HEADER)\n",
    "\n",
    "def run(prep_function: PrepFunction, description: str) -> None:\n",
    "    row = calc_and_display_stats(prep_function, description, PYTHON_DATASETS, PYTHON_KEYWORDS, 'py')\n",
    "    writer.write_line(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.0.0-alpha.8'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dataprep\n",
    "\n",
    "dataprep.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unsplit, with comments and vocabulary. Filtering non-ascii.\n",
      "\n",
      "2019-08-21 18:02:19,120 [dataprep.infrastructure.stages] INFO: Checking first if vocabulary file exists: /home/lv71161/hlibbabii/.config/dataprep/1.0.0-alpha.8/vocab/python-minus-test_19-08-16T13-44-40_py_-_Uc10su/vocab\n",
      "2019-08-21 18:02:19,122 [dataprep.infrastructure.stages] INFO: Vocabulary is already computed and up-to-date\n",
      "2019-08-21 18:02:19,123 [dataprep.api.corpus] INFO: Preprocessed dataset is ready at /tmp/scratch/prep-datasets/python-minus-test_19-08-16T13-44-40_py_-_Uc10su_-_prep\n",
      "2019-08-21 18:03:02,271 [dataprep.infrastructure.stages] INFO: Checking first if vocabulary file exists: /home/lv71161/hlibbabii/.config/dataprep/1.0.0-alpha.8/vocab/python-test_15-07-11T19-08-23_py_-_Uc10su/vocab\n",
      "2019-08-21 18:03:02,275 [dataprep.infrastructure.stages] INFO: Vocabulary is already computed and up-to-date\n",
      "2019-08-21 18:03:02,276 [dataprep.api.corpus] INFO: Preprocessed dataset is ready at /tmp/scratch/prep-datasets/python-test_15-07-11T19-08-23_py_-_Uc10su_-_prep\n",
      "2019-08-21 18:03:03,317 [vocabstudy.common] DEBUG: Checking if train dataset exists: /tmp/scratch/prep-datasets/python-minus-test_19-08-16T13-44-40_py_-_Uc10su_-_prep\n",
      "2019-08-21 18:03:03,319 [vocabstudy.common] INFO: Train dataset is found and is going to be removed to save space: /tmp/scratch/prep-datasets/python-minus-test_19-08-16T13-44-40_py_-_Uc10su_-_prep. Removing ...\n",
      "2019-08-21 18:03:03,321 [vocabstudy.common] INFO: Moving test dataset from tmp storage: /tmp/scratch/prep-datasets/python-test_15-07-11T19-08-23_py_-_Uc10su_-_prep -> /home/lv71161/hlibbabii/prep-datasets\n",
      "2019-08-21 18:03:03,323 [vocabstudy.common] WARNING: Not moving. Path already exists: /home/lv71161/hlibbabii/prep-datasets/python-test_15-07-11T19-08-23_py_-_Uc10su_-_prep\n",
      "\n",
      "========================   Split example   =========================\n",
      "\n",
      "['void', 'test_WordUeberraschungPrinter', '(', ')', '{', '\\n', '\\t', 'if', '(', 'eps', '>', '=', '0.345e+4', ')', '{', '/', '/', 'FIXME', '10l', '\\n', '<EOL>', '\\t', '\\t', 'printWord', '(', '\"', '.', '.', '.', '<non-en>', '0x12', '\"', ')', ';', '\\n', '\\t', '}', '\\n', '}']\n",
      "\n",
      "========================   Stats           =========================\n",
      "\n",
      "Train vocab: 15493134\n",
      "Test vocab : 409380, identifiers: 367093 (0.90%)\n",
      "\n",
      "Train corpus size: 2863151236\n",
      "Test corpus size : 37368820, identifiers: 11315722 (0.30%)\n",
      "\n",
      "OOV in test set (top 9223372036854775807): 24447 (5.97%), oov tokens number: 97312 (0.26%)\n",
      "OOV in test set (top 200000): 305543 (74.64%), oov tokens number: 1082023 (2.90%)\n",
      "OOV in test set (top 100000): 342585 (83.68%), oov tokens number: 1389677 (3.72%)\n",
      "OOV in test set (top 75000): 354626 (86.63%), oov tokens number: 1529858 (4.09%)\n",
      "OOV in test set (top 50000): 368622 (90.04%), oov tokens number: 1756185 (4.70%)\n",
      "OOV in test set (top 25000): 387815 (94.73%), oov tokens number: 2146435 (5.74%)\n",
      "\n",
      "For identifiers: \n",
      "\n",
      "OOV in test set (top 9223372036854775807): 22946 (6.25%), oov tokens number: 94482 (0.83%)\n",
      "OOV in test set (top 200000): 280012 (76.28%), oov tokens number: 1044872 (9.23%)\n",
      "OOV in test set (top 100000): 312316 (85.08%), oov tokens number: 1336394 (11.81%)\n",
      "OOV in test set (top 75000): 323096 (88.01%), oov tokens number: 1471042 (13.00%)\n",
      "OOV in test set (top 50000): 336357 (91.63%), oov tokens number: 1692149 (14.95%)\n",
      "OOV in test set (top 25000): 348310 (94.88%), oov tokens number: 1981485 (17.51%)\n",
      "[5861936, 7454613, 1893531, 239006, 44048]\n"
     ]
    }
   ],
   "source": [
    "prep_function = PrepFunction(api.nosplit, [], {\"no_unicode\": True})\n",
    "description = \"unsplit, with comments and vocabulary. Filtering non-ascii.\"\n",
    "\n",
    "run(prep_function, description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering  comments ( + whitespace, + non-ascii)\n",
      "\n",
      "2019-08-21 18:03:50,470 [dataprep.infrastructure.stages] INFO: Checking first if vocabulary file exists: /home/lv71161/hlibbabii/.config/dataprep/1.0.0-alpha.8/vocab/python-minus-test_19-08-16T13-44-40_py_-_U0100u/vocab\n",
      "2019-08-21 18:03:50,472 [dataprep.infrastructure.stages] INFO: Vocabulary is already computed and up-to-date\n",
      "2019-08-21 18:03:50,473 [dataprep.api.corpus] INFO: Preprocessed dataset is ready at /tmp/scratch/prep-datasets/python-minus-test_19-08-16T13-44-40_py_-_U0100u_-_prep\n",
      "2019-08-21 18:04:31,181 [dataprep.infrastructure.stages] INFO: Checking first if vocabulary file exists: /home/lv71161/hlibbabii/.config/dataprep/1.0.0-alpha.8/vocab/python-test_15-07-11T19-08-23_py_-_U0100u/vocab\n",
      "2019-08-21 18:04:31,183 [dataprep.infrastructure.stages] INFO: Vocabulary is already computed and up-to-date\n",
      "2019-08-21 18:04:31,184 [dataprep.api.corpus] INFO: Preprocessed dataset is ready at /tmp/scratch/prep-datasets/python-test_15-07-11T19-08-23_py_-_U0100u_-_prep\n",
      "2019-08-21 18:04:32,240 [vocabstudy.common] DEBUG: Checking if train dataset exists: /tmp/scratch/prep-datasets/python-minus-test_19-08-16T13-44-40_py_-_U0100u_-_prep\n",
      "2019-08-21 18:04:32,242 [vocabstudy.common] INFO: Train dataset is found and is going to be removed to save space: /tmp/scratch/prep-datasets/python-minus-test_19-08-16T13-44-40_py_-_U0100u_-_prep. Removing ...\n",
      "2019-08-21 18:04:32,244 [vocabstudy.common] INFO: Moving test dataset from tmp storage: /tmp/scratch/prep-datasets/python-test_15-07-11T19-08-23_py_-_U0100u_-_prep -> /home/lv71161/hlibbabii/prep-datasets\n",
      "2019-08-21 18:04:32,245 [vocabstudy.common] WARNING: Not moving. Path already exists: /home/lv71161/hlibbabii/prep-datasets/python-test_15-07-11T19-08-23_py_-_U0100u_-_prep\n",
      "\n",
      "========================   Split example   =========================\n",
      "\n",
      "['void', 'test_WordUeberraschungPrinter', '(', ')', '{', 'if', '(', 'eps', '>', '=', '0.345e+4', ')', '{', '<comment>', 'printWord', '(', '\"', '.', '.', '.', '<non-en>', '0x12', '\"', ')', ';', '}', '}']\n",
      "\n",
      "========================   Stats           =========================\n",
      "\n",
      "Train vocab: 15207571\n",
      "Test vocab : 399500, identifiers: 358132 (0.90%)\n",
      "\n",
      "Train corpus size: 2037456204\n",
      "Test corpus size : 27787534, identifiers: 10134446 (0.36%)\n",
      "\n",
      "OOV in test set (top 9223372036854775807): 24081 (6.03%), oov tokens number: 95870 (0.35%)\n",
      "OOV in test set (top 200000): 297809 (74.55%), oov tokens number: 1047842 (3.77%)\n",
      "OOV in test set (top 100000): 333552 (83.49%), oov tokens number: 1341277 (4.83%)\n",
      "OOV in test set (top 75000): 345994 (86.61%), oov tokens number: 1471310 (5.29%)\n",
      "OOV in test set (top 50000): 359432 (89.97%), oov tokens number: 1683897 (6.06%)\n",
      "OOV in test set (top 25000): 378209 (94.67%), oov tokens number: 2048438 (7.37%)\n",
      "\n",
      "For identifiers: \n",
      "\n",
      "OOV in test set (top 9223372036854775807): 22651 (6.32%), oov tokens number: 93143 (0.92%)\n",
      "OOV in test set (top 200000): 273088 (76.25%), oov tokens number: 1012535 (9.99%)\n",
      "OOV in test set (top 100000): 304965 (85.15%), oov tokens number: 1292835 (12.76%)\n",
      "OOV in test set (top 75000): 315050 (87.97%), oov tokens number: 1413933 (13.95%)\n",
      "OOV in test set (top 50000): 328019 (91.59%), oov tokens number: 1623490 (16.02%)\n",
      "OOV in test set (top 25000): 339884 (94.90%), oov tokens number: 1896896 (18.72%)\n",
      "[5766902, 7332321, 1837961, 229356, 41031]\n"
     ]
    }
   ],
   "source": [
    "prep_function = PrepFunction(api.nosplit, [], {\"no_unicode\": True, \"no_spaces\": True, \"no_com\": True})\n",
    "description = \"Filtering  comments ( + whitespace, + non-ascii)\"\n",
    "\n",
    "run(prep_function, description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An additional choice, the model from Hellendoorn and Devanbu: keep strings shorter than 15 char (check SLP-core code), remove others, remove comments\n",
      "\n",
      "2019-08-21 18:05:17,830 [dataprep.infrastructure.stages] INFO: Checking first if vocabulary file exists: /home/lv71161/hlibbabii/.config/dataprep/1.0.0-alpha.8/vocab/python-minus-test_19-08-16T13-44-40_py_-_U0EF0u/vocab\n",
      "2019-08-21 18:05:17,831 [dataprep.infrastructure.stages] INFO: Vocabulary is already computed and up-to-date\n",
      "2019-08-21 18:05:17,831 [dataprep.api.corpus] INFO: Preprocessed dataset is ready at /tmp/scratch/prep-datasets/python-minus-test_19-08-16T13-44-40_py_-_U0EF0u_-_prep\n",
      "2019-08-21 18:05:55,694 [dataprep.infrastructure.stages] INFO: Checking first if vocabulary file exists: /home/lv71161/hlibbabii/.config/dataprep/1.0.0-alpha.8/vocab/python-test_15-07-11T19-08-23_py_-_U0EF0u/vocab\n",
      "2019-08-21 18:05:55,696 [dataprep.infrastructure.stages] INFO: Vocabulary is already computed and up-to-date\n",
      "2019-08-21 18:05:55,697 [dataprep.api.corpus] INFO: Preprocessed dataset is ready at /tmp/scratch/prep-datasets/python-test_15-07-11T19-08-23_py_-_U0EF0u_-_prep\n",
      "2019-08-21 18:05:56,746 [vocabstudy.common] DEBUG: Checking if train dataset exists: /tmp/scratch/prep-datasets/python-minus-test_19-08-16T13-44-40_py_-_U0EF0u_-_prep\n",
      "2019-08-21 18:05:56,747 [vocabstudy.common] INFO: Train dataset is found and is going to be removed to save space: /tmp/scratch/prep-datasets/python-minus-test_19-08-16T13-44-40_py_-_U0EF0u_-_prep. Removing ...\n",
      "2019-08-21 18:05:56,977 [vocabstudy.common] INFO: Moving test dataset from tmp storage: /tmp/scratch/prep-datasets/python-test_15-07-11T19-08-23_py_-_U0EF0u_-_prep -> /home/lv71161/hlibbabii/prep-datasets\n",
      "2019-08-21 18:05:56,979 [vocabstudy.common] WARNING: Not moving. Path already exists: /home/lv71161/hlibbabii/prep-datasets/python-test_15-07-11T19-08-23_py_-_U0EF0u_-_prep\n",
      "\n",
      "========================   Split example   =========================\n",
      "\n",
      "['void', 'test_WordUeberraschungPrinter', '(', ')', '{', 'if', '(', 'eps', '>', '=', '0.345e+4', ')', '{', '<comment>', 'printWord', '(', '\"\"', ')', ';', '}', '}']\n",
      "\n",
      "========================   Stats           =========================\n",
      "\n",
      "Train vocab: 14149544\n",
      "Test vocab : 382490, identifiers: 220348 (0.58%)\n",
      "\n",
      "Train corpus size: 1535917448\n",
      "Test corpus size : 18227038, identifiers: 4689008 (0.26%)\n",
      "\n",
      "OOV in test set (top 9223372036854775807): 26076 (6.82%), oov tokens number: 89034 (0.49%)\n",
      "OOV in test set (top 200000): 285253 (74.58%), oov tokens number: 794719 (4.36%)\n",
      "OOV in test set (top 100000): 319189 (83.45%), oov tokens number: 1005507 (5.52%)\n",
      "OOV in test set (top 75000): 332505 (86.93%), oov tokens number: 1099944 (6.03%)\n",
      "OOV in test set (top 50000): 344695 (90.12%), oov tokens number: 1239490 (6.80%)\n",
      "OOV in test set (top 25000): 361529 (94.52%), oov tokens number: 1508076 (8.27%)\n",
      "\n",
      "For identifiers: \n",
      "\n",
      "OOV in test set (top 9223372036854775807): 19201 (8.71%), oov tokens number: 77095 (1.64%)\n",
      "OOV in test set (top 200000): 156585 (71.06%), oov tokens number: 504820 (10.77%)\n",
      "OOV in test set (top 100000): 179316 (81.38%), oov tokens number: 671159 (14.31%)\n",
      "OOV in test set (top 75000): 185974 (84.40%), oov tokens number: 737759 (15.73%)\n",
      "OOV in test set (top 50000): 195726 (88.83%), oov tokens number: 858681 (18.31%)\n",
      "OOV in test set (top 25000): 206414 (93.68%), oov tokens number: 1053532 (22.47%)\n",
      "[5857782, 6535272, 1526830, 197443, 32217]\n"
     ]
    }
   ],
   "source": [
    "prep_function = PrepFunction(api.nosplit, [], {\"no_unicode\": True, \"no_spaces\": True, \"no_com\": True, \"full_strings\": True, \"max_str_length\": 14})\n",
    "description = \"An additional choice, the model from Hellendoorn and Devanbu: keep strings shorter than 15 char (check SLP-core code), remove others, remove comments\"\n",
    "\n",
    "run(prep_function, description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Unsplit, remove non-ascii, remove whitespace, remove comments, remove strings longer than 15 chars] + Word splitting via conventions\n",
      "\n",
      "2019-08-21 18:06:40,097 [dataprep.infrastructure.stages] INFO: Checking first if vocabulary file exists: /home/lv71161/hlibbabii/.config/dataprep/1.0.0-alpha.8/vocab/python-minus-test_19-08-16T13-44-40_py_-_U0E10u/vocab\n",
      "2019-08-21 18:06:40,098 [dataprep.infrastructure.stages] INFO: Vocabulary is already computed and up-to-date\n",
      "2019-08-21 18:06:40,098 [dataprep.api.corpus] INFO: Preprocessed dataset is ready at /tmp/scratch/prep-datasets/python-minus-test_19-08-16T13-44-40_py_-_U0E10u_-_prep\n",
      "2019-08-21 18:06:53,110 [dataprep.infrastructure.stages] INFO: Checking first if vocabulary file exists: /home/lv71161/hlibbabii/.config/dataprep/1.0.0-alpha.8/vocab/python-test_15-07-11T19-08-23_py_-_U0E10u/vocab\n",
      "2019-08-21 18:06:53,112 [dataprep.infrastructure.stages] INFO: Vocabulary is already computed and up-to-date\n",
      "2019-08-21 18:06:53,113 [dataprep.api.corpus] INFO: Preprocessed dataset is ready at /tmp/scratch/prep-datasets/python-test_15-07-11T19-08-23_py_-_U0E10u_-_prep\n",
      "2019-08-21 18:06:53,425 [vocabstudy.common] DEBUG: Checking if train dataset exists: /tmp/scratch/prep-datasets/python-minus-test_19-08-16T13-44-40_py_-_U0E10u_-_prep\n",
      "2019-08-21 18:06:53,427 [vocabstudy.common] INFO: Train dataset is found and is going to be removed to save space: /tmp/scratch/prep-datasets/python-minus-test_19-08-16T13-44-40_py_-_U0E10u_-_prep. Removing ...\n",
      "2019-08-21 18:06:53,429 [vocabstudy.common] INFO: Moving test dataset from tmp storage: /tmp/scratch/prep-datasets/python-test_15-07-11T19-08-23_py_-_U0E10u_-_prep -> /home/lv71161/hlibbabii/prep-datasets\n",
      "2019-08-21 18:06:53,430 [vocabstudy.common] WARNING: Not moving. Path already exists: /home/lv71161/hlibbabii/prep-datasets/python-test_15-07-11T19-08-23_py_-_U0E10u_-_prep\n",
      "\n",
      "========================   Split example   =========================\n",
      "\n",
      "['void', '<w>', 'test', '_', 'Word', 'Ueberraschung', 'Printer', '</w>', '(', ')', '{', 'if', '(', 'eps', '>', '=', '0.345e+4', ')', '{', '<comment>', '<w>', 'print', 'Word', '</w>', '(', '\"', '\"', ')', ';', '}', '}']\n",
      "\n",
      "========================   Stats           =========================\n",
      "\n",
      "Train vocab: 5085302\n",
      "Test vocab : 126253, identifiers: 90099 (0.71%)\n",
      "\n",
      "Train corpus size: 2350559745\n",
      "Test corpus size : 26171110, identifiers: 8088554 (0.31%)\n",
      "\n",
      "OOV in test set (top 9223372036854775807): 2981 (2.36%), oov tokens number: 18963 (0.07%)\n",
      "OOV in test set (top 200000): 51886 (41.10%), oov tokens number: 109339 (0.42%)\n",
      "OOV in test set (top 100000): 71001 (56.24%), oov tokens number: 179030 (0.68%)\n",
      "OOV in test set (top 75000): 77666 (61.52%), oov tokens number: 218836 (0.84%)\n",
      "OOV in test set (top 50000): 89105 (70.58%), oov tokens number: 291075 (1.11%)\n",
      "OOV in test set (top 25000): 104166 (82.51%), oov tokens number: 498635 (1.91%)\n",
      "\n",
      "For identifiers: \n",
      "\n",
      "OOV in test set (top 9223372036854775807): 2497 (2.77%), oov tokens number: 18183 (0.22%)\n",
      "OOV in test set (top 200000): 34370 (38.15%), oov tokens number: 87260 (1.08%)\n",
      "OOV in test set (top 100000): 51606 (57.28%), oov tokens number: 153032 (1.89%)\n",
      "OOV in test set (top 75000): 57617 (63.95%), oov tokens number: 190709 (2.36%)\n",
      "OOV in test set (top 50000): 64345 (71.42%), oov tokens number: 246132 (3.04%)\n",
      "OOV in test set (top 25000): 74626 (82.83%), oov tokens number: 398407 (4.93%)\n",
      "[2788935, 1775353, 408925, 81183, 30906]\n"
     ]
    }
   ],
   "source": [
    "prep_function = PrepFunction(api.basic, [],\n",
    "                             {\"no_unicode\": True, \"no_spaces\": True, \"no_com\": True, \"max_str_length\": 14})\n",
    "description = \"[Unsplit, remove non-ascii, remove whitespace, remove comments, remove strings longer than 15 chars] + Word splitting via conventions\"\n",
    "\n",
    "run(prep_function, description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Unsplit, remove non-ascii, remove whitespace, remove comments, remove strings longer than 15 chars] + split via conventions, but keep case. + Split numbers + Ronin\n",
      "\n",
      "2019-08-21 18:07:07,509 [dataprep.infrastructure.stages] INFO: Checking first if vocabulary file exists: /home/lv71161/hlibbabii/.config/dataprep/1.0.0-alpha.8/vocab/python-minus-test_19-08-16T13-44-40_py_-_U0E30l/vocab\n",
      "2019-08-21 18:07:07,520 [dataprep.infrastructure.stages] INFO: Vocabulary is already computed and up-to-date\n",
      "2019-08-21 18:07:07,521 [dataprep.api.corpus] INFO: Preprocessed dataset is ready at /tmp/scratch/prep-datasets/python-minus-test_19-08-16T13-44-40_py_-_U0E30l_-_prep\n",
      "2019-08-21 18:07:10,162 [dataprep.infrastructure.stages] INFO: Checking first if vocabulary file exists: /home/lv71161/hlibbabii/.config/dataprep/1.0.0-alpha.8/vocab/python-test_15-07-11T19-08-23_py_-_U0E30l/vocab\n",
      "2019-08-21 18:07:10,164 [dataprep.infrastructure.stages] INFO: Vocabulary is already computed and up-to-date\n",
      "2019-08-21 18:07:10,165 [dataprep.api.corpus] INFO: Preprocessed dataset is ready at /tmp/scratch/prep-datasets/python-test_15-07-11T19-08-23_py_-_U0E30l_-_prep\n",
      "2019-08-21 18:07:10,326 [vocabstudy.common] DEBUG: Checking if train dataset exists: /tmp/scratch/prep-datasets/python-minus-test_19-08-16T13-44-40_py_-_U0E30l_-_prep\n",
      "2019-08-21 18:07:10,327 [vocabstudy.common] INFO: Train dataset is found and is going to be removed to save space: /tmp/scratch/prep-datasets/python-minus-test_19-08-16T13-44-40_py_-_U0E30l_-_prep. Removing ...\n",
      "2019-08-21 18:07:10,329 [vocabstudy.common] INFO: Moving test dataset from tmp storage: /tmp/scratch/prep-datasets/python-test_15-07-11T19-08-23_py_-_U0E30l_-_prep -> /home/lv71161/hlibbabii/prep-datasets\n",
      "2019-08-21 18:07:10,331 [vocabstudy.common] WARNING: Not moving. Path already exists: /home/lv71161/hlibbabii/prep-datasets/python-test_15-07-11T19-08-23_py_-_U0E30l_-_prep\n",
      "\n",
      "========================   Split example   =========================\n",
      "\n",
      "['void', '<w>', 'test', '_', '<Cap>', 'word', '<Cap>', 'ueberraschung', '<Cap>', 'printer', '</w>', '(', ')', '{', 'if', '(', 'eps', '>', '=', '<w>', '0', '.', '3', '4', '5', 'e', '+', '4', '</w>', ')', '{', '<comment>', '<w>', 'print', '<Cap>', 'word', '</w>', '(', '\"', '\"', ')', ';', '}', '}']\n",
      "\n",
      "========================   Stats           =========================\n",
      "\n",
      "Train vocab: 977202\n",
      "Test vocab : 56594, identifiers: 44923 (0.79%)\n",
      "\n",
      "Train corpus size: 2807036704\n",
      "Test corpus size : 29757092, identifiers: 8616647 (0.29%)\n",
      "\n",
      "OOV in test set (top 9223372036854775807): 703 (1.24%), oov tokens number: 5563 (0.02%)\n",
      "OOV in test set (top 200000): 2760 (4.88%), oov tokens number: 10888 (0.04%)\n",
      "OOV in test set (top 100000): 13798 (24.38%), oov tokens number: 26578 (0.09%)\n",
      "OOV in test set (top 75000): 17598 (31.10%), oov tokens number: 34936 (0.12%)\n",
      "OOV in test set (top 50000): 26249 (46.38%), oov tokens number: 61557 (0.21%)\n",
      "OOV in test set (top 25000): 38679 (68.34%), oov tokens number: 115627 (0.39%)\n",
      "\n",
      "For identifiers: \n",
      "\n",
      "OOV in test set (top 9223372036854775807): 699 (1.56%), oov tokens number: 5551 (0.06%)\n",
      "OOV in test set (top 200000): 2732 (6.08%), oov tokens number: 10841 (0.13%)\n",
      "OOV in test set (top 100000): 13456 (29.95%), oov tokens number: 26192 (0.30%)\n",
      "OOV in test set (top 75000): 17110 (38.09%), oov tokens number: 34291 (0.40%)\n",
      "OOV in test set (top 50000): 22582 (50.27%), oov tokens number: 51399 (0.60%)\n",
      "OOV in test set (top 25000): 28966 (64.48%), oov tokens number: 85727 (0.99%)\n",
      "[325628, 487288, 113315, 35940, 15031]\n"
     ]
    }
   ],
   "source": [
    "prep_function = PrepFunction(api.basic, [],\n",
    "                             {\"no_unicode\": True, \"no_spaces\": True, \"no_com\": True, \"max_str_length\": 14,\n",
    "                              \"no_case\": True, \"split_numbers\": True, \"ronin\": True})\n",
    "description = \"[Unsplit, remove non-ascii, remove whitespace, remove comments, remove strings longer than 15 chars] + split via conventions, but keep case. + Split numbers + Ronin\"\n",
    "run(prep_function, description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bpe 2k Hellendoorn and Devanbu strings no comments no unicode \n",
      "\n",
      "2019-08-21 18:07:14,624 [dataprep.infrastructure.stages] INFO: Checking first if vocabulary file exists: /home/lv71161/hlibbabii/.config/dataprep/1.0.0-alpha.8/vocab/python-minus-test_19-08-16T13-44-40_py_-_U0E9su_python-bpe-training_nounicode-2000/vocab\n",
      "2019-08-21 18:07:14,626 [dataprep.infrastructure.stages] INFO: Vocabulary is already computed and up-to-date\n",
      "2019-08-21 18:07:14,627 [dataprep.api.corpus] INFO: Preprocessed dataset is ready at /tmp/scratch/prep-datasets/python-minus-test_19-08-16T13-44-40_py_-_U0E9su_python-bpe-training_nounicode-2000_-_prep\n",
      "2019-08-21 18:07:14,704 [dataprep.infrastructure.stages] INFO: Checking first if vocabulary file exists: /home/lv71161/hlibbabii/.config/dataprep/1.0.0-alpha.8/vocab/python-test_15-07-11T19-08-23_py_-_U0E9su_python-bpe-training_nounicode-2000/vocab\n",
      "2019-08-21 18:07:14,706 [dataprep.infrastructure.stages] INFO: Vocabulary is already computed and up-to-date\n",
      "2019-08-21 18:07:14,707 [dataprep.api.corpus] INFO: Preprocessed dataset is ready at /tmp/scratch/prep-datasets/python-test_15-07-11T19-08-23_py_-_U0E9su_python-bpe-training_nounicode-2000_-_prep\n",
      "2019-08-21 18:07:14,742 [vocabstudy.common] DEBUG: Checking if train dataset exists: /tmp/scratch/prep-datasets/python-minus-test_19-08-16T13-44-40_py_-_U0E9su_python-bpe-training_nounicode-2000_-_prep\n",
      "2019-08-21 18:07:14,743 [vocabstudy.common] INFO: Train dataset is found and is going to be removed to save space: /tmp/scratch/prep-datasets/python-minus-test_19-08-16T13-44-40_py_-_U0E9su_python-bpe-training_nounicode-2000_-_prep. Removing ...\n",
      "2019-08-21 18:07:14,745 [vocabstudy.common] INFO: Moving test dataset from tmp storage: /tmp/scratch/prep-datasets/python-test_15-07-11T19-08-23_py_-_U0E9su_python-bpe-training_nounicode-2000_-_prep -> /home/lv71161/hlibbabii/prep-datasets\n",
      "2019-08-21 18:07:14,747 [vocabstudy.common] WARNING: Not moving. Path already exists: /home/lv71161/hlibbabii/prep-datasets/python-test_15-07-11T19-08-23_py_-_U0E9su_python-bpe-training_nounicode-2000_-_prep\n",
      "\n",
      "========================   Split example   =========================\n",
      "\n",
      "2019-08-21 18:07:14,752 [dataprep.to_repr] INFO: Using bpe merges file: /home/lv71161/hlibbabii/.config/dataprep/1.0.0-alpha.8/bpe/python-bpe-training_15-07-12T15-41-46_py_-_nounicode/2000/merges.txt\n",
      "2019-08-21 18:07:14,781 [dataprep.to_repr] INFO: Using first 2000 merges.\n",
      "['void</t>', 'test_', 'W', 'ord', 'U', 'e', 'b', 'err', 'as', 'ch', 'un', 'g', 'P', 'r', 'in', 'ter</t>', '(</t>', ')</t>', '{</t>', '\\n', '\\t', 'if</t>', '(</t>', 'ep', 's</t>', '></t>', '=</t>', '0.', '3', '45', 'e', '+', '4</t>', ')</t>', '{</t>', '<comment>', '\\t', '\\t', 'pr', 'int', 'W', 'ord</t>', '(</t>', '\"', '\"', ')</t>', ';</t>', '\\n', '\\t', '}</t>', '\\n', '}</t>']\n",
      "\n",
      "========================   Stats           =========================\n",
      "\n",
      "Train vocab: 2293\n",
      "Test vocab : 2115, identifiers: 1050 (0.50%)\n",
      "\n",
      "Train corpus size: 3008636821\n",
      "Test corpus size : 34398712, identifiers: 7185874 (0.21%)\n",
      "\n",
      "OOV in test set (top 9223372036854775807): 0 (0.00%), oov tokens number: 0 (0.00%)\n",
      "OOV in test set (top 200000): 0 (0.00%), oov tokens number: 0 (0.00%)\n",
      "OOV in test set (top 100000): 0 (0.00%), oov tokens number: 0 (0.00%)\n",
      "OOV in test set (top 75000): 0 (0.00%), oov tokens number: 0 (0.00%)\n",
      "OOV in test set (top 50000): 0 (0.00%), oov tokens number: 0 (0.00%)\n",
      "OOV in test set (top 25000): 0 (0.00%), oov tokens number: 0 (0.00%)\n",
      "\n",
      "For identifiers: \n",
      "\n",
      "OOV in test set (top 9223372036854775807): 0 (0.00%), oov tokens number: 0 (0.00%)\n",
      "OOV in test set (top 200000): 0 (0.00%), oov tokens number: 0 (0.00%)\n",
      "OOV in test set (top 100000): 0 (0.00%), oov tokens number: 0 (0.00%)\n",
      "OOV in test set (top 75000): 0 (0.00%), oov tokens number: 0 (0.00%)\n",
      "OOV in test set (top 50000): 0 (0.00%), oov tokens number: 0 (0.00%)\n",
      "OOV in test set (top 25000): 0 (0.00%), oov tokens number: 0 (0.00%)\n",
      "[25, 9, 31, 10, 2218]\n"
     ]
    }
   ],
   "source": [
    "prep_function = PrepFunction(api.bpe, ['python-bpe-training_nounicode-2000'], {\"no_com\": True, \"max_str_length\": 14, \"no_unicode\": True})\n",
    "description = \"bpe 2k Hellendoorn and Devanbu strings no comments no unicode \"\n",
    "run(prep_function, description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bpe 5k Hellendoorn and Devanbu strings no comments no unicode\n",
      "\n",
      "2019-08-21 18:07:14,888 [dataprep.infrastructure.stages] INFO: Checking first if vocabulary file exists: /home/lv71161/hlibbabii/.config/dataprep/1.0.0-alpha.8/vocab/python-minus-test_19-08-16T13-44-40_py_-_U0E9su_python-bpe-training_nounicode-5000/vocab\n",
      "2019-08-21 18:07:14,911 [dataprep.infrastructure.stages] INFO: Vocabulary is already computed and up-to-date\n",
      "2019-08-21 18:07:14,912 [dataprep.api.corpus] INFO: Preprocessed dataset is ready at /tmp/scratch/prep-datasets/python-minus-test_19-08-16T13-44-40_py_-_U0E9su_python-bpe-training_nounicode-5000_-_prep\n",
      "2019-08-21 18:07:14,998 [dataprep.infrastructure.stages] INFO: Checking first if vocabulary file exists: /home/lv71161/hlibbabii/.config/dataprep/1.0.0-alpha.8/vocab/python-test_15-07-11T19-08-23_py_-_U0E9su_python-bpe-training_nounicode-5000/vocab\n",
      "2019-08-21 18:07:15,000 [dataprep.infrastructure.stages] INFO: Vocabulary is already computed and up-to-date\n",
      "2019-08-21 18:07:15,001 [dataprep.api.corpus] INFO: Preprocessed dataset is ready at /tmp/scratch/prep-datasets/python-test_15-07-11T19-08-23_py_-_U0E9su_python-bpe-training_nounicode-5000_-_prep\n",
      "2019-08-21 18:07:15,033 [vocabstudy.common] DEBUG: Checking if train dataset exists: /tmp/scratch/prep-datasets/python-minus-test_19-08-16T13-44-40_py_-_U0E9su_python-bpe-training_nounicode-5000_-_prep\n",
      "2019-08-21 18:07:15,034 [vocabstudy.common] INFO: Train dataset is found and is going to be removed to save space: /tmp/scratch/prep-datasets/python-minus-test_19-08-16T13-44-40_py_-_U0E9su_python-bpe-training_nounicode-5000_-_prep. Removing ...\n",
      "2019-08-21 18:07:15,036 [vocabstudy.common] INFO: Moving test dataset from tmp storage: /tmp/scratch/prep-datasets/python-test_15-07-11T19-08-23_py_-_U0E9su_python-bpe-training_nounicode-5000_-_prep -> /home/lv71161/hlibbabii/prep-datasets\n",
      "2019-08-21 18:07:15,037 [vocabstudy.common] WARNING: Not moving. Path already exists: /home/lv71161/hlibbabii/prep-datasets/python-test_15-07-11T19-08-23_py_-_U0E9su_python-bpe-training_nounicode-5000_-_prep\n",
      "\n",
      "========================   Split example   =========================\n",
      "\n",
      "2019-08-21 18:07:15,042 [dataprep.to_repr] INFO: Using bpe merges file: /home/lv71161/hlibbabii/.config/dataprep/1.0.0-alpha.8/bpe/python-bpe-training_15-07-12T15-41-46_py_-_nounicode/5000/merges.txt\n",
      "2019-08-21 18:07:15,140 [dataprep.to_repr] INFO: Using first 5000 merges.\n",
      "['void</t>', 'test_', 'W', 'ord', 'U', 'e', 'b', 'err', 'as', 'chun', 'g', 'P', 'r', 'inter</t>', '(</t>', ')</t>', '{</t>', '\\n', '\\t', 'if</t>', '(</t>', 'ep', 's</t>', '></t>', '=</t>', '0.3', '45', 'e+', '4</t>', ')</t>', '{</t>', '<comment>', '\\t', '\\t', 'print', 'Word</t>', '(</t>', '\"', '\"', ')</t>', ';</t>', '\\n', '\\t', '}</t>', '\\n', '}</t>']\n",
      "\n",
      "========================   Stats           =========================\n",
      "\n",
      "Train vocab: 5274\n",
      "Test vocab : 5009, identifiers: 2459 (0.49%)\n",
      "\n",
      "Train corpus size: 2750132850\n",
      "Test corpus size : 31785842, identifiers: 4862292 (0.15%)\n",
      "\n",
      "OOV in test set (top 9223372036854775807): 0 (0.00%), oov tokens number: 0 (0.00%)\n",
      "OOV in test set (top 200000): 0 (0.00%), oov tokens number: 0 (0.00%)\n",
      "OOV in test set (top 100000): 0 (0.00%), oov tokens number: 0 (0.00%)\n",
      "OOV in test set (top 75000): 0 (0.00%), oov tokens number: 0 (0.00%)\n",
      "OOV in test set (top 50000): 0 (0.00%), oov tokens number: 0 (0.00%)\n",
      "OOV in test set (top 25000): 0 (0.00%), oov tokens number: 0 (0.00%)\n",
      "\n",
      "For identifiers: \n",
      "\n",
      "OOV in test set (top 9223372036854775807): 0 (0.00%), oov tokens number: 0 (0.00%)\n",
      "OOV in test set (top 200000): 0 (0.00%), oov tokens number: 0 (0.00%)\n",
      "OOV in test set (top 100000): 0 (0.00%), oov tokens number: 0 (0.00%)\n",
      "OOV in test set (top 75000): 0 (0.00%), oov tokens number: 0 (0.00%)\n",
      "OOV in test set (top 50000): 0 (0.00%), oov tokens number: 0 (0.00%)\n",
      "OOV in test set (top 25000): 0 (0.00%), oov tokens number: 0 (0.00%)\n",
      "[25, 10, 35, 38, 5166]\n"
     ]
    }
   ],
   "source": [
    "prep_function = PrepFunction(api.bpe, ['python-bpe-training_nounicode-5000'], {\"no_com\": True, \"max_str_length\": 14, \"no_unicode\": True})\n",
    "description = \"bpe 5k Hellendoorn and Devanbu strings no comments no unicode\"\n",
    "run(prep_function, description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bpe 10k Hellendoorn and Devanbu strings no comments no unicode\n",
      "\n",
      "2019-08-21 18:07:15,291 [dataprep.infrastructure.stages] INFO: Checking first if vocabulary file exists: /home/lv71161/hlibbabii/.config/dataprep/1.0.0-alpha.8/vocab/python-minus-test_19-08-16T13-44-40_py_-_U0E9su_python-bpe-training_nounicode-10000/vocab\n",
      "2019-08-21 18:07:15,292 [dataprep.infrastructure.stages] INFO: Vocabulary is already computed and up-to-date\n",
      "2019-08-21 18:07:15,294 [dataprep.api.corpus] INFO: Preprocessed dataset is ready at /tmp/scratch/prep-datasets/python-minus-test_19-08-16T13-44-40_py_-_U0E9su_python-bpe-training_nounicode-10000_-_prep\n",
      "2019-08-21 18:07:15,458 [dataprep.infrastructure.stages] INFO: Checking first if vocabulary file exists: /home/lv71161/hlibbabii/.config/dataprep/1.0.0-alpha.8/vocab/python-test_15-07-11T19-08-23_py_-_U0E9su_python-bpe-training_nounicode-10000/vocab\n",
      "2019-08-21 18:07:15,460 [dataprep.infrastructure.stages] INFO: Vocabulary is already computed and up-to-date\n",
      "2019-08-21 18:07:15,461 [dataprep.api.corpus] INFO: Preprocessed dataset is ready at /tmp/scratch/prep-datasets/python-test_15-07-11T19-08-23_py_-_U0E9su_python-bpe-training_nounicode-10000_-_prep\n",
      "2019-08-21 18:07:15,521 [vocabstudy.common] DEBUG: Checking if train dataset exists: /tmp/scratch/prep-datasets/python-minus-test_19-08-16T13-44-40_py_-_U0E9su_python-bpe-training_nounicode-10000_-_prep\n",
      "2019-08-21 18:07:15,522 [vocabstudy.common] INFO: Train dataset is found and is going to be removed to save space: /tmp/scratch/prep-datasets/python-minus-test_19-08-16T13-44-40_py_-_U0E9su_python-bpe-training_nounicode-10000_-_prep. Removing ...\n",
      "2019-08-21 18:07:15,524 [vocabstudy.common] INFO: Moving test dataset from tmp storage: /tmp/scratch/prep-datasets/python-test_15-07-11T19-08-23_py_-_U0E9su_python-bpe-training_nounicode-10000_-_prep -> /home/lv71161/hlibbabii/prep-datasets\n",
      "2019-08-21 18:07:15,526 [vocabstudy.common] WARNING: Not moving. Path already exists: /home/lv71161/hlibbabii/prep-datasets/python-test_15-07-11T19-08-23_py_-_U0E9su_python-bpe-training_nounicode-10000_-_prep\n",
      "\n",
      "========================   Split example   =========================\n",
      "\n",
      "2019-08-21 18:07:15,531 [dataprep.to_repr] INFO: Using bpe merges file: /home/lv71161/hlibbabii/.config/dataprep/1.0.0-alpha.8/bpe/python-bpe-training_15-07-12T15-41-46_py_-_nounicode/10000/merges.txt\n",
      "2019-08-21 18:07:15,630 [dataprep.to_repr] INFO: Using first 10000 merges.\n",
      "['void</t>', 'test_', 'Word', 'U', 'e', 'b', 'err', 'as', 'chun', 'g', 'Pr', 'inter</t>', '(</t>', ')</t>', '{</t>', '\\n', '\\t', 'if</t>', '(</t>', 'ep', 's</t>', '></t>', '=</t>', '0.3', '45', 'e+', '4</t>', ')</t>', '{</t>', '<comment>', '\\t', '\\t', 'print', 'Word</t>', '(</t>', '\"', '\"', ')</t>', ';</t>', '\\n', '\\t', '}</t>', '\\n', '}</t>']\n",
      "\n",
      "========================   Stats           =========================\n",
      "\n",
      "Train vocab: 10264\n",
      "Test vocab : 9704, identifiers: 4562 (0.47%)\n",
      "\n",
      "Train corpus size: 2612459714\n",
      "Test corpus size : 30332162, identifiers: 3596933 (0.12%)\n",
      "\n",
      "OOV in test set (top 9223372036854775807): 0 (0.00%), oov tokens number: 0 (0.00%)\n",
      "OOV in test set (top 200000): 0 (0.00%), oov tokens number: 0 (0.00%)\n",
      "OOV in test set (top 100000): 0 (0.00%), oov tokens number: 0 (0.00%)\n",
      "OOV in test set (top 75000): 0 (0.00%), oov tokens number: 0 (0.00%)\n",
      "OOV in test set (top 50000): 0 (0.00%), oov tokens number: 0 (0.00%)\n",
      "OOV in test set (top 25000): 0 (0.00%), oov tokens number: 0 (0.00%)\n",
      "\n",
      "For identifiers: \n",
      "\n",
      "OOV in test set (top 9223372036854775807): 0 (0.00%), oov tokens number: 0 (0.00%)\n",
      "OOV in test set (top 200000): 0 (0.00%), oov tokens number: 0 (0.00%)\n",
      "OOV in test set (top 100000): 0 (0.00%), oov tokens number: 0 (0.00%)\n",
      "OOV in test set (top 75000): 0 (0.00%), oov tokens number: 0 (0.00%)\n",
      "OOV in test set (top 50000): 0 (0.00%), oov tokens number: 0 (0.00%)\n",
      "OOV in test set (top 25000): 0 (0.00%), oov tokens number: 0 (0.00%)\n",
      "[25, 14, 52, 106, 10067]\n"
     ]
    }
   ],
   "source": [
    "prep_function = PrepFunction(api.bpe, ['python-bpe-training_nounicode-10000'], {\"no_com\": True, \"max_str_length\": 14, \"no_unicode\": True})\n",
    "description = \"bpe 10k Hellendoorn and Devanbu strings no comments no unicode\"\n",
    "run(prep_function, description)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "metrics",
   "language": "python",
   "name": "metrics"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
