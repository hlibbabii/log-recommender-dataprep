{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataprep.api.corpus as api\n",
    "import os\n",
    "\n",
    "from vocabstudy.common import PrepFunction, calc_and_display_stats, VocabStatsCsvWriter, HEADER, HOME\n",
    "JAVA_KEYWORDS = {\"abstract\", \"assert\", \"boolean\", \"break\", \"byte\", \"case\", \"catch\", \"char\",\n",
    "            \"class\", \"const\", \"continue\", \"default\", \"do\", \"double\", \"else\", \"enum\", \"extends\", \"final\", \"finally\",\n",
    "            \"float\", \"for\", \"goto\", \"if\", \"implements\", \"import\", \"instanceof\", \"int\", \"interface\", \"long\", \"native\",\n",
    "            \"new\", \"package\", \"private\", \"protected\", \"public\", \"return\", \"short\", \"static\", \"strictfp\", \"super\",\n",
    "            \"switch\", \"synchronized\", \"this\", \"throw\", \"throws\", \"transient\", \"try\", \"void\", \"volatile\", \"while\",\n",
    "            \"true\", \"false\", \"null\"}\n",
    "\n",
    "JAVA_DATASETS = (\n",
    "    'allamanis/java-minus-small-test',\n",
    "    'allamanis/java-small-test'\n",
    ")\n",
    "\n",
    "writer = VocabStatsCsvWriter(os.path.join(HOME, 'java-stats.csv'), HEADER)\n",
    "\n",
    "def run(prep_function: PrepFunction, description: str) -> None:\n",
    "    row = calc_and_display_stats(prep_function, description, JAVA_DATASETS, JAVA_KEYWORDS, 'java')\n",
    "    writer.write_line(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.0.0-alpha.8'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dataprep\n",
    "\n",
    "dataprep.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unsplit corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unsplit, with comments and strings. No filtering.\n",
      "\n",
      "2019-08-26 12:22:55,429 [dataprep.infrastructure.stages] INFO: Checking first if vocabulary file exists: /home/lv71161/hlibbabii/.config/dataprep/1.0.0-alpha.8/vocab/java-minus-small-test_19-08-08T23-17-22_java_-_uc10su/vocab\n",
      "2019-08-26 12:22:55,431 [dataprep.infrastructure.stages] INFO: Vocabulary is already computed and up-to-date\n",
      "2019-08-26 12:22:55,432 [dataprep.api.corpus] INFO: Preprocessed dataset is ready at /tmp/scratch/prep-datasets/java-minus-small-test_19-08-08T23-17-22_java_-_uc10su_-_prep\n",
      "2019-08-26 12:23:28,538 [dataprep.infrastructure.stages] INFO: Checking first if vocabulary file exists: /home/lv71161/hlibbabii/.config/dataprep/1.0.0-alpha.8/vocab/java-small-test_19-02-09T13-18-23_java_-_uc10su/vocab\n",
      "2019-08-26 12:23:28,541 [dataprep.infrastructure.stages] INFO: Vocabulary is already computed and up-to-date\n",
      "2019-08-26 12:23:28,542 [dataprep.api.corpus] INFO: Preprocessed dataset is ready at /tmp/scratch/prep-datasets/java-small-test_19-02-09T13-18-23_java_-_uc10su_-_prep\n",
      "2019-08-26 12:23:28,824 [vocabstudy.common] DEBUG: Checking if train dataset exists: /tmp/scratch/prep-datasets/java-minus-small-test_19-08-08T23-17-22_java_-_uc10su_-_prep\n",
      "2019-08-26 12:23:28,825 [vocabstudy.common] INFO: Train dataset is found and is going to be removed to save space: /tmp/scratch/prep-datasets/java-minus-small-test_19-08-08T23-17-22_java_-_uc10su_-_prep. Removing ...\n",
      "2019-08-26 12:23:28,828 [vocabstudy.common] INFO: Moving test dataset from tmp storage: /tmp/scratch/prep-datasets/java-small-test_19-02-09T13-18-23_java_-_uc10su_-_prep -> /home/lv71161/hlibbabii/prep-datasets\n",
      "2019-08-26 12:23:28,829 [vocabstudy.common] WARNING: Not moving. Path already exists: /home/lv71161/hlibbabii/prep-datasets/java-small-test_19-02-09T13-18-23_java_-_uc10su_-_prep\n",
      "\n",
      "========================   Split example   =========================\n",
      "\n",
      "['void', 'test_WordUeberraschungPrinter', '(', ')', '{', '\\n', '\\t', 'if', '(', 'eps', '>', '=', '0.345e+4', ')', '{', '/', '/', 'FIXME', '10l', '\\n', '<EOL>', '\\t', '\\t', 'printWord', '(', '\"', '.', '.', '.', 'Ãœberraschung', '0x12', '\"', ')', ';', '\\n', '\\t', '}', '\\n', '}']\n",
      "\n",
      "========================   Stats           =========================\n",
      "\n",
      "Train vocab: 11589391\n",
      "Test vocab : 100974, identifiers: 86612 (0.86%)\n",
      "\n",
      "Train corpus size: 2431144083\n",
      "Test corpus size : 10650037, identifiers: 3029114 (0.28%)\n",
      "\n",
      "OOV in test set (top 9223372036854775807): 42485 (42.08%), oov tokens number: 272902 (2.56%)\n",
      "OOV in test set (top 200000): 72243 (71.55%), oov tokens number: 500942 (4.70%)\n",
      "OOV in test set (top 100000): 77406 (76.66%), oov tokens number: 555580 (5.22%)\n",
      "OOV in test set (top 75000): 79629 (78.86%), oov tokens number: 591510 (5.55%)\n",
      "OOV in test set (top 50000): 82689 (81.89%), oov tokens number: 637874 (5.99%)\n",
      "OOV in test set (top 25000): 87810 (86.96%), oov tokens number: 706050 (6.63%)\n",
      "Variation coeff: 0.19706195232886503\n",
      "[2874996, 6716742, 1755521, 209695, 32437]\n"
     ]
    }
   ],
   "source": [
    "prep_function = PrepFunction(api.nosplit)\n",
    "description = \"unsplit, with comments and strings. No filtering.\"\n",
    "run(prep_function, description)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering non-ASCII tokens\n",
      "\n",
      "2019-08-26 12:23:57,326 [dataprep.infrastructure.stages] INFO: Checking first if vocabulary file exists: /home/lv71161/hlibbabii/.config/dataprep/1.0.0-alpha.8/vocab/java-minus-small-test_19-08-08T23-17-22_java_-_Uc10su/vocab\n",
      "2019-08-26 12:23:57,327 [dataprep.infrastructure.stages] INFO: Vocabulary is already computed and up-to-date\n",
      "2019-08-26 12:23:57,328 [dataprep.api.corpus] INFO: Preprocessed dataset is ready at /tmp/scratch/prep-datasets/java-minus-small-test_19-08-08T23-17-22_java_-_Uc10su_-_prep\n",
      "2019-08-26 12:24:31,352 [dataprep.infrastructure.stages] INFO: Checking first if vocabulary file exists: /home/lv71161/hlibbabii/.config/dataprep/1.0.0-alpha.8/vocab/java-small-test_19-02-09T13-18-23_java_-_Uc10su/vocab\n",
      "2019-08-26 12:24:31,356 [dataprep.infrastructure.stages] INFO: Vocabulary is already computed and up-to-date\n",
      "2019-08-26 12:24:31,357 [dataprep.api.corpus] INFO: Preprocessed dataset is ready at /tmp/scratch/prep-datasets/java-small-test_19-02-09T13-18-23_java_-_Uc10su_-_prep\n",
      "2019-08-26 12:24:31,595 [vocabstudy.common] DEBUG: Checking if train dataset exists: /tmp/scratch/prep-datasets/java-minus-small-test_19-08-08T23-17-22_java_-_Uc10su_-_prep\n",
      "2019-08-26 12:24:31,597 [vocabstudy.common] INFO: Train dataset is found and is going to be removed to save space: /tmp/scratch/prep-datasets/java-minus-small-test_19-08-08T23-17-22_java_-_Uc10su_-_prep. Removing ...\n",
      "2019-08-26 12:24:31,600 [vocabstudy.common] INFO: Moving test dataset from tmp storage: /tmp/scratch/prep-datasets/java-small-test_19-02-09T13-18-23_java_-_Uc10su_-_prep -> /home/lv71161/hlibbabii/prep-datasets\n",
      "2019-08-26 12:24:31,601 [vocabstudy.common] WARNING: Not moving. Path already exists: /home/lv71161/hlibbabii/prep-datasets/java-small-test_19-02-09T13-18-23_java_-_Uc10su_-_prep\n",
      "\n",
      "========================   Split example   =========================\n",
      "\n",
      "['void', 'test_WordUeberraschungPrinter', '(', ')', '{', '\\n', '\\t', 'if', '(', 'eps', '>', '=', '0.345e+4', ')', '{', '/', '/', 'FIXME', '10l', '\\n', '<EOL>', '\\t', '\\t', 'printWord', '(', '\"', '.', '.', '.', '<non-en>', '0x12', '\"', ')', ';', '\\n', '\\t', '}', '\\n', '}']\n",
      "\n",
      "========================   Stats           =========================\n",
      "\n",
      "Train vocab: 11418908\n",
      "Test vocab : 89185, identifiers: 86577 (0.97%)\n",
      "\n",
      "Train corpus size: 2431144083\n",
      "Test corpus size : 10650037, identifiers: 3029037 (0.28%)\n",
      "\n",
      "OOV in test set (top 9223372036854775807): 31158 (34.94%), oov tokens number: 237321 (2.23%)\n",
      "OOV in test set (top 200000): 60446 (67.78%), oov tokens number: 458410 (4.30%)\n",
      "OOV in test set (top 100000): 65607 (73.56%), oov tokens number: 511282 (4.80%)\n",
      "OOV in test set (top 75000): 67831 (76.06%), oov tokens number: 547073 (5.14%)\n",
      "OOV in test set (top 50000): 70888 (79.48%), oov tokens number: 593344 (5.57%)\n",
      "OOV in test set (top 25000): 76008 (85.23%), oov tokens number: 661442 (6.21%)\n",
      "Variation coeff: 0.1970621352693868\n",
      "[2759470, 6667800, 1749998, 209256, 32384]\n"
     ]
    }
   ],
   "source": [
    "prep_function = PrepFunction(api.nosplit, [], {\"no_unicode\": True})\n",
    "description = \"Filtering non-ASCII tokens\"\n",
    "\n",
    "run(prep_function, description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering whitespace (+ non-ascii)\n",
      "\n",
      "2019-08-26 12:24:59,856 [dataprep.infrastructure.stages] INFO: Checking first if vocabulary file exists: /home/lv71161/hlibbabii/.config/dataprep/1.0.0-alpha.8/vocab/java-minus-small-test_19-08-08T23-17-22_java_-_Uc100u/vocab\n",
      "2019-08-26 12:24:59,857 [dataprep.infrastructure.stages] INFO: Vocabulary is already computed and up-to-date\n",
      "2019-08-26 12:24:59,857 [dataprep.api.corpus] INFO: Preprocessed dataset is ready at /tmp/scratch/prep-datasets/java-minus-small-test_19-08-08T23-17-22_java_-_Uc100u_-_prep\n",
      "2019-08-26 12:25:32,371 [dataprep.infrastructure.stages] INFO: Checking first if vocabulary file exists: /home/lv71161/hlibbabii/.config/dataprep/1.0.0-alpha.8/vocab/java-small-test_19-02-09T13-18-23_java_-_Uc100u/vocab\n",
      "2019-08-26 12:25:32,380 [dataprep.infrastructure.stages] INFO: Vocabulary is already computed and up-to-date\n",
      "2019-08-26 12:25:32,381 [dataprep.api.corpus] INFO: Preprocessed dataset is ready at /tmp/scratch/prep-datasets/java-small-test_19-02-09T13-18-23_java_-_Uc100u_-_prep\n",
      "2019-08-26 12:25:32,786 [vocabstudy.common] DEBUG: Checking if train dataset exists: /tmp/scratch/prep-datasets/java-minus-small-test_19-08-08T23-17-22_java_-_Uc100u_-_prep\n",
      "2019-08-26 12:25:32,787 [vocabstudy.common] INFO: Train dataset is found and is going to be removed to save space: /tmp/scratch/prep-datasets/java-minus-small-test_19-08-08T23-17-22_java_-_Uc100u_-_prep. Removing ...\n",
      "2019-08-26 12:25:32,789 [vocabstudy.common] INFO: Moving test dataset from tmp storage: /tmp/scratch/prep-datasets/java-small-test_19-02-09T13-18-23_java_-_Uc100u_-_prep -> /home/lv71161/hlibbabii/prep-datasets\n",
      "2019-08-26 12:25:32,790 [vocabstudy.common] WARNING: Not moving. Path already exists: /home/lv71161/hlibbabii/prep-datasets/java-small-test_19-02-09T13-18-23_java_-_Uc100u_-_prep\n",
      "\n",
      "========================   Split example   =========================\n",
      "\n",
      "['void', 'test_WordUeberraschungPrinter', '(', ')', '{', 'if', '(', 'eps', '>', '=', '0.345e+4', ')', '{', '/', '/', 'FIXME', '10l', '<EOL>', 'printWord', '(', '\"', '.', '.', '.', '<non-en>', '0x12', '\"', ')', ';', '}', '}']\n",
      "\n",
      "========================   Stats           =========================\n",
      "\n",
      "Train vocab: 11418906\n",
      "Test vocab : 89184, identifiers: 86578 (0.97%)\n",
      "\n",
      "Train corpus size: 1892510212\n",
      "Test corpus size : 8341935, identifiers: 3029038 (0.36%)\n",
      "\n",
      "OOV in test set (top 9223372036854775807): 31158 (34.94%), oov tokens number: 237321 (2.84%)\n",
      "OOV in test set (top 200000): 60446 (67.78%), oov tokens number: 458458 (5.50%)\n",
      "OOV in test set (top 100000): 65608 (73.56%), oov tokens number: 511199 (6.13%)\n",
      "OOV in test set (top 75000): 67830 (76.06%), oov tokens number: 547008 (6.56%)\n",
      "OOV in test set (top 50000): 70888 (79.49%), oov tokens number: 593313 (7.11%)\n",
      "OOV in test set (top 25000): 76009 (85.23%), oov tokens number: 661447 (7.93%)\n",
      "Variation coeff: 0.15339508396486784\n",
      "[2759470, 6667799, 1749998, 209257, 32382]\n"
     ]
    }
   ],
   "source": [
    "prep_function = PrepFunction(api.nosplit, [], {\"no_unicode\": True, \"no_spaces\": True})\n",
    "description = \"Filtering whitespace (+ non-ascii)\"\n",
    "\n",
    "run(prep_function, description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering comments (+ whitespace, + non-ascii)\n",
      "\n",
      "2019-08-26 12:25:59,219 [dataprep.infrastructure.stages] INFO: Checking first if vocabulary file exists: /home/lv71161/hlibbabii/.config/dataprep/1.0.0-alpha.8/vocab/java-minus-small-test_19-08-08T23-17-22_java_-_U0100u/vocab\n",
      "2019-08-26 12:25:59,231 [dataprep.infrastructure.stages] INFO: Vocabulary is already computed and up-to-date\n",
      "2019-08-26 12:25:59,232 [dataprep.api.corpus] INFO: Preprocessed dataset is ready at /tmp/scratch/prep-datasets/java-minus-small-test_19-08-08T23-17-22_java_-_U0100u_-_prep\n",
      "2019-08-26 12:26:29,468 [dataprep.infrastructure.stages] INFO: Checking first if vocabulary file exists: /home/lv71161/hlibbabii/.config/dataprep/1.0.0-alpha.8/vocab/java-small-test_19-02-09T13-18-23_java_-_U0100u/vocab\n",
      "2019-08-26 12:26:29,495 [dataprep.infrastructure.stages] INFO: Vocabulary is already computed and up-to-date\n",
      "2019-08-26 12:26:29,496 [dataprep.api.corpus] INFO: Preprocessed dataset is ready at /tmp/scratch/prep-datasets/java-small-test_19-02-09T13-18-23_java_-_U0100u_-_prep\n",
      "2019-08-26 12:26:29,755 [vocabstudy.common] DEBUG: Checking if train dataset exists: /tmp/scratch/prep-datasets/java-minus-small-test_19-08-08T23-17-22_java_-_U0100u_-_prep\n",
      "2019-08-26 12:26:29,756 [vocabstudy.common] INFO: Train dataset is found and is going to be removed to save space: /tmp/scratch/prep-datasets/java-minus-small-test_19-08-08T23-17-22_java_-_U0100u_-_prep. Removing ...\n",
      "2019-08-26 12:26:29,758 [vocabstudy.common] INFO: Moving test dataset from tmp storage: /tmp/scratch/prep-datasets/java-small-test_19-02-09T13-18-23_java_-_U0100u_-_prep -> /home/lv71161/hlibbabii/prep-datasets\n",
      "2019-08-26 12:26:29,759 [vocabstudy.common] WARNING: Not moving. Path already exists: /home/lv71161/hlibbabii/prep-datasets/java-small-test_19-02-09T13-18-23_java_-_U0100u_-_prep\n",
      "\n",
      "========================   Split example   =========================\n",
      "\n",
      "['void', 'test_WordUeberraschungPrinter', '(', ')', '{', 'if', '(', 'eps', '>', '=', '0.345e+4', ')', '{', '<comment>', 'printWord', '(', '\"', '.', '.', '.', '<non-en>', '0x12', '\"', ')', ';', '}', '}']\n",
      "\n",
      "========================   Stats           =========================\n",
      "\n",
      "Train vocab: 10813844\n",
      "Test vocab : 80334, identifiers: 78340 (0.98%)\n",
      "\n",
      "Train corpus size: 1261768048\n",
      "Test corpus size : 5851993, identifiers: 1947796 (0.33%)\n",
      "\n",
      "OOV in test set (top 9223372036854775807): 30304 (37.72%), oov tokens number: 222756 (3.81%)\n",
      "OOV in test set (top 200000): 56401 (70.21%), oov tokens number: 415208 (7.10%)\n",
      "OOV in test set (top 100000): 60840 (75.73%), oov tokens number: 461900 (7.89%)\n",
      "OOV in test set (top 75000): 62624 (77.95%), oov tokens number: 483114 (8.26%)\n",
      "OOV in test set (top 50000): 65056 (80.98%), oov tokens number: 532645 (9.10%)\n",
      "OOV in test set (top 25000): 69245 (86.20%), oov tokens number: 592727 (10.13%)\n",
      "Variation coeff: 0.18285918686270033\n",
      "[2532907, 6487131, 1586806, 181371, 25629]\n"
     ]
    }
   ],
   "source": [
    "prep_function = PrepFunction(api.nosplit, [], {\"no_unicode\": True, \"no_spaces\": True, \"no_com\": True})\n",
    "description = \"Filtering comments (+ whitespace, + non-ascii)\"\n",
    "\n",
    "run(prep_function, description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering  strings (+ comments, + whitespace, + non-ascii)\n",
      "\n",
      "2019-08-26 12:26:55,624 [dataprep.infrastructure.stages] INFO: Checking first if vocabulary file exists: /home/lv71161/hlibbabii/.config/dataprep/1.0.0-alpha.8/vocab/java-minus-small-test_19-08-08T23-17-22_java_-_U0000u/vocab\n",
      "2019-08-26 12:26:55,636 [dataprep.infrastructure.stages] INFO: Vocabulary is already computed and up-to-date\n",
      "2019-08-26 12:26:55,637 [dataprep.api.corpus] INFO: Preprocessed dataset is ready at /tmp/scratch/prep-datasets/java-minus-small-test_19-08-08T23-17-22_java_-_U0000u_-_prep\n",
      "2019-08-26 12:27:24,894 [dataprep.infrastructure.stages] INFO: Checking first if vocabulary file exists: /home/lv71161/hlibbabii/.config/dataprep/1.0.0-alpha.8/vocab/java-small-test_19-02-09T13-18-23_java_-_U0000u/vocab\n",
      "2019-08-26 12:27:24,896 [dataprep.infrastructure.stages] INFO: Vocabulary is already computed and up-to-date\n",
      "2019-08-26 12:27:24,898 [dataprep.api.corpus] INFO: Preprocessed dataset is ready at /tmp/scratch/prep-datasets/java-small-test_19-02-09T13-18-23_java_-_U0000u_-_prep\n",
      "2019-08-26 12:27:25,252 [vocabstudy.common] DEBUG: Checking if train dataset exists: /tmp/scratch/prep-datasets/java-minus-small-test_19-08-08T23-17-22_java_-_U0000u_-_prep\n",
      "2019-08-26 12:27:25,253 [vocabstudy.common] INFO: Train dataset is found and is going to be removed to save space: /tmp/scratch/prep-datasets/java-minus-small-test_19-08-08T23-17-22_java_-_U0000u_-_prep. Removing ...\n",
      "2019-08-26 12:27:25,254 [vocabstudy.common] INFO: Moving test dataset from tmp storage: /tmp/scratch/prep-datasets/java-small-test_19-02-09T13-18-23_java_-_U0000u_-_prep -> /home/lv71161/hlibbabii/prep-datasets\n",
      "2019-08-26 12:27:25,255 [vocabstudy.common] WARNING: Not moving. Path already exists: /home/lv71161/hlibbabii/prep-datasets/java-small-test_19-02-09T13-18-23_java_-_U0000u_-_prep\n",
      "\n",
      "========================   Split example   =========================\n",
      "\n",
      "['void', 'test_WordUeberraschungPrinter', '(', ')', '{', 'if', '(', 'eps', '>', '=', '0.345e+4', ')', '{', '<comment>', 'printWord', '(', '<str-literal>', ')', ';', '}', '}']\n",
      "\n",
      "========================   Stats           =========================\n",
      "\n",
      "Train vocab: 9521607\n",
      "Test vocab : 70745, identifiers: 69274 (0.98%)\n",
      "\n",
      "Train corpus size: 1151554964\n",
      "Test corpus size : 5431529, identifiers: 1791408 (0.33%)\n",
      "\n",
      "OOV in test set (top 9223372036854775807): 27274 (38.55%), oov tokens number: 222901 (4.10%)\n",
      "OOV in test set (top 200000): 49948 (70.60%), oov tokens number: 386753 (7.12%)\n",
      "OOV in test set (top 100000): 53813 (76.07%), oov tokens number: 431548 (7.95%)\n",
      "OOV in test set (top 75000): 55361 (78.25%), oov tokens number: 449269 (8.27%)\n",
      "OOV in test set (top 50000): 57442 (81.20%), oov tokens number: 500056 (9.21%)\n",
      "OOV in test set (top 25000): 60996 (86.22%), oov tokens number: 551722 (10.16%)\n",
      "Variation coeff: 0.19326645266080125\n",
      "[1899280, 5980484, 1451884, 166995, 22964]\n"
     ]
    }
   ],
   "source": [
    "prep_function = PrepFunction(api.nosplit, [], {\"no_unicode\": True, \"no_spaces\": True, \"no_com\": True, \"no_str\": True})\n",
    "description = \"Filtering  strings (+ comments, + whitespace, + non-ascii)\"\n",
    "\n",
    "run(prep_function, description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An additional choice, the model from Hellendoorn and Devanbu: keep strings shorter than 15 char (check SLP-core code), remove others, remove comments  (+ no spaces, + no unicode)  --> Baseline for word splitting\n",
      "\n",
      "2019-08-26 12:27:49,308 [dataprep.infrastructure.stages] INFO: Checking first if vocabulary file exists: /home/lv71161/hlibbabii/.config/dataprep/1.0.0-alpha.8/vocab/java-minus-small-test_19-08-08T23-17-22_java_-_U0EF0u/vocab\n",
      "2019-08-26 12:27:49,309 [dataprep.infrastructure.stages] INFO: Vocabulary is already computed and up-to-date\n",
      "2019-08-26 12:27:49,310 [dataprep.api.corpus] INFO: Preprocessed dataset is ready at /tmp/scratch/prep-datasets/java-minus-small-test_19-08-08T23-17-22_java_-_U0EF0u_-_prep\n",
      "2019-08-26 12:28:19,824 [dataprep.infrastructure.stages] INFO: Checking first if vocabulary file exists: /home/lv71161/hlibbabii/.config/dataprep/1.0.0-alpha.8/vocab/java-small-test_19-02-09T13-18-23_java_-_U0EF0u/vocab\n",
      "2019-08-26 12:28:19,859 [dataprep.infrastructure.stages] INFO: Vocabulary is already computed and up-to-date\n",
      "2019-08-26 12:28:19,860 [dataprep.api.corpus] INFO: Preprocessed dataset is ready at /tmp/scratch/prep-datasets/java-small-test_19-02-09T13-18-23_java_-_U0EF0u_-_prep\n",
      "2019-08-26 12:28:20,213 [vocabstudy.common] DEBUG: Checking if train dataset exists: /tmp/scratch/prep-datasets/java-minus-small-test_19-08-08T23-17-22_java_-_U0EF0u_-_prep\n",
      "2019-08-26 12:28:20,214 [vocabstudy.common] INFO: Train dataset is found and is going to be removed to save space: /tmp/scratch/prep-datasets/java-minus-small-test_19-08-08T23-17-22_java_-_U0EF0u_-_prep. Removing ...\n",
      "2019-08-26 12:28:20,215 [vocabstudy.common] INFO: Moving test dataset from tmp storage: /tmp/scratch/prep-datasets/java-small-test_19-02-09T13-18-23_java_-_U0EF0u_-_prep -> /home/lv71161/hlibbabii/prep-datasets\n",
      "2019-08-26 12:28:20,216 [vocabstudy.common] WARNING: Not moving. Path already exists: /home/lv71161/hlibbabii/prep-datasets/java-small-test_19-02-09T13-18-23_java_-_U0EF0u_-_prep\n",
      "\n",
      "========================   Split example   =========================\n",
      "\n",
      "['void', 'test_WordUeberraschungPrinter', '(', ')', '{', 'if', '(', 'eps', '>', '=', '0.345e+4', ')', '{', '<comment>', 'printWord', '(', '\"\"', ')', ';', '}', '}']\n",
      "\n",
      "========================   Stats           =========================\n",
      "\n",
      "Train vocab: 10921632\n",
      "Test vocab : 82410, identifiers: 69274 (0.84%)\n",
      "\n",
      "Train corpus size: 1151554964\n",
      "Test corpus size : 5431529, identifiers: 1791408 (0.33%)\n",
      "\n",
      "OOV in test set (top 9223372036854775807): 31987 (38.81%), oov tokens number: 234724 (4.32%)\n",
      "OOV in test set (top 200000): 59150 (71.78%), oov tokens number: 413198 (7.61%)\n",
      "OOV in test set (top 100000): 63677 (77.27%), oov tokens number: 459965 (8.47%)\n",
      "OOV in test set (top 75000): 65533 (79.52%), oov tokens number: 481992 (8.87%)\n",
      "OOV in test set (top 50000): 67974 (82.48%), oov tokens number: 531270 (9.78%)\n",
      "OOV in test set (top 25000): 72032 (87.41%), oov tokens number: 588677 (10.84%)\n",
      "Variation coeff: 0.19262574485085182\n",
      "[2714639, 6485649, 1522874, 174532, 23938]\n"
     ]
    }
   ],
   "source": [
    "prep_function = PrepFunction(api.nosplit, [], {\"no_unicode\": True, \"no_spaces\": True, \"no_com\": True, \"full_strings\": True, \"max_str_length\": 14})\n",
    "description = \"An additional choice, the model from Hellendoorn and Devanbu: keep strings shorter than 15 char (check SLP-core code), remove others, remove comments  (+ no spaces, + no unicode)  --> Baseline for word splitting\"\n",
    "\n",
    "run(prep_function, description)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Unsplit, remove non-ascii, remove whitespace, remove comments, remove strings longer than 15 chars] + Word splitting via conventions --> Baseline for subword splitting\n",
      "\n",
      "2019-08-26 12:28:47,508 [dataprep.infrastructure.stages] INFO: Checking first if vocabulary file exists: /home/lv71161/hlibbabii/.config/dataprep/1.0.0-alpha.8/vocab/java-minus-small-test_19-08-08T23-17-22_java_-_U0E10u/vocab\n",
      "2019-08-26 12:28:47,509 [dataprep.infrastructure.stages] INFO: Parsing...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-3a9d839fbcc3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdescription\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"[Unsplit, remove non-ascii, remove whitespace, remove comments, remove strings longer than 15 chars] + Word splitting via conventions --> Baseline for subword splitting\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescription\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-1-9115db275306>\u001b[0m in \u001b[0;36mrun\u001b[0;34m(prep_function, description)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep_function\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mPrepFunction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescription\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mrow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalc_and_display_stats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescription\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mJAVA_DATASETS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mJAVA_KEYWORDS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'java'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/log-recommender-dataprep/vocabstudy/common.py\u001b[0m in \u001b[0;36mcalc_and_display_stats\u001b[0;34m(prep_function, description, datasets, keywords, extension)\u001b[0m\n\u001b[1;32m    184\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m         \u001b[0mdataset_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPATH_TO_DATASETS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m         \u001b[0mprep_corpus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprep_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCorpus\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextension\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mPATH_TO_PREP_DATASETS_TMP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m         \u001b[0mprep_corpora\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep_corpus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0mvocabs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep_corpus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/log-recommender-dataprep/vocabstudy/common.py\u001b[0m in \u001b[0;36mprep_corpus\u001b[0;34m(corpus, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mprep_corpus\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mCorpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m             return self.callable(corpus.path, *self.params, **self.options, **kwargs,\n\u001b[0;32m---> 67\u001b[0;31m                                  calc_vocab=True, extensions=corpus.extensions)\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mprep_corpus\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/metrics/lib/python3.7/site-packages/dataprep/api/corpus.py\u001b[0m in \u001b[0;36mbasic\u001b[0;34m(path, extensions, split_numbers, ronin, stem, no_spaces, no_unicode, no_case, no_com, no_str, max_str_length, output_path, calc_vocab)\u001b[0m\n\u001b[1;32m    148\u001b[0m                                      \u001b[0mno_com\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mno_com\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mno_str\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mno_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_str_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_str_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m                                      split_numbers=split_numbers or stem or ronin, ronin=ronin or stem, stem=stem)\n\u001b[0;32m--> 150\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mpreprocess_corpus\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprep_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextensions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextensions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcalc_vocab\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcalc_vocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/metrics/lib/python3.7/site-packages/dataprep/api/corpus.py\u001b[0m in \u001b[0;36mpreprocess_corpus\u001b[0;34m(path, prep_config, bpe_codes_id, extensions, output_path, calc_vocab)\u001b[0m\n\u001b[1;32m    196\u001b[0m                              overriden_path_to_prep_dataset=output_path)\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcalc_vocab\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 198\u001b[0;31m         \u001b[0mstages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_until_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_bpe_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m         \u001b[0mpath_to_vocab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath_to_vocab_file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/metrics/lib/python3.7/site-packages/dataprep/infrastructure/stages.py\u001b[0m in \u001b[0;36mrun_until_vocab\u001b[0;34m(dataset, custom_bpe_config)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_path_ready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath_to_vocab_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0mrun_until_preprocessing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_bpe_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Computing vocab...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0mcalc_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/metrics/lib/python3.7/site-packages/dataprep/infrastructure/stages.py\u001b[0m in \u001b[0;36mrun_until_preprocessing\u001b[0;34m(dataset, custom_bpe_config)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrun_until_preprocessing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_bpe_config\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCustomBpeConfig\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0mrun_parsing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Preprocessing...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/metrics/lib/python3.7/site-packages/dataprep/infrastructure/stages.py\u001b[0m in \u001b[0;36mrun_parsing\u001b[0;34m(dataset)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparsed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mparse_projects\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0;32melif\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparsed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_outdated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparsed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marchive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mparse_projects\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/metrics/lib/python3.7/site-packages/dataprep/infrastructure/dataset.py\u001b[0m in \u001b[0;36mis_outdated\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mis_outdated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mis_path_outdated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfile_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mGenerator\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/metrics/lib/python3.7/site-packages/dataprep/infrastructure/dataset.py\u001b[0m in \u001b[0;36mis_path_outdated\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    293\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodif_file\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0mexpected_timestamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m         \u001b[0mactual_timestamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_timestamp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mexpected_timestamp\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mactual_timestamp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/metrics/lib/python3.7/site-packages/dataprep/dirutils.py\u001b[0m in \u001b[0;36mget_timestamp\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_timestamp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m     \u001b[0mlast_modif_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_dir_last_modification\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mlast_modif_time\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%y-%m-%dT%H-%M-%S\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/metrics/lib/python3.7/site-packages/dataprep/dirutils.py\u001b[0m in \u001b[0;36mget_dir_last_modification\u001b[0;34m(path, limit)\u001b[0m\n\u001b[1;32m     70\u001b[0m                         \u001b[0;32myield\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetmtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m     \u001b[0mmtime\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwalk_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromtimestamp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmtime\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/metrics/lib/python3.7/site-packages/dataprep/dirutils.py\u001b[0m in \u001b[0;36mwalk_path\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetmtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdirs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwalk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mdir\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdirs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mcounter\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/metrics/lib/python3.7/os.py\u001b[0m in \u001b[0;36mwalk\u001b[0;34m(top, topdown, onerror, followlinks)\u001b[0m\n\u001b[1;32m    408\u001b[0m             \u001b[0;31m# above.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mfollowlinks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mislink\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 410\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mwalk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopdown\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0monerror\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfollowlinks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    411\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m         \u001b[0;31m# Recurse into sub-directories\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/metrics/lib/python3.7/os.py\u001b[0m in \u001b[0;36mwalk\u001b[0;34m(top, topdown, onerror, followlinks)\u001b[0m\n\u001b[1;32m    357\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m                     \u001b[0mentry\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscandir_it\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "prep_function = PrepFunction(api.basic, [],\n",
    "                             {\"no_unicode\": True, \"no_spaces\": True, \"no_com\": True, \"max_str_length\": 14})\n",
    "description = \"[Unsplit, remove non-ascii, remove whitespace, remove comments, remove strings longer than 15 chars] + Word splitting via conventions --> Baseline for subword splitting\"\n",
    "\n",
    "run(prep_function, description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Unsplit, remove non-ascii, remove whitespace, remove comments, remove strings longer than 15 chars] + Word splitting via conventions, and remove case.\n",
      "\n",
      "2019-08-26 12:29:58,400 [dataprep.infrastructure.stages] INFO: Checking first if vocabulary file exists: /home/lv71161/hlibbabii/.config/dataprep/1.0.0-alpha.8/vocab/java-minus-small-test_19-08-08T23-17-22_java_-_U0E10l/vocab\n",
      "2019-08-26 12:29:58,401 [dataprep.infrastructure.stages] INFO: Parsing...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-984cf23c4cdb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdescription\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"[Unsplit, remove non-ascii, remove whitespace, remove comments, remove strings longer than 15 chars] + Word splitting via conventions, and remove case.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescription\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-1-9115db275306>\u001b[0m in \u001b[0;36mrun\u001b[0;34m(prep_function, description)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep_function\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mPrepFunction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescription\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mrow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalc_and_display_stats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescription\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mJAVA_DATASETS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mJAVA_KEYWORDS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'java'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/log-recommender-dataprep/vocabstudy/common.py\u001b[0m in \u001b[0;36mcalc_and_display_stats\u001b[0;34m(prep_function, description, datasets, keywords, extension)\u001b[0m\n\u001b[1;32m    184\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m         \u001b[0mdataset_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPATH_TO_DATASETS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m         \u001b[0mprep_corpus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprep_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCorpus\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextension\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mPATH_TO_PREP_DATASETS_TMP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m         \u001b[0mprep_corpora\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep_corpus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0mvocabs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep_corpus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/log-recommender-dataprep/vocabstudy/common.py\u001b[0m in \u001b[0;36mprep_corpus\u001b[0;34m(corpus, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mprep_corpus\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mCorpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m             return self.callable(corpus.path, *self.params, **self.options, **kwargs,\n\u001b[0;32m---> 67\u001b[0;31m                                  calc_vocab=True, extensions=corpus.extensions)\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mprep_corpus\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/metrics/lib/python3.7/site-packages/dataprep/api/corpus.py\u001b[0m in \u001b[0;36mbasic\u001b[0;34m(path, extensions, split_numbers, ronin, stem, no_spaces, no_unicode, no_case, no_com, no_str, max_str_length, output_path, calc_vocab)\u001b[0m\n\u001b[1;32m    148\u001b[0m                                      \u001b[0mno_com\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mno_com\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mno_str\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mno_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_str_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_str_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m                                      split_numbers=split_numbers or stem or ronin, ronin=ronin or stem, stem=stem)\n\u001b[0;32m--> 150\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mpreprocess_corpus\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprep_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextensions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextensions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcalc_vocab\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcalc_vocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/metrics/lib/python3.7/site-packages/dataprep/api/corpus.py\u001b[0m in \u001b[0;36mpreprocess_corpus\u001b[0;34m(path, prep_config, bpe_codes_id, extensions, output_path, calc_vocab)\u001b[0m\n\u001b[1;32m    196\u001b[0m                              overriden_path_to_prep_dataset=output_path)\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcalc_vocab\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 198\u001b[0;31m         \u001b[0mstages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_until_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_bpe_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m         \u001b[0mpath_to_vocab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath_to_vocab_file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/metrics/lib/python3.7/site-packages/dataprep/infrastructure/stages.py\u001b[0m in \u001b[0;36mrun_until_vocab\u001b[0;34m(dataset, custom_bpe_config)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_path_ready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath_to_vocab_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0mrun_until_preprocessing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_bpe_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Computing vocab...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0mcalc_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/metrics/lib/python3.7/site-packages/dataprep/infrastructure/stages.py\u001b[0m in \u001b[0;36mrun_until_preprocessing\u001b[0;34m(dataset, custom_bpe_config)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrun_until_preprocessing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_bpe_config\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCustomBpeConfig\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0mrun_parsing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Preprocessing...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/metrics/lib/python3.7/site-packages/dataprep/infrastructure/stages.py\u001b[0m in \u001b[0;36mrun_parsing\u001b[0;34m(dataset)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparsed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mparse_projects\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0;32melif\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparsed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_outdated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparsed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marchive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mparse_projects\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/metrics/lib/python3.7/site-packages/dataprep/infrastructure/dataset.py\u001b[0m in \u001b[0;36mis_outdated\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mis_outdated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mis_path_outdated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfile_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mGenerator\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/metrics/lib/python3.7/site-packages/dataprep/infrastructure/dataset.py\u001b[0m in \u001b[0;36mis_path_outdated\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    293\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodif_file\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0mexpected_timestamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m         \u001b[0mactual_timestamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_timestamp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mexpected_timestamp\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mactual_timestamp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/metrics/lib/python3.7/site-packages/dataprep/dirutils.py\u001b[0m in \u001b[0;36mget_timestamp\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_timestamp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m     \u001b[0mlast_modif_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_dir_last_modification\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mlast_modif_time\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%y-%m-%dT%H-%M-%S\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/metrics/lib/python3.7/site-packages/dataprep/dirutils.py\u001b[0m in \u001b[0;36mget_dir_last_modification\u001b[0;34m(path, limit)\u001b[0m\n\u001b[1;32m     70\u001b[0m                         \u001b[0;32myield\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetmtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m     \u001b[0mmtime\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwalk_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromtimestamp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmtime\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/metrics/lib/python3.7/site-packages/dataprep/dirutils.py\u001b[0m in \u001b[0;36mwalk_path\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetmtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdirs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwalk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mdir\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdirs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mcounter\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/metrics/lib/python3.7/os.py\u001b[0m in \u001b[0;36mwalk\u001b[0;34m(top, topdown, onerror, followlinks)\u001b[0m\n\u001b[1;32m    408\u001b[0m             \u001b[0;31m# above.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mfollowlinks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mislink\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 410\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mwalk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopdown\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0monerror\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfollowlinks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    411\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m         \u001b[0;31m# Recurse into sub-directories\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/metrics/lib/python3.7/os.py\u001b[0m in \u001b[0;36mwalk\u001b[0;34m(top, topdown, onerror, followlinks)\u001b[0m\n\u001b[1;32m    366\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 368\u001b[0;31m                 \u001b[0mis_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mentry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    369\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m                 \u001b[0;31m# If is_dir() raises an OSError, consider that the entry is not\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "prep_function = PrepFunction(api.basic, [],\n",
    "                             {\"no_unicode\": True, \"no_spaces\": True, \"no_com\": True, \"max_str_length\": 14,\n",
    "                              \"no_case\": True})\n",
    "description = \"[Unsplit, remove non-ascii, remove whitespace, remove comments, remove strings longer than 15 chars] + Word splitting via conventions, and remove case.\"\n",
    "\n",
    "run(prep_function, description)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subword splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_function = PrepFunction(api.basic, [],\n",
    "                             {\"no_unicode\": True, \"no_spaces\": True, \"no_com\": True, \"max_str_length\": 14,\n",
    "                              \"split_numbers\": True})\n",
    "description = \"[Unsplit, remove non-ascii, remove whitespace, remove comments, remove strings longer than 15 chars + split via conventions, but keep case] + Split numbers\"\n",
    "run(prep_function, description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "prep_function = PrepFunction(api.basic, [],\n",
    "                             {\"no_unicode\": True, \"no_spaces\": True, \"no_com\": True, \"max_str_length\": 14,\n",
    "                              \"split_numbers\": True, \"ronin\": True})\n",
    "description = \"[Unsplit, remove non-ascii, remove whitespace, remove comments, remove strings longer than 15 chars + split via conventions, but keep case] + Split numbers + Ronin\"\n",
    "run(prep_function, description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Unsplit, remove non-ascii, remove whitespace, remove comments, remove strings longer than 15 chars + split via conventions, but keep case] + Split numbers + Ronin + Stemming\n",
      "\n",
      "2019-08-26 12:30:20,963 [dataprep.infrastructure.stages] INFO: Checking first if vocabulary file exists: /home/lv71161/hlibbabii/.config/dataprep/1.0.0-alpha.8/vocab/java-minus-small-test_19-08-08T23-17-22_java_-_U0Es0u/vocab\n",
      "2019-08-26 12:30:20,972 [dataprep.infrastructure.stages] INFO: Vocabulary is already computed and up-to-date\n",
      "2019-08-26 12:30:20,972 [dataprep.api.corpus] INFO: Preprocessed dataset is ready at /tmp/scratch/prep-datasets/java-minus-small-test_19-08-08T23-17-22_java_-_U0Es0u_-_prep\n",
      "2019-08-26 12:30:22,305 [dataprep.infrastructure.stages] INFO: Checking first if vocabulary file exists: /home/lv71161/hlibbabii/.config/dataprep/1.0.0-alpha.8/vocab/java-small-test_19-02-09T13-18-23_java_-_U0Es0u/vocab\n",
      "2019-08-26 12:30:22,306 [dataprep.infrastructure.stages] INFO: Parsing...\n",
      "2019-08-26 12:30:24,221 [dataprep.infrastructure.stages] INFO: Parsed dataset is up-to-date.\n",
      "2019-08-26 12:30:24,222 [dataprep.infrastructure.stages] INFO: Preprocessing...\n",
      "2019-08-26 12:30:24,224 [dataprep.to_repr] INFO: Reading parsed files from: /home/lv71161/hlibbabii/.cache/dataprep/1.0.0-alpha.8/parsed_datasets/java-small-test_19-02-09T13-18-23_java\n",
      "2019-08-26 12:30:24,225 [dataprep.to_repr] INFO: Writing preprocessed files to /tmp/scratch/prep-datasets/java-small-test_19-02-09T13-18-23_java_-_U0Es0u_-_prep\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 6409/8268 [00:33<00:19, 96.39it/s] Process ForkPoolWorker-13:\n",
      "Process ForkPoolWorker-20:\n",
      "Process ForkPoolWorker-31:\n",
      "Process ForkPoolWorker-32:\n",
      "Process ForkPoolWorker-4:\n",
      "Process ForkPoolWorker-6:\n",
      "Process ForkPoolWorker-24:\n",
      "Process ForkPoolWorker-29:\n",
      "Process ForkPoolWorker-8:\n",
      "Process ForkPoolWorker-3:\n",
      "Process ForkPoolWorker-22:\n",
      "Process ForkPoolWorker-21:\n",
      "Process ForkPoolWorker-19:\n",
      "Process ForkPoolWorker-16:\n",
      "Process ForkPoolWorker-18:\n",
      "Process ForkPoolWorker-17:\n",
      "Process ForkPoolWorker-11:\n",
      "Process ForkPoolWorker-23:\n",
      "Process ForkPoolWorker-14:\n",
      "Process ForkPoolWorker-25:\n",
      "Process ForkPoolWorker-28:\n",
      "Process ForkPoolWorker-27:\n",
      "Process ForkPoolWorker-15:\n",
      "Process ForkPoolWorker-12:\n",
      "Process ForkPoolWorker-26:\n",
      "Process ForkPoolWorker-7:\n",
      "Process ForkPoolWorker-10:\n",
      "Process ForkPoolWorker-2:\n",
      "Process ForkPoolWorker-1:\n",
      "Process ForkPoolWorker-5:\n",
      "Process ForkPoolWorker-30:\n",
      "Process ForkPoolWorker-9:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lv71161/hlibbabii/.pyenv/versions/metrics/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/lv71161/hlibbabii/.pyenv/versions/metrics/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/lv71161/hlibbabii/.pyenv/versions/metrics/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/lv71161/hlibbabii/.pyenv/versions/metrics/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/lv71161/hlibbabii/.pyenv/versions/metrics/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/home/lv71161/hlibbabii/.pyenv/versions/metrics/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/home/lv71161/hlibbabii/.pyenv/versions/metrics/lib/python3.7/multiprocessing/pool.py\", line 44, in mapstar\n",
      "    return list(map(*args))\n",
      "  File \"/home/lv71161/hlibbabii/.pyenv/versions/metrics/lib/python3.7/multiprocessing/pool.py\", line 44, in mapstar\n",
      "    return list(map(*args))\n",
      "  File \"/home/lv71161/hlibbabii/.pyenv/versions/metrics/lib/python3.7/site-packages/dataprep/to_repr.py\", line 57, in preprocess_and_write\n",
      "    with gzip.GzipFile(src_file_path, 'rb') as i, open(not_finished_dest_file_path, 'w') as o:\n",
      "  File \"/home/lv71161/hlibbabii/.pyenv/versions/metrics/lib/python3.7/site-packages/dataprep/to_repr.py\", line 60, in preprocess_and_write\n",
      "    o.write(to_token_str(repr))\n",
      "KeyboardInterrupt\n",
      "  File \"/home/lv71161/hlibbabii/.pyenv/versions/metrics/lib/python3.7/site-packages/dataprep/to_repr.py\", line 42, in to_token_str\n",
      "    return to_literal_str(\" \".join(map(lambda t : str(t),tokens))) + f\" {placeholders['ect']}\\n\"\n",
      "  File \"/home/lv71161/hlibbabii/.pyenv/versions/metrics/lib/python3.7/site-packages/dataprep/to_repr.py\", line 42, in <lambda>\n",
      "    return to_literal_str(\" \".join(map(lambda t : str(t),tokens))) + f\" {placeholders['ect']}\\n\"\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lv71161/hlibbabii/.pyenv/versions/metrics/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/lv71161/hlibbabii/.pyenv/versions/metrics/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/lv71161/hlibbabii/.pyenv/versions/metrics/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/home/lv71161/hlibbabii/.pyenv/versions/metrics/lib/python3.7/multiprocessing/pool.py\", line 44, in mapstar\n",
      "    return list(map(*args))\n",
      "  File \"/home/lv71161/hlibbabii/.pyenv/versions/metrics/lib/python3.7/site-packages/dataprep/to_repr.py\", line 58, in preprocess_and_write\n",
      "    token_list = pickle.load(i)\n",
      "  File \"/home/lv71161/hlibbabii/.pyenv/versions/metrics/lib/python3.7/gzip.py\", line 296, in peek\n",
      "    return self._buffer.peek(n)\n",
      "  File \"/home/lv71161/hlibbabii/.pyenv/versions/metrics/lib/python3.7/_compression.py\", line 68, in readinto\n",
      "    data = self.read(len(byte_view))\n",
      "  File \"/home/lv71161/hlibbabii/.pyenv/versions/metrics/lib/python3.7/gzip.py\", line 463, in read\n",
      "    if not self._read_gzip_header():\n",
      "  File \"/home/lv71161/hlibbabii/.pyenv/versions/metrics/lib/python3.7/gzip.py\", line 406, in _read_gzip_header\n",
      "    magic = self._fp.read(2)\n",
      "  File \"/home/lv71161/hlibbabii/.pyenv/versions/metrics/lib/python3.7/gzip.py\", line 91, in read\n",
      "    self.file.read(size-self._length+read)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m~/.pyenv/versions/metrics/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    732\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 733\u001b[0;31m                 \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_items\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpopleft\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    734\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: pop from an empty deque",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-14536e7dc79f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m                               \"split_numbers\": True, \"ronin\": True, \"stem\": True})\n\u001b[1;32m      4\u001b[0m \u001b[0mdescription\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"[Unsplit, remove non-ascii, remove whitespace, remove comments, remove strings longer than 15 chars + split via conventions, but keep case] + Split numbers + Ronin + Stemming\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescription\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-1-9115db275306>\u001b[0m in \u001b[0;36mrun\u001b[0;34m(prep_function, description)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep_function\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mPrepFunction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescription\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mrow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalc_and_display_stats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescription\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mJAVA_DATASETS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mJAVA_KEYWORDS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'java'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/log-recommender-dataprep/vocabstudy/common.py\u001b[0m in \u001b[0;36mcalc_and_display_stats\u001b[0;34m(prep_function, description, datasets, keywords, extension)\u001b[0m\n\u001b[1;32m    184\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m         \u001b[0mdataset_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPATH_TO_DATASETS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m         \u001b[0mprep_corpus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprep_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCorpus\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextension\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mPATH_TO_PREP_DATASETS_TMP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m         \u001b[0mprep_corpora\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep_corpus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0mvocabs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep_corpus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/log-recommender-dataprep/vocabstudy/common.py\u001b[0m in \u001b[0;36mprep_corpus\u001b[0;34m(corpus, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mprep_corpus\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mCorpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m             return self.callable(corpus.path, *self.params, **self.options, **kwargs,\n\u001b[0;32m---> 67\u001b[0;31m                                  calc_vocab=True, extensions=corpus.extensions)\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mprep_corpus\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/metrics/lib/python3.7/site-packages/dataprep/api/corpus.py\u001b[0m in \u001b[0;36mbasic\u001b[0;34m(path, extensions, split_numbers, ronin, stem, no_spaces, no_unicode, no_case, no_com, no_str, max_str_length, output_path, calc_vocab)\u001b[0m\n\u001b[1;32m    148\u001b[0m                                      \u001b[0mno_com\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mno_com\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mno_str\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mno_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_str_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_str_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m                                      split_numbers=split_numbers or stem or ronin, ronin=ronin or stem, stem=stem)\n\u001b[0;32m--> 150\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mpreprocess_corpus\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprep_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextensions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextensions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcalc_vocab\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcalc_vocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/metrics/lib/python3.7/site-packages/dataprep/api/corpus.py\u001b[0m in \u001b[0;36mpreprocess_corpus\u001b[0;34m(path, prep_config, bpe_codes_id, extensions, output_path, calc_vocab)\u001b[0m\n\u001b[1;32m    196\u001b[0m                              overriden_path_to_prep_dataset=output_path)\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcalc_vocab\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 198\u001b[0;31m         \u001b[0mstages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_until_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_bpe_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m         \u001b[0mpath_to_vocab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath_to_vocab_file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/metrics/lib/python3.7/site-packages/dataprep/infrastructure/stages.py\u001b[0m in \u001b[0;36mrun_until_vocab\u001b[0;34m(dataset, custom_bpe_config)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_path_ready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath_to_vocab_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0mrun_until_preprocessing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_bpe_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Computing vocab...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0mcalc_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/metrics/lib/python3.7/site-packages/dataprep/infrastructure/stages.py\u001b[0m in \u001b[0;36mrun_until_preprocessing\u001b[0;34m(dataset, custom_bpe_config)\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Preprocessing...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mto_repr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_bpe_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_outdated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marchive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/metrics/lib/python3.7/site-packages/dataprep/to_repr.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(dataset, custom_bpe_config)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mPool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0mit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimap_unordered\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreprocess_and_write\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath_to_part_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mCHUNKSIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfiles_total\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/metrics/lib/python3.7/site-packages/tqdm/_tqdm.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1020\u001b[0m                 \"\"\"), fp_write=getattr(self.fp, 'write', sys.stderr.write))\n\u001b[1;32m   1021\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1022\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1023\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/metrics/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    352\u001b[0m                     \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_length\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m                 ))\n\u001b[0;32m--> 354\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    355\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m     def apply_async(self, func, args=(), kwds={}, callback=None,\n",
      "\u001b[0;32m~/.pyenv/versions/metrics/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    735\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_length\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 737\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    738\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m                     \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_items\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpopleft\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/metrics/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "prep_function = PrepFunction(api.basic, [],\n",
    "                             {\"no_unicode\": True, \"no_spaces\": True, \"no_com\": True, \"max_str_length\": 14,\n",
    "                              \"split_numbers\": True, \"ronin\": True, \"stem\": True})\n",
    "description = \"[Unsplit, remove non-ascii, remove whitespace, remove comments, remove strings longer than 15 chars + split via conventions, but keep case] + Split numbers + Ronin + Stemming\"\n",
    "run(prep_function, description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Char model (remove non-ascii, remove whitespace, remove comments, remove strings longer than 15 chars, keep case)\n",
      "\n",
      "2019-08-26 12:30:18,356 [dataprep.infrastructure.stages] INFO: Checking first if vocabulary file exists: /home/lv71161/hlibbabii/.config/dataprep/1.0.0-alpha.8/vocab/java-minus-small-test_19-08-08T23-17-22_java_-_U0E80u/vocab\n",
      "2019-08-26 12:30:18,365 [dataprep.infrastructure.stages] INFO: Vocabulary is already computed and up-to-date\n",
      "2019-08-26 12:30:18,366 [dataprep.api.corpus] INFO: Preprocessed dataset is ready at /tmp/scratch/prep-datasets/java-minus-small-test_19-08-08T23-17-22_java_-_U0E80u_-_prep\n",
      "2019-08-26 12:30:18,568 [dataprep.infrastructure.stages] INFO: Checking first if vocabulary file exists: /home/lv71161/hlibbabii/.config/dataprep/1.0.0-alpha.8/vocab/java-small-test_19-02-09T13-18-23_java_-_U0E80u/vocab\n",
      "2019-08-26 12:30:18,575 [dataprep.infrastructure.stages] INFO: Vocabulary is already computed and up-to-date\n",
      "2019-08-26 12:30:18,575 [dataprep.api.corpus] INFO: Preprocessed dataset is ready at /tmp/scratch/prep-datasets/java-small-test_19-02-09T13-18-23_java_-_U0E80u_-_prep\n",
      "2019-08-26 12:30:18,593 [vocabstudy.common] DEBUG: Checking if train dataset exists: /tmp/scratch/prep-datasets/java-minus-small-test_19-08-08T23-17-22_java_-_U0E80u_-_prep\n",
      "2019-08-26 12:30:18,593 [vocabstudy.common] INFO: Train dataset is found and is going to be removed to save space: /tmp/scratch/prep-datasets/java-minus-small-test_19-08-08T23-17-22_java_-_U0E80u_-_prep. Removing ...\n",
      "2019-08-26 12:30:18,596 [vocabstudy.common] INFO: Moving test dataset from tmp storage: /tmp/scratch/prep-datasets/java-small-test_19-02-09T13-18-23_java_-_U0E80u_-_prep -> /home/lv71161/hlibbabii/prep-datasets\n",
      "2019-08-26 12:30:18,596 [vocabstudy.common] WARNING: Not moving. Path already exists: /home/lv71161/hlibbabii/prep-datasets/java-small-test_19-02-09T13-18-23_java_-_U0E80u_-_prep\n",
      "\n",
      "========================   Split example   =========================\n",
      "\n",
      "['void</t>', 't', 'e', 's', 't', '_', 'W', 'o', 'r', 'd', 'U', 'e', 'b', 'e', 'r', 'r', 'a', 's', 'c', 'h', 'u', 'n', 'g', 'P', 'r', 'i', 'n', 't', 'e', 'r', '</t>', '(</t>', ')</t>', '{</t>', 'if</t>', '(</t>', 'e', 'p', 's', '</t>', '></t>', '=</t>', '0', '.', '3', '4', '5', 'e', '+', '4', '</t>', ')</t>', '{</t>', '<comment>', 'p', 'r', 'i', 'n', 't', 'W', 'o', 'r', 'd', '</t>', '(</t>', '\"', '\"', ')</t>', ';</t>', '}</t>', '}</t>']\n",
      "\n",
      "========================   Stats           =========================\n",
      "\n",
      "Train vocab: 279\n",
      "Test vocab : 178, identifiers: 54 (0.30%)\n",
      "\n",
      "Train corpus size: 4485132432\n",
      "Test corpus size : 21228876, identifiers: 15488805 (0.73%)\n",
      "\n",
      "OOV in test set (top 9223372036854775807): 0 (0.00%), oov tokens number: 0 (0.00%)\n",
      "OOV in test set (top 200000): 0 (0.00%), oov tokens number: 0 (0.00%)\n",
      "OOV in test set (top 100000): 0 (0.00%), oov tokens number: 0 (0.00%)\n",
      "OOV in test set (top 75000): 0 (0.00%), oov tokens number: 0 (0.00%)\n",
      "OOV in test set (top 50000): 0 (0.00%), oov tokens number: 0 (0.00%)\n",
      "OOV in test set (top 25000): 0 (0.00%), oov tokens number: 0 (0.00%)\n",
      "Variation coeff: 0.18285945751460525\n",
      "[17, 40, 34, 6, 182]\n"
     ]
    }
   ],
   "source": [
    "prep_function = PrepFunction(api.chars, [], {\"no_unicode\": True, \"no_spaces\": True, \"no_com\": True, \"max_str_length\": 14})\n",
    "description = \"Char model (remove non-ascii, remove whitespace, remove comments, remove strings longer than 15 chars, keep case)\"\n",
    "\n",
    "run(prep_function, description)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BPE (no unicode, no whitespace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bpe 1k Hellendoorn and Devanbu strings no comments\n",
      "\n",
      "2019-08-26 12:31:03,182 [dataprep.infrastructure.stages] INFO: Checking first if vocabulary file exists: /home/lv71161/hlibbabii/.config/dataprep/1.0.0-alpha.8/vocab/java-minus-small-test_19-08-08T23-17-22_java_-_U0E90u_java-bpe-training_nounicode-1000/vocab\n",
      "2019-08-26 12:31:03,183 [dataprep.infrastructure.stages] INFO: Vocabulary is already computed and up-to-date\n",
      "2019-08-26 12:31:03,184 [dataprep.api.corpus] INFO: Preprocessed dataset is ready at /tmp/scratch/prep-datasets/java-minus-small-test_19-08-08T23-17-22_java_-_U0E90u_java-bpe-training_nounicode-1000_-_prep\n",
      "2019-08-26 12:31:03,267 [dataprep.infrastructure.stages] INFO: Checking first if vocabulary file exists: /home/lv71161/hlibbabii/.config/dataprep/1.0.0-alpha.8/vocab/java-small-test_19-02-09T13-18-23_java_-_U0E90u_java-bpe-training_nounicode-1000/vocab\n",
      "2019-08-26 12:31:03,274 [dataprep.infrastructure.stages] INFO: Vocabulary is already computed and up-to-date\n",
      "2019-08-26 12:31:03,275 [dataprep.api.corpus] INFO: Preprocessed dataset is ready at /tmp/scratch/prep-datasets/java-small-test_19-02-09T13-18-23_java_-_U0E90u_java-bpe-training_nounicode-1000_-_prep\n",
      "2019-08-26 12:31:03,286 [vocabstudy.common] DEBUG: Checking if train dataset exists: /tmp/scratch/prep-datasets/java-minus-small-test_19-08-08T23-17-22_java_-_U0E90u_java-bpe-training_nounicode-1000_-_prep\n",
      "2019-08-26 12:31:03,287 [vocabstudy.common] INFO: Train dataset is found and is going to be removed to save space: /tmp/scratch/prep-datasets/java-minus-small-test_19-08-08T23-17-22_java_-_U0E90u_java-bpe-training_nounicode-1000_-_prep. Removing ...\n",
      "2019-08-26 12:31:03,288 [vocabstudy.common] INFO: Moving test dataset from tmp storage: /tmp/scratch/prep-datasets/java-small-test_19-02-09T13-18-23_java_-_U0E90u_java-bpe-training_nounicode-1000_-_prep -> /home/lv71161/hlibbabii/prep-datasets\n",
      "2019-08-26 12:31:03,298 [vocabstudy.common] WARNING: Not moving. Path already exists: /home/lv71161/hlibbabii/prep-datasets/java-small-test_19-02-09T13-18-23_java_-_U0E90u_java-bpe-training_nounicode-1000_-_prep\n",
      "\n",
      "========================   Split example   =========================\n",
      "\n",
      "2019-08-26 12:31:03,301 [dataprep.to_repr] INFO: Using bpe merges file: /home/lv71161/hlibbabii/.config/dataprep/1.0.0-alpha.8/bpe/java-bpe-training_19-08-01T10-29-09_java_-_nounicode/1000/merges.txt\n",
      "2019-08-26 12:31:03,331 [dataprep.to_repr] INFO: Using first 1000 merges.\n",
      "['void</t>', 'test', '_', 'Wor', 'd', 'U', 'eb', 'err', 'as', 'ch', 'un', 'g', 'P', 'r', 'int', 'er</t>', '(</t>', ')</t>', '{</t>', 'if</t>', '(</t>', 'e', 'p', 's</t>', '></t>', '=</t>', '0.', '3', '4', '5', 'e', '+', '4</t>', ')</t>', '{</t>', '<comment>', 'print', 'Wor', 'd</t>', '(</t>', '\"', '\"', ')</t>', ';</t>', '}</t>', '}</t>']\n",
      "\n",
      "========================   Stats           =========================\n",
      "\n",
      "Train vocab: 1271\n",
      "Test vocab : 1165, identifiers: 712 (0.61%)\n",
      "\n",
      "Train corpus size: 2186538924\n",
      "Test corpus size : 10102803, identifiers: 4472445 (0.44%)\n",
      "\n",
      "OOV in test set (top 9223372036854775807): 0 (0.00%), oov tokens number: 0 (0.00%)\n",
      "OOV in test set (top 200000): 0 (0.00%), oov tokens number: 0 (0.00%)\n",
      "OOV in test set (top 100000): 0 (0.00%), oov tokens number: 0 (0.00%)\n",
      "OOV in test set (top 75000): 0 (0.00%), oov tokens number: 0 (0.00%)\n",
      "OOV in test set (top 50000): 0 (0.00%), oov tokens number: 0 (0.00%)\n",
      "OOV in test set (top 25000): 0 (0.00%), oov tokens number: 0 (0.00%)\n",
      "Variation coeff: 0.10438930426184329\n",
      "[17, 40, 33, 7, 1174]\n"
     ]
    }
   ],
   "source": [
    "prep_function = PrepFunction(api.bpe, ['java-bpe-training_nounicode-1000'], {\"no_com\": True, \"max_str_length\": 14, \"no_unicode\": True, \"no_spaces\": True})\n",
    "description = \"bpe 1k Hellendoorn and Devanbu strings no comments\"\n",
    "run(prep_function, description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bpe 2k Hellendoorn and Devanbu strings no comments\n",
      "\n",
      "2019-08-26 12:31:10,276 [dataprep.infrastructure.stages] INFO: Checking first if vocabulary file exists: /home/lv71161/hlibbabii/.config/dataprep/1.0.0-alpha.8/vocab/java-minus-small-test_19-08-08T23-17-22_java_-_U0E90u_java-bpe-training_nounicode-2000/vocab\n",
      "2019-08-26 12:31:10,284 [dataprep.infrastructure.stages] INFO: Vocabulary is already computed and up-to-date\n",
      "2019-08-26 12:31:10,285 [dataprep.api.corpus] INFO: Preprocessed dataset is ready at /tmp/scratch/prep-datasets/java-minus-small-test_19-08-08T23-17-22_java_-_U0E90u_java-bpe-training_nounicode-2000_-_prep\n",
      "2019-08-26 12:31:10,421 [dataprep.infrastructure.stages] INFO: Checking first if vocabulary file exists: /home/lv71161/hlibbabii/.config/dataprep/1.0.0-alpha.8/vocab/java-small-test_19-02-09T13-18-23_java_-_U0E90u_java-bpe-training_nounicode-2000/vocab\n",
      "2019-08-26 12:31:10,440 [dataprep.infrastructure.stages] INFO: Vocabulary is already computed and up-to-date\n",
      "2019-08-26 12:31:10,441 [dataprep.api.corpus] INFO: Preprocessed dataset is ready at /tmp/scratch/prep-datasets/java-small-test_19-02-09T13-18-23_java_-_U0E90u_java-bpe-training_nounicode-2000_-_prep\n",
      "2019-08-26 12:31:10,478 [vocabstudy.common] DEBUG: Checking if train dataset exists: /tmp/scratch/prep-datasets/java-minus-small-test_19-08-08T23-17-22_java_-_U0E90u_java-bpe-training_nounicode-2000_-_prep\n",
      "2019-08-26 12:31:10,479 [vocabstudy.common] INFO: Train dataset is found and is going to be removed to save space: /tmp/scratch/prep-datasets/java-minus-small-test_19-08-08T23-17-22_java_-_U0E90u_java-bpe-training_nounicode-2000_-_prep. Removing ...\n",
      "2019-08-26 12:31:10,481 [vocabstudy.common] INFO: Moving test dataset from tmp storage: /tmp/scratch/prep-datasets/java-small-test_19-02-09T13-18-23_java_-_U0E90u_java-bpe-training_nounicode-2000_-_prep -> /home/lv71161/hlibbabii/prep-datasets\n",
      "2019-08-26 12:31:10,492 [vocabstudy.common] WARNING: Not moving. Path already exists: /home/lv71161/hlibbabii/prep-datasets/java-small-test_19-02-09T13-18-23_java_-_U0E90u_java-bpe-training_nounicode-2000_-_prep\n",
      "\n",
      "========================   Split example   =========================\n",
      "\n",
      "2019-08-26 12:31:10,497 [dataprep.to_repr] INFO: Using bpe merges file: /home/lv71161/hlibbabii/.config/dataprep/1.0.0-alpha.8/bpe/java-bpe-training_19-08-01T10-29-09_java_-_nounicode/2000/merges.txt\n",
      "2019-08-26 12:31:10,539 [dataprep.to_repr] INFO: Using first 2000 merges.\n",
      "['void</t>', 'test', '_', 'Wor', 'd', 'U', 'eb', 'err', 'as', 'ch', 'un', 'g', 'Pr', 'int', 'er</t>', '(</t>', ')</t>', '{</t>', 'if</t>', '(</t>', 'e', 'ps</t>', '></t>', '=</t>', '0.', '3', '4', '5', 'e', '+', '4</t>', ')</t>', '{</t>', '<comment>', 'print', 'Wor', 'd</t>', '(</t>', '\"', '\"', ')</t>', ';</t>', '}</t>', '}</t>']\n",
      "\n",
      "========================   Stats           =========================\n",
      "\n",
      "Train vocab: 2271\n",
      "Test vocab : 2108, identifiers: 1285 (0.61%)\n",
      "\n",
      "Train corpus size: 1944950540\n",
      "Test corpus size : 8982886, identifiers: 3365217 (0.37%)\n",
      "\n",
      "OOV in test set (top 9223372036854775807): 0 (0.00%), oov tokens number: 0 (0.00%)\n",
      "OOV in test set (top 200000): 0 (0.00%), oov tokens number: 0 (0.00%)\n",
      "OOV in test set (top 100000): 0 (0.00%), oov tokens number: 0 (0.00%)\n",
      "OOV in test set (top 75000): 0 (0.00%), oov tokens number: 0 (0.00%)\n",
      "OOV in test set (top 50000): 0 (0.00%), oov tokens number: 0 (0.00%)\n",
      "OOV in test set (top 25000): 0 (0.00%), oov tokens number: 0 (0.00%)\n",
      "Variation coeff: 0.11577439393247807\n",
      "[17, 40, 33, 12, 2169]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 6409/8268 [00:49<00:19, 96.39it/s]"
     ]
    }
   ],
   "source": [
    "prep_function = PrepFunction(api.bpe, ['java-bpe-training_nounicode-2000'], {\"no_com\": True, \"max_str_length\": 14, \"no_unicode\": True, \"no_spaces\": True})\n",
    "description = \"bpe 2k Hellendoorn and Devanbu strings no comments\"\n",
    "run(prep_function, description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bpe 5k Hellendoorn and Devanbu strings no comments\n",
      "\n",
      "2019-08-26 12:32:38,301 [dataprep.infrastructure.stages] INFO: Checking first if vocabulary file exists: /home/lv71161/hlibbabii/.config/dataprep/1.0.0-alpha.8/vocab/java-minus-small-test_19-08-08T23-17-22_java_-_U0E90u_java-bpe-training_nounicode-5000/vocab\n",
      "2019-08-26 12:32:38,316 [dataprep.infrastructure.stages] INFO: Vocabulary is already computed and up-to-date\n",
      "2019-08-26 12:32:38,317 [dataprep.api.corpus] INFO: Preprocessed dataset is ready at /tmp/scratch/prep-datasets/java-minus-small-test_19-08-08T23-17-22_java_-_U0E90u_java-bpe-training_nounicode-5000_-_prep\n",
      "2019-08-26 12:32:38,526 [dataprep.infrastructure.stages] INFO: Checking first if vocabulary file exists: /home/lv71161/hlibbabii/.config/dataprep/1.0.0-alpha.8/vocab/java-small-test_19-02-09T13-18-23_java_-_U0E90u_java-bpe-training_nounicode-5000/vocab\n",
      "2019-08-26 12:32:38,528 [dataprep.infrastructure.stages] INFO: Vocabulary is already computed and up-to-date\n",
      "2019-08-26 12:32:38,529 [dataprep.api.corpus] INFO: Preprocessed dataset is ready at /tmp/scratch/prep-datasets/java-small-test_19-02-09T13-18-23_java_-_U0E90u_java-bpe-training_nounicode-5000_-_prep\n",
      "2019-08-26 12:32:38,561 [vocabstudy.common] DEBUG: Checking if train dataset exists: /tmp/scratch/prep-datasets/java-minus-small-test_19-08-08T23-17-22_java_-_U0E90u_java-bpe-training_nounicode-5000_-_prep\n",
      "2019-08-26 12:32:38,562 [vocabstudy.common] INFO: Train dataset is found and is going to be removed to save space: /tmp/scratch/prep-datasets/java-minus-small-test_19-08-08T23-17-22_java_-_U0E90u_java-bpe-training_nounicode-5000_-_prep. Removing ...\n",
      "2019-08-26 12:32:38,565 [vocabstudy.common] INFO: Moving test dataset from tmp storage: /tmp/scratch/prep-datasets/java-small-test_19-02-09T13-18-23_java_-_U0E90u_java-bpe-training_nounicode-5000_-_prep -> /home/lv71161/hlibbabii/prep-datasets\n",
      "2019-08-26 12:32:38,580 [vocabstudy.common] WARNING: Not moving. Path already exists: /home/lv71161/hlibbabii/prep-datasets/java-small-test_19-02-09T13-18-23_java_-_U0E90u_java-bpe-training_nounicode-5000_-_prep\n",
      "\n",
      "========================   Split example   =========================\n",
      "\n",
      "2019-08-26 12:32:38,585 [dataprep.to_repr] INFO: Using bpe merges file: /home/lv71161/hlibbabii/.config/dataprep/1.0.0-alpha.8/bpe/java-bpe-training_19-08-01T10-29-09_java_-_nounicode/5000/merges.txt\n",
      "2019-08-26 12:32:38,645 [dataprep.to_repr] INFO: Using first 5000 merges.\n",
      "['void</t>', 'test', '_', 'Wor', 'd', 'U', 'eb', 'err', 'as', 'ch', 'un', 'g', 'Print', 'er</t>', '(</t>', ')</t>', '{</t>', 'if</t>', '(</t>', 'e', 'ps</t>', '></t>', '=</t>', '0.', '34', '5', 'e+', '4</t>', ')</t>', '{</t>', '<comment>', 'print', 'Wor', 'd</t>', '(</t>', '\"', '\"', ')</t>', ';</t>', '}</t>', '}</t>']\n",
      "\n",
      "========================   Stats           =========================\n",
      "\n",
      "Train vocab: 5264\n",
      "Test vocab : 4729, identifiers: 2699 (0.57%)\n",
      "\n",
      "Train corpus size: 1703338207\n",
      "Test corpus size : 7837256, identifiers: 2254301 (0.29%)\n",
      "\n",
      "OOV in test set (top 9223372036854775807): 0 (0.00%), oov tokens number: 0 (0.00%)\n",
      "OOV in test set (top 200000): 0 (0.00%), oov tokens number: 0 (0.00%)\n",
      "OOV in test set (top 100000): 0 (0.00%), oov tokens number: 0 (0.00%)\n",
      "OOV in test set (top 75000): 0 (0.00%), oov tokens number: 0 (0.00%)\n",
      "OOV in test set (top 50000): 0 (0.00%), oov tokens number: 0 (0.00%)\n",
      "OOV in test set (top 25000): 0 (0.00%), oov tokens number: 0 (0.00%)\n",
      "Variation coeff: 0.13132573662531788\n",
      "[18, 42, 42, 45, 5117]\n"
     ]
    }
   ],
   "source": [
    "prep_function = PrepFunction(api.bpe, ['java-bpe-training_nounicode-5000'], {\"no_com\": True, \"max_str_length\": 14, \"no_unicode\": True, \"no_spaces\": True})\n",
    "description = \"bpe 5k Hellendoorn and Devanbu strings no comments\"\n",
    "run(prep_function, description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bpe 10k Hellendoorn and Devanbu strings no comments\n",
      "\n",
      "2019-08-26 12:32:45,196 [dataprep.infrastructure.stages] INFO: Checking first if vocabulary file exists: /home/lv71161/hlibbabii/.config/dataprep/1.0.0-alpha.8/vocab/java-minus-small-test_19-08-08T23-17-22_java_-_U0E90u_java-bpe-training_nounicode-10000/vocab\n",
      "2019-08-26 12:32:45,198 [dataprep.infrastructure.stages] INFO: Vocabulary is already computed and up-to-date\n",
      "2019-08-26 12:32:45,199 [dataprep.api.corpus] INFO: Preprocessed dataset is ready at /tmp/scratch/prep-datasets/java-minus-small-test_19-08-08T23-17-22_java_-_U0E90u_java-bpe-training_nounicode-10000_-_prep\n",
      "2019-08-26 12:32:45,360 [dataprep.infrastructure.stages] INFO: Checking first if vocabulary file exists: /home/lv71161/hlibbabii/.config/dataprep/1.0.0-alpha.8/vocab/java-small-test_19-02-09T13-18-23_java_-_U0E90u_java-bpe-training_nounicode-10000/vocab\n",
      "2019-08-26 12:32:45,377 [dataprep.infrastructure.stages] INFO: Vocabulary is already computed and up-to-date\n",
      "2019-08-26 12:32:45,379 [dataprep.api.corpus] INFO: Preprocessed dataset is ready at /tmp/scratch/prep-datasets/java-small-test_19-02-09T13-18-23_java_-_U0E90u_java-bpe-training_nounicode-10000_-_prep\n",
      "2019-08-26 12:32:45,439 [vocabstudy.common] DEBUG: Checking if train dataset exists: /tmp/scratch/prep-datasets/java-minus-small-test_19-08-08T23-17-22_java_-_U0E90u_java-bpe-training_nounicode-10000_-_prep\n",
      "2019-08-26 12:32:45,440 [vocabstudy.common] INFO: Train dataset is found and is going to be removed to save space: /tmp/scratch/prep-datasets/java-minus-small-test_19-08-08T23-17-22_java_-_U0E90u_java-bpe-training_nounicode-10000_-_prep. Removing ...\n",
      "2019-08-26 12:32:45,443 [vocabstudy.common] INFO: Moving test dataset from tmp storage: /tmp/scratch/prep-datasets/java-small-test_19-02-09T13-18-23_java_-_U0E90u_java-bpe-training_nounicode-10000_-_prep -> /home/lv71161/hlibbabii/prep-datasets\n",
      "2019-08-26 12:32:45,467 [vocabstudy.common] WARNING: Not moving. Path already exists: /home/lv71161/hlibbabii/prep-datasets/java-small-test_19-02-09T13-18-23_java_-_U0E90u_java-bpe-training_nounicode-10000_-_prep\n",
      "\n",
      "========================   Split example   =========================\n",
      "\n",
      "2019-08-26 12:32:45,473 [dataprep.to_repr] INFO: Using bpe merges file: /home/lv71161/hlibbabii/.config/dataprep/1.0.0-alpha.8/bpe/java-bpe-training_19-08-01T10-29-09_java_-_nounicode/10000/merges.txt\n",
      "2019-08-26 12:32:45,569 [dataprep.to_repr] INFO: Using first 10000 merges.\n",
      "['void</t>', 'test_', 'Word', 'U', 'eb', 'err', 'as', 'ch', 'un', 'g', 'Print', 'er</t>', '(</t>', ')</t>', '{</t>', 'if</t>', '(</t>', 'e', 'ps</t>', '></t>', '=</t>', '0.', '34', '5', 'e+', '4</t>', ')</t>', '{</t>', '<comment>', 'print', 'Word</t>', '(</t>', '\"', '\"', ')</t>', ';</t>', '}</t>', '}</t>']\n",
      "\n",
      "========================   Stats           =========================\n",
      "\n",
      "Train vocab: 10254\n",
      "Test vocab : 8567, identifiers: 4560 (0.53%)\n",
      "\n",
      "Train corpus size: 1574232279\n",
      "Test corpus size : 7286896, identifiers: 1722139 (0.24%)\n",
      "\n",
      "OOV in test set (top 9223372036854775807): 0 (0.00%), oov tokens number: 0 (0.00%)\n",
      "OOV in test set (top 200000): 0 (0.00%), oov tokens number: 0 (0.00%)\n",
      "OOV in test set (top 100000): 0 (0.00%), oov tokens number: 0 (0.00%)\n",
      "OOV in test set (top 75000): 0 (0.00%), oov tokens number: 0 (0.00%)\n",
      "OOV in test set (top 50000): 0 (0.00%), oov tokens number: 0 (0.00%)\n",
      "OOV in test set (top 25000): 0 (0.00%), oov tokens number: 0 (0.00%)\n",
      "Variation coeff: 0.14169873000879668\n",
      "[19, 56, 73, 146, 9960]\n"
     ]
    }
   ],
   "source": [
    "prep_function = PrepFunction(api.bpe, ['java-bpe-training_nounicode-10000'], {\"no_com\": True, \"max_str_length\": 14, \"no_unicode\": True, \"no_spaces\": True})\n",
    "description = \"bpe 10k Hellendoorn and Devanbu strings no comments\"\n",
    "run(prep_function, description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bpe 20k Hellendoorn and Devanbu strings no comments\n",
      "\n",
      "2019-08-26 12:32:54,178 [dataprep.infrastructure.stages] INFO: Checking first if vocabulary file exists: /home/lv71161/hlibbabii/.config/dataprep/1.0.0-alpha.8/vocab/java-minus-small-test_19-08-08T23-17-22_java_-_U0E90u_java-bpe-training_nounicode-20000/vocab\n",
      "2019-08-26 12:32:54,204 [dataprep.infrastructure.stages] INFO: Vocabulary is already computed and up-to-date\n",
      "2019-08-26 12:32:54,205 [dataprep.api.corpus] INFO: Preprocessed dataset is ready at /tmp/scratch/prep-datasets/java-minus-small-test_19-08-08T23-17-22_java_-_U0E90u_java-bpe-training_nounicode-20000_-_prep\n",
      "2019-08-26 12:32:54,378 [dataprep.infrastructure.stages] INFO: Checking first if vocabulary file exists: /home/lv71161/hlibbabii/.config/dataprep/1.0.0-alpha.8/vocab/java-small-test_19-02-09T13-18-23_java_-_U0E90u_java-bpe-training_nounicode-20000/vocab\n",
      "2019-08-26 12:32:54,413 [dataprep.infrastructure.stages] INFO: Vocabulary is already computed and up-to-date\n",
      "2019-08-26 12:32:54,414 [dataprep.api.corpus] INFO: Preprocessed dataset is ready at /tmp/scratch/prep-datasets/java-small-test_19-02-09T13-18-23_java_-_U0E90u_java-bpe-training_nounicode-20000_-_prep\n",
      "2019-08-26 12:32:54,521 [vocabstudy.common] DEBUG: Checking if train dataset exists: /tmp/scratch/prep-datasets/java-minus-small-test_19-08-08T23-17-22_java_-_U0E90u_java-bpe-training_nounicode-20000_-_prep\n",
      "2019-08-26 12:32:54,522 [vocabstudy.common] INFO: Train dataset is found and is going to be removed to save space: /tmp/scratch/prep-datasets/java-minus-small-test_19-08-08T23-17-22_java_-_U0E90u_java-bpe-training_nounicode-20000_-_prep. Removing ...\n",
      "2019-08-26 12:32:54,524 [vocabstudy.common] INFO: Moving test dataset from tmp storage: /tmp/scratch/prep-datasets/java-small-test_19-02-09T13-18-23_java_-_U0E90u_java-bpe-training_nounicode-20000_-_prep -> /home/lv71161/hlibbabii/prep-datasets\n",
      "2019-08-26 12:32:54,526 [vocabstudy.common] WARNING: Not moving. Path already exists: /home/lv71161/hlibbabii/prep-datasets/java-small-test_19-02-09T13-18-23_java_-_U0E90u_java-bpe-training_nounicode-20000_-_prep\n",
      "\n",
      "========================   Split example   =========================\n",
      "\n",
      "2019-08-26 12:32:54,532 [dataprep.to_repr] INFO: Using bpe merges file: /home/lv71161/hlibbabii/.config/dataprep/1.0.0-alpha.8/bpe/java-bpe-training_19-08-01T10-29-09_java_-_nounicode/20000/merges.txt\n",
      "2019-08-26 12:32:54,718 [dataprep.to_repr] INFO: Using first 20000 merges.\n",
      "['void</t>', 'test_', 'Word', 'U', 'eb', 'err', 'as', 'ch', 'un', 'g', 'Printer</t>', '(</t>', ')</t>', '{</t>', 'if</t>', '(</t>', 'e', 'ps</t>', '></t>', '=</t>', '0.', '34', '5', 'e+', '4</t>', ')</t>', '{</t>', '<comment>', 'print', 'Word</t>', '(</t>', '\"', '\"', ')</t>', ';</t>', '}</t>', '}</t>']\n",
      "\n",
      "========================   Stats           =========================\n",
      "\n",
      "Train vocab: 20194\n",
      "Test vocab : 14258, identifiers: 6992 (0.49%)\n",
      "\n",
      "Train corpus size: 1489322529\n",
      "Test corpus size : 6926011, identifiers: 1375473 (0.20%)\n",
      "\n",
      "OOV in test set (top 9223372036854775807): 0 (0.00%), oov tokens number: 0 (0.00%)\n",
      "OOV in test set (top 200000): 0 (0.00%), oov tokens number: 0 (0.00%)\n",
      "OOV in test set (top 100000): 0 (0.00%), oov tokens number: 0 (0.00%)\n",
      "OOV in test set (top 75000): 0 (0.00%), oov tokens number: 0 (0.00%)\n",
      "OOV in test set (top 50000): 0 (0.00%), oov tokens number: 0 (0.00%)\n",
      "OOV in test set (top 25000): 0 (0.00%), oov tokens number: 0 (0.00%)\n",
      "Variation coeff: 0.1495952120715133\n",
      "[23, 90, 171, 1447, 18463]\n"
     ]
    }
   ],
   "source": [
    "prep_function = PrepFunction(api.bpe, ['java-bpe-training_nounicode-20000'], {\"no_com\": True, \"max_str_length\": 14, \"no_unicode\": True, \"no_spaces\": True})\n",
    "description = \"bpe 20k Hellendoorn and Devanbu strings no comments\"\n",
    "run(prep_function, description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_function = PrepFunction(api.bpe, ['java-bpe-training_nounicode-1000'], {\"no_unicode\": True, 'no_spaces': True})\n",
    "description = \"bpe 1k\"\n",
    "run(prep_function, description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_function = PrepFunction(api.bpe, ['java-bpe-training_nounicode-2000'], {\"no_unicode\": True, 'no_spaces': True})\n",
    "description = \"bpe 2k\"\n",
    "run(prep_function, description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_function = PrepFunction(api.bpe, ['java-bpe-training_nounicode-5000'], {\"no_unicode\": True, 'no_spaces': True})\n",
    "description = \"bpe 5k\"\n",
    "run(prep_function, description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_function = PrepFunction(api.bpe, ['java-bpe-training_nounicode-10000'], {\"no_unicode\": True, 'no_spaces': True})\n",
    "description = \"bpe 10k\"\n",
    "run(prep_function, description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_function = PrepFunction(api.bpe, ['java-bpe-training_nounicode-20000'], {\"no_unicode\": True, 'no_spaces': True})\n",
    "description = \"bpe 20k\"\n",
    "run(prep_function, description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_function = PrepFunction(api.bpe, ['java-bpe-training_nounicode-1000'], {\"no_com\": True, \"no_str\": True, \"no_unicode\": True, \"no_spaces\": True})\n",
    "description = \"bpe 1k no strings no comments\"\n",
    "run(prep_function, description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "prep_function = PrepFunction(api.bpe, ['java-bpe-training_nounicode-2000'], {\"no_com\": True, \"no_str\": True, \"no_unicode\": True, \"no_spaces\": True})\n",
    "description = \"bpe 2k no strings no comments\"\n",
    "run(prep_function, description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "prep_function = PrepFunction(api.bpe, ['java-bpe-training_nounicode-5000'], {\"no_com\": True, \"no_str\": True, \"no_unicode\": True, \"no_spaces\": True})\n",
    "description = \"bpe 5k no strings no comments\"\n",
    "run(prep_function, description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_function = PrepFunction(api.bpe, ['java-bpe-training_nounicode-10000'], {\"no_com\": True, \"no_str\": True, \"no_unicode\": True, \"no_spaces\": True})\n",
    "description = \"bpe 10k no strings no comments\"\n",
    "run(prep_function, description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_function = PrepFunction(api.bpe, ['java-bpe-training_nounicode-20000'], {\"no_com\": True, \"no_str\": True, \"no_unicode\": True, \"no_spaces\": True})\n",
    "description = \"bpe 20k no strings no comments\"\n",
    "run(prep_function, description)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "metrics",
   "language": "python",
   "name": "metrics"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
