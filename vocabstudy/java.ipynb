{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataprep.api.corpus as api\n",
    "from vocabstudy.common import PrepFunction, calc_and_display_stats, VocabStatsCsvWriter, HEADER, HOME\n",
    "JAVA_KEYWORDS = {\"abstract\", \"assert\", \"boolean\", \"break\", \"byte\", \"case\", \"catch\", \"char\",\n",
    "            \"class\", \"const\", \"continue\", \"default\", \"do\", \"double\", \"else\", \"enum\", \"extends\", \"final\", \"finally\",\n",
    "            \"float\", \"for\", \"goto\", \"if\", \"implements\", \"import\", \"instanceof\", \"int\", \"interface\", \"long\", \"native\",\n",
    "            \"new\", \"package\", \"private\", \"protected\", \"public\", \"return\", \"short\", \"static\", \"strictfp\", \"super\",\n",
    "            \"switch\", \"synchronized\", \"this\", \"throw\", \"throws\", \"transient\", \"try\", \"void\", \"volatile\", \"while\",\n",
    "            \"true\", \"false\", \"null\"}\n",
    "\n",
    "JAVA_DATASETS = (\n",
    "    'allamanis/java-minus-small-test',\n",
    "    'allamanis/java-small-test'\n",
    ")\n",
    "\n",
    "writer = VocabStatsCsvWriter(os.path.join(HOME, 'java-stats.csv'), HEADER)\n",
    "\n",
    "def run(prep_function: PrepFunction, description: str) -> None:\n",
    "    row = calc_and_display_stats(prep_function, description, JAVA_DATASETS, JAVA_KEYWORDS, 'java')\n",
    "    writer.write_line(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.0.0-alpha.8'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dataprep\n",
    "\n",
    "dataprep.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unsplit corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unsplit, with comments and vocabulary. No filtering.\n",
      "\n",
      "2019-08-18 23:27:54,149 [dataprep.infrastructure.stages] INFO: Checking first if vocabulary file exists: /home/lv71161/hlibbabii/.config/dataprep/1.0.0-alpha.8/vocab/java-small-test_19-02-09T13-18-23_java_-_uc10su/vocab\n",
      "2019-08-18 23:27:54,150 [dataprep.infrastructure.stages] INFO: Vocabulary is already computed and up-to-date\n",
      "2019-08-18 23:27:54,151 [dataprep.api.corpus] INFO: Preprocessed dataset is ready at /home/lv71161/hlibbabii/prep-datasets/java-small-test_19-02-09T13-18-23_java_-_uc10su_-_prep\n",
      "2019-08-18 23:27:55,307 [dataprep.infrastructure.stages] INFO: Checking first if vocabulary file exists: /home/lv71161/hlibbabii/.config/dataprep/1.0.0-alpha.8/vocab/java-small-test_19-02-09T13-18-23_java_-_uc10su/vocab\n",
      "2019-08-18 23:27:55,308 [dataprep.infrastructure.stages] INFO: Vocabulary is already computed and up-to-date\n",
      "2019-08-18 23:27:55,309 [dataprep.api.corpus] INFO: Preprocessed dataset is ready at /home/lv71161/hlibbabii/prep-datasets/java-small-test_19-02-09T13-18-23_java_-_uc10su_-_prep\n",
      "Removing prepped dataset at /home/lv71161/hlibbabii/prep-datasets/java-small-test_19-02-09T13-18-23_java_-_uc10su_-_prep\n",
      "\n",
      "========================   Split example   =========================\n",
      "\n",
      "['void', 'test_WordUeberraschungPrinter', '(', ')', '{', '\\n', '\\t', 'if', '(', 'eps', '>', '=', '0.345e+4', ')', '{', '/', '/', 'FIXME', '10l', '\\n', '<EOL>', '\\t', '\\t', 'printWord', '(', '\"', '.', '.', '.', 'Überraschung', '0x12', '\"', ')', ';', '\\n', '\\t', '}', '\\n', '}']\n",
      "\n",
      "========================   Stats           =========================\n",
      "\n",
      "Train vocab: 100974\n",
      "Test vocab : 100974, identifiers: 86612 (0.86%)\n",
      "\n",
      "Train corpus size: 10650037\n",
      "Test corpus size : 10650037, identifiers: 3029114 (0.28%)\n",
      "\n",
      "OOV in test set (top 9223372036854775807): 0 (0.00%), oov tokens number: 0 (0.00%)\n",
      "OOV in test set (top 200000): 0 (0.00%), oov tokens number: 0 (0.00%)\n",
      "OOV in test set (top 100000): 974 (0.96%), oov tokens number: 974 (0.01%)\n",
      "OOV in test set (top 75000): 25974 (25.72%), oov tokens number: 25974 (0.24%)\n",
      "OOV in test set (top 50000): 50974 (50.48%), oov tokens number: 78627 (0.74%)\n",
      "OOV in test set (top 25000): 75974 (75.24%), oov tokens number: 189917 (1.78%)\n",
      "\n",
      "For identifiers: \n",
      "\n",
      "OOV in test set (top 9223372036854775807): 0 (0.00%), oov tokens number: 0 (0.00%)\n",
      "OOV in test set (top 200000): 0 (0.00%), oov tokens number: 0 (0.00%)\n",
      "OOV in test set (top 100000): 658 (0.76%), oov tokens number: 658 (0.02%)\n",
      "OOV in test set (top 75000): 16988 (19.61%), oov tokens number: 16988 (0.56%)\n",
      "OOV in test set (top 50000): 39012 (45.04%), oov tokens number: 63764 (2.11%)\n",
      "OOV in test set (top 25000): 62549 (72.22%), oov tokens number: 168988 (5.58%)\n",
      "[27307, 55199, 15333, 2620, 515]\n"
     ]
    }
   ],
   "source": [
    "prep_function = PrepFunction(api.nosplit)\n",
    "description = \"unsplit, with comments and strings. No filtering.\"\n",
    "\n",
    "run(prep_function, description)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering non-ASCII tokens\n",
      "\n",
      "2019-08-14 11:04:30,149 [dataprep.infrastructure.stages] INFO: Checking first if vocabulary file exists: /home/lv71161/hlibbabii/.config/dataprep/1.0.0-alpha.8/vocab/java-minus-small-test_19-08-08T23-17-22_java_-_Uc10su/vocab\n",
      "2019-08-14 11:04:30,177 [dataprep.infrastructure.stages] INFO: Vocabulary is already computed and up-to-date\n",
      "2019-08-14 11:04:30,179 [dataprep.api.corpus] INFO: Preprocessed dataset is ready at /home/lv71161/hlibbabii/prep-datasets/java-minus-small-test_19-08-08T23-17-22_java_-_Uc10su_-_prep\n",
      "2019-08-14 11:05:03,034 [dataprep.infrastructure.stages] INFO: Checking first if vocabulary file exists: /home/lv71161/hlibbabii/.config/dataprep/1.0.0-alpha.8/vocab/java-small-test_19-02-09T13-18-23_java_-_Uc10su/vocab\n",
      "2019-08-14 11:05:03,037 [dataprep.infrastructure.stages] INFO: Vocabulary is already computed and up-to-date\n",
      "2019-08-14 11:05:03,037 [dataprep.api.corpus] INFO: Preprocessed dataset is ready at /home/lv71161/hlibbabii/prep-datasets/java-small-test_19-02-09T13-18-23_java_-_Uc10su_-_prep\n",
      "Removing prepped dataset at /home/lv71161/hlibbabii/prep-datasets/java-minus-small-test_19-08-08T23-17-22_java_-_Uc10su_-_prep\n",
      "\n",
      "========================   Split example   =========================\n",
      "\n",
      "['void', 'test_WordUeberraschungPrinter', '(', ')', '{', '\\n', '\\t', 'if', '(', 'eps', '>', '=', '0.345e+4', ')', '{', '/', '/', 'FIXME', '10l', '\\n', '<EOL>', '\\t', '\\t', 'printWord', '(', '\"', '.', '.', '.', '<non-en>', '0x12', '\"', ')', ';', '\\n', '\\t', '}', '\\n', '}']\n",
      "\n",
      "========================   Stats           =========================\n",
      "\n",
      "Train vocab: 11418908\n",
      "Test vocab : 89185, identifiers: 86577 (0.97%)\n",
      "\n",
      "Train corpus size: 2431144083\n",
      "Test corpus size : 10650037, identifiers: 3029037 (0.28%)\n",
      "\n",
      "OOV in test set (top 9223372036854775807): 31158 (34.94%), oov tokens number: 237321 (2.23%)\n",
      "OOV in test set (top 200000): 60446 (67.78%), oov tokens number: 458410 (4.30%)\n",
      "OOV in test set (top 100000): 65607 (73.56%), oov tokens number: 511282 (4.80%)\n",
      "OOV in test set (top 75000): 67831 (76.06%), oov tokens number: 547073 (5.14%)\n",
      "OOV in test set (top 50000): 70888 (79.48%), oov tokens number: 593344 (5.57%)\n",
      "OOV in test set (top 25000): 76008 (85.23%), oov tokens number: 661442 (6.21%)\n",
      "\n",
      "For identifiers: \n",
      "\n",
      "OOV in test set (top 9223372036854775807): 30699 (35.46%), oov tokens number: 236576 (7.81%)\n",
      "OOV in test set (top 200000): 59263 (68.45%), oov tokens number: 456233 (15.06%)\n",
      "OOV in test set (top 100000): 64193 (74.15%), oov tokens number: 508717 (16.79%)\n",
      "OOV in test set (top 75000): 66255 (76.53%), oov tokens number: 544227 (17.97%)\n",
      "OOV in test set (top 50000): 69105 (79.82%), oov tokens number: 589954 (19.48%)\n",
      "OOV in test set (top 25000): 74010 (85.48%), oov tokens number: 657259 (21.70%)\n",
      "[2759470, 6667800, 1749998, 209256, 32384]\n"
     ]
    }
   ],
   "source": [
    "prep_function = PrepFunction(api.nosplit, [], {\"no_unicode\": True})\n",
    "description = \"Filtering non-ASCII tokens\"\n",
    "\n",
    "run(prep_function, description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering whitespace (+ non-ascii)\n",
      "\n",
      "2019-08-14 11:07:51,950 [dataprep.infrastructure.stages] INFO: Checking first if vocabulary file exists: /home/lv71161/hlibbabii/.config/dataprep/1.0.0-alpha.8/vocab/java-minus-small-test_19-08-08T23-17-22_java_-_Uc100u/vocab\n",
      "2019-08-14 11:07:51,972 [dataprep.infrastructure.stages] INFO: Vocabulary is already computed and up-to-date\n",
      "2019-08-14 11:07:51,972 [dataprep.api.corpus] INFO: Preprocessed dataset is ready at /home/lv71161/hlibbabii/prep-datasets/java-minus-small-test_19-08-08T23-17-22_java_-_Uc100u_-_prep\n",
      "2019-08-14 11:08:24,462 [dataprep.infrastructure.stages] INFO: Checking first if vocabulary file exists: /home/lv71161/hlibbabii/.config/dataprep/1.0.0-alpha.8/vocab/java-small-test_19-02-09T13-18-23_java_-_Uc100u/vocab\n",
      "2019-08-14 11:08:24,494 [dataprep.infrastructure.stages] INFO: Vocabulary is already computed and up-to-date\n",
      "2019-08-14 11:08:24,495 [dataprep.api.corpus] INFO: Preprocessed dataset is ready at /home/lv71161/hlibbabii/prep-datasets/java-small-test_19-02-09T13-18-23_java_-_Uc100u_-_prep\n",
      "Removing prepped dataset at /home/lv71161/hlibbabii/prep-datasets/java-minus-small-test_19-08-08T23-17-22_java_-_Uc100u_-_prep\n",
      "\n",
      "========================   Split example   =========================\n",
      "\n",
      "['void', 'test_WordUeberraschungPrinter', '(', ')', '{', 'if', '(', 'eps', '>', '=', '0.345e+4', ')', '{', '/', '/', 'FIXME', '10l', '<EOL>', 'printWord', '(', '\"', '.', '.', '.', '<non-en>', '0x12', '\"', ')', ';', '}', '}']\n",
      "\n",
      "========================   Stats           =========================\n",
      "\n",
      "Train vocab: 11418906\n",
      "Test vocab : 89184, identifiers: 86578 (0.97%)\n",
      "\n",
      "Train corpus size: 1892510212\n",
      "Test corpus size : 8341935, identifiers: 3029038 (0.36%)\n",
      "\n",
      "OOV in test set (top 9223372036854775807): 31158 (34.94%), oov tokens number: 237321 (2.84%)\n",
      "OOV in test set (top 200000): 60446 (67.78%), oov tokens number: 458458 (5.50%)\n",
      "OOV in test set (top 100000): 65608 (73.56%), oov tokens number: 511199 (6.13%)\n",
      "OOV in test set (top 75000): 67830 (76.06%), oov tokens number: 547008 (6.56%)\n",
      "OOV in test set (top 50000): 70888 (79.49%), oov tokens number: 593313 (7.11%)\n",
      "OOV in test set (top 25000): 76009 (85.23%), oov tokens number: 661447 (7.93%)\n",
      "\n",
      "For identifiers: \n",
      "\n",
      "OOV in test set (top 9223372036854775807): 30699 (35.46%), oov tokens number: 236576 (7.81%)\n",
      "OOV in test set (top 200000): 59263 (68.45%), oov tokens number: 456281 (15.06%)\n",
      "OOV in test set (top 100000): 64195 (74.15%), oov tokens number: 508635 (16.79%)\n",
      "OOV in test set (top 75000): 66254 (76.53%), oov tokens number: 544162 (17.96%)\n",
      "OOV in test set (top 50000): 69105 (79.82%), oov tokens number: 589923 (19.48%)\n",
      "OOV in test set (top 25000): 74011 (85.48%), oov tokens number: 657264 (21.70%)\n",
      "[2759470, 6667799, 1749998, 209257, 32382]\n"
     ]
    }
   ],
   "source": [
    "prep_function = PrepFunction(api.nosplit, [], {\"no_unicode\": True, \"no_spaces\": True})\n",
    "description = \"Filtering whitespace (+ non-ascii)\"\n",
    "\n",
    "run(prep_function, description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering comments (+ whitespace, + non-ascii)\n",
      "\n",
      "2019-08-14 11:09:04,071 [dataprep.infrastructure.stages] INFO: Checking first if vocabulary file exists: /home/lv71161/hlibbabii/.config/dataprep/1.0.0-alpha.8/vocab/java-minus-small-test_19-08-08T23-17-22_java_-_U0100u/vocab\n",
      "2019-08-14 11:09:04,159 [dataprep.infrastructure.stages] INFO: Vocabulary is already computed and up-to-date\n",
      "2019-08-14 11:09:04,160 [dataprep.api.corpus] INFO: Preprocessed dataset is ready at /home/lv71161/hlibbabii/prep-datasets/java-minus-small-test_19-08-08T23-17-22_java_-_U0100u_-_prep\n",
      "2019-08-14 11:09:38,090 [dataprep.infrastructure.stages] INFO: Checking first if vocabulary file exists: /home/lv71161/hlibbabii/.config/dataprep/1.0.0-alpha.8/vocab/java-small-test_19-02-09T13-18-23_java_-_U0100u/vocab\n",
      "2019-08-14 11:09:38,245 [dataprep.infrastructure.stages] INFO: Vocabulary is already computed and up-to-date\n",
      "2019-08-14 11:09:38,246 [dataprep.api.corpus] INFO: Preprocessed dataset is ready at /home/lv71161/hlibbabii/prep-datasets/java-small-test_19-02-09T13-18-23_java_-_U0100u_-_prep\n",
      "Removing prepped dataset at /home/lv71161/hlibbabii/prep-datasets/java-minus-small-test_19-08-08T23-17-22_java_-_U0100u_-_prep\n",
      "\n",
      "========================   Split example   =========================\n",
      "\n",
      "['void', 'test_WordUeberraschungPrinter', '(', ')', '{', 'if', '(', 'eps', '>', '=', '0.345e+4', ')', '{', '<comment>', 'printWord', '(', '\"', '.', '.', '.', '<non-en>', '0x12', '\"', ')', ';', '}', '}']\n",
      "\n",
      "========================   Stats           =========================\n",
      "\n",
      "Train vocab: 10813844\n",
      "Test vocab : 80334, identifiers: 78340 (0.98%)\n",
      "\n",
      "Train corpus size: 1261768048\n",
      "Test corpus size : 5851993, identifiers: 1947796 (0.33%)\n",
      "\n",
      "OOV in test set (top 9223372036854775807): 30304 (37.72%), oov tokens number: 222756 (3.81%)\n",
      "OOV in test set (top 200000): 56401 (70.21%), oov tokens number: 415208 (7.10%)\n",
      "OOV in test set (top 100000): 60840 (75.73%), oov tokens number: 461900 (7.89%)\n",
      "OOV in test set (top 75000): 62624 (77.95%), oov tokens number: 483114 (8.26%)\n",
      "OOV in test set (top 50000): 65056 (80.98%), oov tokens number: 532645 (9.10%)\n",
      "OOV in test set (top 25000): 69245 (86.20%), oov tokens number: 592727 (10.13%)\n",
      "\n",
      "For identifiers: \n",
      "\n",
      "OOV in test set (top 9223372036854775807): 29852 (38.11%), oov tokens number: 222014 (11.40%)\n",
      "OOV in test set (top 200000): 55491 (70.83%), oov tokens number: 413482 (21.23%)\n",
      "OOV in test set (top 100000): 59771 (76.30%), oov tokens number: 459885 (23.61%)\n",
      "OOV in test set (top 75000): 61481 (78.48%), oov tokens number: 480911 (24.69%)\n",
      "OOV in test set (top 50000): 63818 (81.46%), oov tokens number: 530245 (27.22%)\n",
      "OOV in test set (top 25000): 67842 (86.60%), oov tokens number: 589680 (30.27%)\n",
      "[2532907, 6487131, 1586806, 181371, 25629]\n"
     ]
    }
   ],
   "source": [
    "prep_function = PrepFunction(api.nosplit, [], {\"no_unicode\": True, \"no_spaces\": True, \"no_com\": True})\n",
    "description = \"Filtering comments (+ whitespace, + non-ascii)\"\n",
    "\n",
    "run(prep_function, description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering  strings (+ comments, + whitespace, + non-ascii)\n",
      "\n",
      "2019-08-16 12:01:58,564 [dataprep.infrastructure.stages] INFO: Checking first if vocabulary file exists: /home/lv71161/hlibbabii/.config/dataprep/1.0.0-alpha.8/vocab/java-minus-small-test_19-08-08T23-17-22_java_-_U0000u/vocab\n",
      "2019-08-16 12:01:58,621 [dataprep.infrastructure.stages] INFO: Vocabulary is already computed and up-to-date\n",
      "2019-08-16 12:01:58,622 [dataprep.api.corpus] INFO: Preprocessed dataset is ready at /home/lv71161/hlibbabii/prep-datasets/java-minus-small-test_19-08-08T23-17-22_java_-_U0000u_-_prep\n",
      "2019-08-16 12:02:23,453 [dataprep.infrastructure.stages] INFO: Checking first if vocabulary file exists: /home/lv71161/hlibbabii/.config/dataprep/1.0.0-alpha.8/vocab/java-small-test_19-02-09T13-18-23_java_-_U0000u/vocab\n",
      "2019-08-16 12:02:23,523 [dataprep.infrastructure.stages] INFO: Vocabulary is already computed and up-to-date\n",
      "2019-08-16 12:02:23,524 [dataprep.api.corpus] INFO: Preprocessed dataset is ready at /home/lv71161/hlibbabii/prep-datasets/java-small-test_19-02-09T13-18-23_java_-_U0000u_-_prep\n",
      "Removing prepped dataset at /home/lv71161/hlibbabii/prep-datasets/java-minus-small-test_19-08-08T23-17-22_java_-_U0000u_-_prep\n",
      "\n",
      "========================   Split example   =========================\n",
      "\n",
      "['void', 'test_WordUeberraschungPrinter', '(', ')', '{', 'if', '(', 'eps', '>', '=', '0.345e+4', ')', '{', '<comment>', 'printWord', '(', '<str-literal>', ')', ';', '}', '}']\n",
      "\n",
      "========================   Stats           =========================\n",
      "\n",
      "Train vocab: 9521607\n",
      "Test vocab : 70745, identifiers: 69274 (0.98%)\n",
      "\n",
      "Train corpus size: 1151554964\n",
      "Test corpus size : 5431529, identifiers: 1791408 (0.33%)\n",
      "\n",
      "OOV in test set (top 9223372036854775807): 27274 (38.55%), oov tokens number: 222901 (4.10%)\n",
      "OOV in test set (top 200000): 49948 (70.60%), oov tokens number: 386753 (7.12%)\n",
      "OOV in test set (top 100000): 53813 (76.07%), oov tokens number: 431548 (7.95%)\n",
      "OOV in test set (top 75000): 55361 (78.25%), oov tokens number: 449269 (8.27%)\n",
      "OOV in test set (top 50000): 57442 (81.20%), oov tokens number: 500056 (9.21%)\n",
      "OOV in test set (top 25000): 60996 (86.22%), oov tokens number: 551722 (10.16%)\n",
      "\n",
      "For identifiers: \n",
      "\n",
      "OOV in test set (top 9223372036854775807): 26987 (38.96%), oov tokens number: 222547 (12.42%)\n",
      "OOV in test set (top 200000): 49393 (71.30%), oov tokens number: 386023 (21.55%)\n",
      "OOV in test set (top 100000): 53126 (76.69%), oov tokens number: 430615 (24.04%)\n",
      "OOV in test set (top 75000): 54626 (78.85%), oov tokens number: 448268 (25.02%)\n",
      "OOV in test set (top 50000): 56637 (81.76%), oov tokens number: 498937 (27.85%)\n",
      "OOV in test set (top 25000): 60059 (86.70%), oov tokens number: 550285 (30.72%)\n",
      "[1899280, 5980484, 1451884, 166995, 22964]\n"
     ]
    }
   ],
   "source": [
    "prep_function = PrepFunction(api.nosplit, [], {\"no_unicode\": True, \"no_spaces\": True, \"no_com\": True, \"no_str\": True})\n",
    "description = \"Filtering  strings (+ comments, + whitespace, + non-ascii)\"\n",
    "\n",
    "run(prep_function, description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_function = PrepFunction(api.nosplit, [], {\"no_unicode\": True, \"no_spaces\": True, \"no_com\": True, \"full_strings\": True, \"max_str_length\": 14})\n",
    "description = \"An additional choice, the model from Hellendoorn and Devanbu: keep strings shorter than 15 char (check SLP-core code), remove others, remove comments  (+ no spaces, + no unicode)  --> Baseline for word splitting\"\n",
    "\n",
    "run(prep_function, description)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Unsplit, remove non-ascii, remove whitespace, remove comments, remove strings longer than 15 chars] + Word splitting via conventions\n",
      "\n",
      "2019-08-14 11:12:19,725 [dataprep.infrastructure.stages] INFO: Checking first if vocabulary file exists: /home/lv71161/hlibbabii/.config/dataprep/1.0.0-alpha.8/vocab/java-minus-small-test_19-08-08T23-17-22_java_-_U0E10u/vocab\n",
      "2019-08-14 11:12:19,727 [dataprep.infrastructure.stages] INFO: Vocabulary is already computed and up-to-date\n",
      "2019-08-14 11:12:19,729 [dataprep.api.corpus] INFO: Preprocessed dataset is ready at /home/lv71161/hlibbabii/prep-datasets/java-minus-small-test_19-08-08T23-17-22_java_-_U0E10u_-_prep\n",
      "2019-08-14 11:12:25,575 [dataprep.infrastructure.stages] INFO: Checking first if vocabulary file exists: /home/lv71161/hlibbabii/.config/dataprep/1.0.0-alpha.8/vocab/java-small-test_19-02-09T13-18-23_java_-_U0E10u/vocab\n",
      "2019-08-14 11:12:25,592 [dataprep.infrastructure.stages] INFO: Vocabulary is already computed and up-to-date\n",
      "2019-08-14 11:12:25,593 [dataprep.api.corpus] INFO: Preprocessed dataset is ready at /home/lv71161/hlibbabii/prep-datasets/java-small-test_19-02-09T13-18-23_java_-_U0E10u_-_prep\n",
      "Removing prepped dataset at /home/lv71161/hlibbabii/prep-datasets/java-minus-small-test_19-08-08T23-17-22_java_-_U0E10u_-_prep\n",
      "\n",
      "========================   Split example   =========================\n",
      "\n",
      "['void', '<w>', 'test', '_', 'Word', 'Ueberraschung', 'Printer', '</w>', '(', ')', '{', 'if', '(', 'eps', '>', '=', '0.345e+4', ')', '{', '<comment>', '<w>', 'print', 'Word', '</w>', '(', '\"', '\"', ')', ';', '}', '}']\n",
      "\n",
      "========================   Stats           =========================\n",
      "\n",
      "Train vocab: 1270257\n",
      "Test vocab : 16450, identifiers: 14739 (0.90%)\n",
      "\n",
      "Train corpus size: 1812960637\n",
      "Test corpus size : 8383149, identifiers: 3016823 (0.36%)\n",
      "\n",
      "OOV in test set (top 9223372036854775807): 1247 (7.58%), oov tokens number: 50442 (0.60%)\n",
      "OOV in test set (top 200000): 2206 (13.41%), oov tokens number: 60404 (0.72%)\n",
      "OOV in test set (top 100000): 2918 (17.74%), oov tokens number: 67197 (0.80%)\n",
      "OOV in test set (top 75000): 3317 (20.16%), oov tokens number: 71773 (0.86%)\n",
      "OOV in test set (top 50000): 4028 (24.49%), oov tokens number: 79559 (0.95%)\n",
      "OOV in test set (top 25000): 5836 (35.48%), oov tokens number: 129028 (1.54%)\n",
      "\n",
      "For identifiers: \n",
      "\n",
      "OOV in test set (top 9223372036854775807): 951 (6.45%), oov tokens number: 50064 (1.66%)\n",
      "OOV in test set (top 200000): 1765 (11.98%), oov tokens number: 59728 (1.98%)\n",
      "OOV in test set (top 100000): 2375 (16.11%), oov tokens number: 66329 (2.20%)\n",
      "OOV in test set (top 75000): 2700 (18.32%), oov tokens number: 70786 (2.35%)\n",
      "OOV in test set (top 50000): 3273 (22.21%), oov tokens number: 78256 (2.59%)\n",
      "OOV in test set (top 25000): 4777 (32.41%), oov tokens number: 126981 (4.21%)\n",
      "[476518, 552034, 173295, 48302, 20108]\n"
     ]
    }
   ],
   "source": [
    "prep_function = PrepFunction(api.basic, [],\n",
    "                             {\"no_unicode\": True, \"no_spaces\": True, \"no_com\": True, \"max_str_length\": 14})\n",
    "description = \"[Unsplit, remove non-ascii, remove whitespace, remove comments, remove strings longer than 15 chars] + Word splitting via conventions --> Baseline for subword splitting\"\n",
    "\n",
    "run(prep_function, description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Unsplit, remove non-ascii, remove whitespace, remove comments, remove strings longer than 15 chars] + Word splitting via conventions, and remove case.\n",
      "\n",
      "2019-08-16 14:54:02,956 [dataprep.infrastructure.stages] INFO: Checking first if vocabulary file exists: /home/lv71161/hlibbabii/.config/dataprep/1.0.0-alpha.8/vocab/java-minus-small-test_19-08-08T23-17-22_java_-_U0E10l/vocab\n",
      "2019-08-16 14:54:02,967 [dataprep.infrastructure.stages] INFO: Vocabulary is already computed and up-to-date\n",
      "2019-08-16 14:54:02,967 [dataprep.api.corpus] INFO: Preprocessed dataset is ready at /home/lv71161/hlibbabii/prep-datasets/java-minus-small-test_19-08-08T23-17-22_java_-_U0E10l_-_prep\n",
      "2019-08-16 14:54:08,592 [dataprep.infrastructure.stages] INFO: Checking first if vocabulary file exists: /home/lv71161/hlibbabii/.config/dataprep/1.0.0-alpha.8/vocab/java-small-test_19-02-09T13-18-23_java_-_U0E10l/vocab\n",
      "2019-08-16 14:54:08,602 [dataprep.infrastructure.stages] INFO: Vocabulary is already computed and up-to-date\n",
      "2019-08-16 14:54:08,604 [dataprep.api.corpus] INFO: Preprocessed dataset is ready at /home/lv71161/hlibbabii/prep-datasets/java-small-test_19-02-09T13-18-23_java_-_U0E10l_-_prep\n",
      "Removing prepped dataset at /home/lv71161/hlibbabii/prep-datasets/java-minus-small-test_19-08-08T23-17-22_java_-_U0E10l_-_prep\n",
      "\n",
      "========================   Split example   =========================\n",
      "\n",
      "['void', '<w>', 'test', '_', '<Cap>', 'word', '<Cap>', 'ueberraschung', '<Cap>', 'printer', '</w>', '(', ')', '{', 'if', '(', 'eps', '>', '=', '0.345e+4', ')', '{', '<comment>', '<w>', 'print', '<Cap>', 'word', '</w>', '(', '\"', '\"', ')', ';', '}', '}']\n",
      "\n",
      "========================   Stats           =========================\n",
      "\n",
      "Train vocab: 1098305\n",
      "Test vocab : 10439, identifiers: 8726 (0.84%)\n",
      "\n",
      "Train corpus size: 2160127794\n",
      "Test corpus size : 10030252, identifiers: 2954550 (0.29%)\n",
      "\n",
      "OOV in test set (top 9223372036854775807): 990 (9.48%), oov tokens number: 35904 (0.36%)\n",
      "OOV in test set (top 200000): 1558 (14.92%), oov tokens number: 50552 (0.50%)\n",
      "OOV in test set (top 100000): 1964 (18.81%), oov tokens number: 56987 (0.57%)\n",
      "OOV in test set (top 75000): 2195 (21.03%), oov tokens number: 59813 (0.60%)\n",
      "OOV in test set (top 50000): 2559 (24.51%), oov tokens number: 65285 (0.65%)\n",
      "OOV in test set (top 25000): 3436 (32.92%), oov tokens number: 76542 (0.76%)\n",
      "\n",
      "For identifiers: \n",
      "\n",
      "OOV in test set (top 9223372036854775807): 694 (7.95%), oov tokens number: 35526 (1.20%)\n",
      "OOV in test set (top 200000): 1146 (13.13%), oov tokens number: 49908 (1.69%)\n",
      "OOV in test set (top 100000): 1482 (16.98%), oov tokens number: 56219 (1.90%)\n",
      "OOV in test set (top 75000): 1666 (19.09%), oov tokens number: 58971 (2.00%)\n",
      "OOV in test set (top 50000): 1936 (22.19%), oov tokens number: 64291 (2.18%)\n",
      "OOV in test set (top 25000): 2532 (29.02%), oov tokens number: 74875 (2.53%)\n",
      "[441824, 475548, 133762, 33519, 13652]\n"
     ]
    }
   ],
   "source": [
    "prep_function = PrepFunction(api.basic, [],\n",
    "                             {\"no_unicode\": True, \"no_spaces\": True, \"no_com\": True, \"max_str_length\": 14,\n",
    "                              \"no_case\": True})\n",
    "description = \"[Unsplit, remove non-ascii, remove whitespace, remove comments, remove strings longer than 15 chars] + Word splitting via conventions, and remove case.\"\n",
    "\n",
    "run(prep_function, description)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subword splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Unsplit, remove non-ascii, remove whitespace, remove comments, remove strings longer than 15 chars] + split via conventions, but keep case.+ Split numbers\n",
      "\n",
      "2019-08-16 14:54:12,001 [dataprep.infrastructure.stages] INFO: Checking first if vocabulary file exists: /home/lv71161/hlibbabii/.config/dataprep/1.0.0-alpha.8/vocab/java-minus-small-test_19-08-08T23-17-22_java_-_U0E20l/vocab\n",
      "2019-08-16 14:54:12,025 [dataprep.infrastructure.stages] INFO: Vocabulary is already computed and up-to-date\n",
      "2019-08-16 14:54:12,026 [dataprep.api.corpus] INFO: Preprocessed dataset is ready at /home/lv71161/hlibbabii/prep-datasets/java-minus-small-test_19-08-08T23-17-22_java_-_U0E20l_-_prep\n",
      "2019-08-16 14:54:14,775 [dataprep.infrastructure.stages] INFO: Checking first if vocabulary file exists: /home/lv71161/hlibbabii/.config/dataprep/1.0.0-alpha.8/vocab/java-small-test_19-02-09T13-18-23_java_-_U0E20l/vocab\n",
      "2019-08-16 14:54:14,798 [dataprep.infrastructure.stages] INFO: Vocabulary is already computed and up-to-date\n",
      "2019-08-16 14:54:14,799 [dataprep.api.corpus] INFO: Preprocessed dataset is ready at /home/lv71161/hlibbabii/prep-datasets/java-small-test_19-02-09T13-18-23_java_-_U0E20l_-_prep\n",
      "Removing prepped dataset at /home/lv71161/hlibbabii/prep-datasets/java-minus-small-test_19-08-08T23-17-22_java_-_U0E20l_-_prep\n",
      "\n",
      "========================   Split example   =========================\n",
      "\n",
      "['void', '<w>', 'test', '_', '<Cap>', 'word', '<Cap>', 'ueberraschung', '<Cap>', 'printer', '</w>', '(', ')', '{', 'if', '(', 'eps', '>', '=', '<w>', '0', '.', '3', '4', '5', 'e', '+', '4', '</w>', ')', '{', '<comment>', '<w>', 'print', '<Cap>', 'word', '</w>', '(', '\"', '\"', ')', ';', '}', '}']\n",
      "\n",
      "========================   Stats           =========================\n",
      "\n",
      "Train vocab: 622735\n",
      "Test vocab : 9105, identifiers: 8726 (0.96%)\n",
      "\n",
      "Train corpus size: 2199424158\n",
      "Test corpus size : 10075383, identifiers: 2957288 (0.29%)\n",
      "\n",
      "OOV in test set (top 9223372036854775807): 700 (7.69%), oov tokens number: 35537 (0.35%)\n",
      "OOV in test set (top 200000): 1154 (12.67%), oov tokens number: 49115 (0.49%)\n",
      "OOV in test set (top 100000): 1524 (16.74%), oov tokens number: 53213 (0.53%)\n",
      "OOV in test set (top 75000): 1703 (18.70%), oov tokens number: 57646 (0.57%)\n",
      "OOV in test set (top 50000): 1993 (21.89%), oov tokens number: 62221 (0.62%)\n",
      "OOV in test set (top 25000): 2634 (28.93%), oov tokens number: 74035 (0.73%)\n",
      "\n",
      "For identifiers: \n",
      "\n",
      "OOV in test set (top 9223372036854775807): 694 (7.95%), oov tokens number: 35526 (1.20%)\n",
      "OOV in test set (top 200000): 1091 (12.50%), oov tokens number: 48913 (1.65%)\n",
      "OOV in test set (top 100000): 1441 (16.51%), oov tokens number: 52954 (1.79%)\n",
      "OOV in test set (top 75000): 1615 (18.51%), oov tokens number: 57377 (1.94%)\n",
      "OOV in test set (top 50000): 1888 (21.64%), oov tokens number: 61818 (2.09%)\n",
      "OOV in test set (top 25000): 2495 (28.59%), oov tokens number: 73522 (2.49%)\n",
      "[147169, 314901, 116031, 31437, 13197]\n"
     ]
    }
   ],
   "source": [
    "prep_function = PrepFunction(api.basic, [],\n",
    "                             {\"no_unicode\": True, \"no_spaces\": True, \"no_com\": True, \"max_str_length\": 14,\n",
    "                              \"split_numbers\": True})\n",
    "description = \"[Unsplit, remove non-ascii, remove whitespace, remove comments, remove strings longer than 15 chars + split via conventions, but keep case] + Split numbers\"\n",
    "run(prep_function, description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Unsplit, remove non-ascii, remove whitespace, remove comments, remove strings longer than 15 chars] + split via conventions, but keep case. + Split numbers + Ronin\n",
      "\n",
      "2019-08-16 14:56:11,400 [dataprep.infrastructure.stages] INFO: Checking first if vocabulary file exists: /home/lv71161/hlibbabii/.config/dataprep/1.0.0-alpha.8/vocab/java-minus-small-test_19-08-08T23-17-22_java_-_U0E30l/vocab\n",
      "2019-08-16 14:56:11,401 [dataprep.infrastructure.stages] INFO: Vocabulary is already computed and up-to-date\n",
      "2019-08-16 14:56:11,401 [dataprep.api.corpus] INFO: Preprocessed dataset is ready at /home/lv71161/hlibbabii/prep-datasets/java-minus-small-test_19-08-08T23-17-22_java_-_U0E30l_-_prep\n",
      "2019-08-16 14:56:12,655 [dataprep.infrastructure.stages] INFO: Checking first if vocabulary file exists: /home/lv71161/hlibbabii/.config/dataprep/1.0.0-alpha.8/vocab/java-small-test_19-02-09T13-18-23_java_-_U0E30l/vocab\n",
      "2019-08-16 14:56:12,657 [dataprep.infrastructure.stages] INFO: Vocabulary is already computed and up-to-date\n",
      "2019-08-16 14:56:12,658 [dataprep.api.corpus] INFO: Preprocessed dataset is ready at /home/lv71161/hlibbabii/prep-datasets/java-small-test_19-02-09T13-18-23_java_-_U0E30l_-_prep\n",
      "Removing prepped dataset at /home/lv71161/hlibbabii/prep-datasets/java-minus-small-test_19-08-08T23-17-22_java_-_U0E30l_-_prep\n",
      "\n",
      "========================   Split example   =========================\n",
      "\n",
      "['void', '<w>', 'test', '_', '<Cap>', 'word', '<Cap>', 'ueberraschung', '<Cap>', 'printer', '</w>', '(', ')', '{', 'if', '(', 'eps', '>', '=', '<w>', '0', '.', '3', '4', '5', 'e', '+', '4', '</w>', ')', '{', '<comment>', '<w>', 'print', '<Cap>', 'word', '</w>', '(', '\"', '\"', ')', ';', '}', '}']\n",
      "\n",
      "========================   Stats           =========================\n",
      "\n",
      "Train vocab: 363291\n",
      "Test vocab : 7558, identifiers: 7179 (0.95%)\n",
      "\n",
      "Train corpus size: 2233565327\n",
      "Test corpus size : 10266581, identifiers: 3040958 (0.30%)\n",
      "\n",
      "OOV in test set (top 9223372036854775807): 262 (3.47%), oov tokens number: 9460 (0.09%)\n",
      "OOV in test set (top 200000): 340 (4.50%), oov tokens number: 9903 (0.10%)\n",
      "OOV in test set (top 100000): 488 (6.46%), oov tokens number: 11500 (0.11%)\n",
      "OOV in test set (top 75000): 572 (7.57%), oov tokens number: 12147 (0.12%)\n",
      "OOV in test set (top 50000): 722 (9.55%), oov tokens number: 14211 (0.14%)\n",
      "OOV in test set (top 25000): 1096 (14.50%), oov tokens number: 20203 (0.20%)\n",
      "\n",
      "For identifiers: \n",
      "\n",
      "OOV in test set (top 9223372036854775807): 256 (3.57%), oov tokens number: 9449 (0.31%)\n",
      "OOV in test set (top 200000): 312 (4.35%), oov tokens number: 9841 (0.32%)\n",
      "OOV in test set (top 100000): 421 (5.86%), oov tokens number: 11288 (0.37%)\n",
      "OOV in test set (top 75000): 497 (6.92%), oov tokens number: 11920 (0.39%)\n",
      "OOV in test set (top 50000): 634 (8.83%), oov tokens number: 13942 (0.46%)\n",
      "OOV in test set (top 25000): 964 (13.43%), oov tokens number: 19735 (0.65%)\n",
      "[102926, 168520, 58905, 20910, 12030]\n"
     ]
    }
   ],
   "source": [
    "prep_function = PrepFunction(api.basic, [],\n",
    "                             {\"no_unicode\": True, \"no_spaces\": True, \"no_com\": True, \"max_str_length\": 14,\n",
    "                              \"split_numbers\": True, \"ronin\": True})\n",
    "description = \"[Unsplit, remove non-ascii, remove whitespace, remove comments, remove strings longer than 15 chars + split via conventions, but keep case] + Split numbers + Ronin\"\n",
    "run(prep_function, description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_function = PrepFunction(api.basic, [],\n",
    "                             {\"no_unicode\": True, \"no_spaces\": True, \"no_com\": True, \"max_str_length\": 14,\n",
    "                              \"split_numbers\": True, \"ronin\": True, \"stemming\": True})\n",
    "description = \"[Unsplit, remove non-ascii, remove whitespace, remove comments, remove strings longer than 15 chars + split via conventions, but keep case] + Split numbers + Ronin + Stemming\"\n",
    "run(prep_function, description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_function = PrepFunction(api.char, [], {\"no_unicode\": True, \"no_spaces\": True, \"no_com\": True, \"max_str_length\": 14})\n",
    "description = \"Char model (remove non-ascii, remove whitespace, remove comments, remove strings longer than 15 chars, keep case)\"\n",
    "\n",
    "run(prep_function, description)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_function = PrepFunction(api.bpe, ['java-bpe-training_nounicode-1000'], {\"no_com\": True, \"max_str_length\": 14, \"no_unicode\": True})\n",
    "description = \"bpe 1k Hellendoorn and Devanbu strings no comments no unicode\"\n",
    "run(prep_function, description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bpe 2k Hellendoorn and Devanbu strings no comments, no unicode\n",
      "\n",
      "2019-08-18 23:32:58,547 [dataprep.infrastructure.stages] INFO: Checking first if vocabulary file exists: /home/lv71161/hlibbabii/.config/dataprep/1.0.0-alpha.8/vocab/java-small-test_19-02-09T13-18-23_java_-_U0E9su_java-bpe-training_nounicode-2000/vocab\n",
      "2019-08-18 23:32:58,547 [dataprep.infrastructure.stages] INFO: Parsing...\n",
      "2019-08-18 23:32:58,664 [dataprep.infrastructure.stages] INFO: Parsed dataset is up-to-date.\n",
      "2019-08-18 23:32:58,664 [dataprep.infrastructure.stages] INFO: Preprocessing...\n",
      "2019-08-18 23:32:58,665 [dataprep.to_repr] INFO: Reading parsed files from: /home/lv71161/hlibbabii/.cache/dataprep/1.0.0-alpha.8/parsed_datasets/java-small-test_19-02-09T13-18-23_java\n",
      "2019-08-18 23:32:58,666 [dataprep.to_repr] INFO: Using bpe merges file: /home/lv71161/hlibbabii/.config/dataprep/1.0.0-alpha.8/bpe/java-bpe-training_19-08-01T10-29-09_java_-_nounicode/2000/merges.txt\n",
      "2019-08-18 23:32:58,693 [dataprep.to_repr] INFO: Using first 2000 merges.\n",
      "2019-08-18 23:32:58,695 [dataprep.to_repr] INFO: Writing preprocessed files to /tmp/scratch/prep-datasets/java-small-test_19-02-09T13-18-23_java_-_U0E9su_java-bpe-training_nounicode-2000_-_prep\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8268/8268 [01:15<00:00, 109.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-08-18 23:34:14,856 [dataprep.infrastructure.stages] INFO: Computing vocab...\n",
      "2019-08-18 23:34:14,858 [dataprep.vocab] DEBUG: Reading files from: /tmp/scratch/prep-datasets/java-small-test_19-02-09T13-18-23_java_-_U0E9su_java-bpe-training_nounicode-2000_-_prep\n",
      "2019-08-18 23:34:14,859 [dataprep.vocab] INFO: Calculating vocabulary from scratch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5120/5120 [00:36<00:00,  3.08it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-08-18 23:34:51,941 [dataprep.vocab] DEBUG: Using 32 mergers, number of partial vocabs: 5120\n",
      "2019-08-18 23:34:52,111 [dataprep.vocab] DEBUG: ==================    Starting merging    =================\n",
      "2019-08-18 23:34:52,131 [dataprep.vocab] DEBUG: Merges need to be done: 5100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-08-18 23:34:52,267 [dataprep.vocab] INFO: [1] Merging vocabs (0 out of 5100)\n",
      "2019-08-18 23:34:52,275 [dataprep.vocab] INFO: [2] Merging vocabs (1 out of 5100)\n",
      "2019-08-18 23:34:52,279 [dataprep.vocab] DEBUG: [1] New words: ['com</t>', 'te', 'am', '11', '6', '0</t>', 'sc', 'out', 'ing</t>', 'f'] ..., total: 173\n",
      "2019-08-18 23:34:52,280 [dataprep.vocab] DEBUG: [1] Merging took 0.012 s, current vocab size: 374\n",
      "2019-08-18 23:34:52,282 [dataprep.vocab] INFO: [3] Merging vocabs (2 out of 5100)\n",
      "2019-08-18 23:34:52,287 [dataprep.vocab] DEBUG: [2] New words: ['net</t>', 'g', 'tools</t>', 'gr', 'and</t>', 'ui</t>', 'raph</t>', 'draw', '2', 'd</t>'] ..., total: 410\n",
      "2019-08-18 23:34:52,288 [dataprep.vocab] INFO: [1] Merging vocabs (4 out of 5100)\n",
      "2019-08-18 23:34:52,289 [dataprep.vocab] DEBUG: [2] Merging took 0.013 s, current vocab size: 578\n",
      "2019-08-18 23:34:52,309 [dataprep.vocab] INFO: [6] Merging vocabs (8 out of 5100)\n",
      "2019-08-18 23:34:52,363 [dataprep.vocab] INFO: [14] Merging vocabs (16 out of 5100)\n",
      "2019-08-18 23:34:52,469 [dataprep.vocab] INFO: [30] Merging vocabs (32 out of 5100)\n",
      "2019-08-18 23:34:52,507 [dataprep.vocab] DEBUG: [6] New words: ['util</t>', 'import', 'static</t>', 'P', 'se', 'ud', 'Description</t>', '*</t>', 'java</t>', 'lang</t>'] ..., total: 164\n",
      "2019-08-18 23:34:52,509 [dataprep.vocab] DEBUG: [6] Merging took 0.199 s, current vocab size: 230\n",
      "2019-08-18 23:34:52,511 [dataprep.vocab] DEBUG: [3] New words: ['tions</t>', 'raph</t>', 'Graph', 'Control', 'Provider</t>', 'C', 'le', 'ar', 'Filter', 'Action</t>'] ..., total: 31\n",
      "2019-08-18 23:34:52,511 [dataprep.vocab] DEBUG: [1] New words: ['com</t>', 'm', 'c', 'b', 'fi', 't', 'ar</t>', 'log</t>', 'k', 'it'] ..., total: 222\n",
      "2019-08-18 23:34:52,512 [dataprep.vocab] DEBUG: [3] Merging took 0.229 s, current vocab size: 231\n",
      "2019-08-18 23:34:52,513 [dataprep.vocab] DEBUG: [1] Merging took 0.223 s, current vocab size: 354\n",
      "2019-08-18 23:34:52,519 [dataprep.vocab] DEBUG: [14] New words: ['test', 'low', '</t>', 'model</t>', 'Ex', 'Temp', 'ary', 'Output', 'S', 'por'] ..., total: 48\n",
      "2019-08-18 23:34:52,520 [dataprep.vocab] DEBUG: [14] Merging took 0.156 s, current vocab size: 208\n",
      "2019-08-18 23:34:52,774 [dataprep.vocab] DEBUG: [30] New words: ['import', 'h', 'am', 'Match', '*</t>', 'junit</t>', 'Assert</t>', 'io</t>', 'File</t>', 'IOException</t>'] ..., total: 269\n",
      "2019-08-18 23:34:52,775 [dataprep.vocab] INFO: [27] Merging vocabs (64 out of 5100)\n",
      "2019-08-18 23:34:52,776 [dataprep.vocab] DEBUG: [30] Merging took 0.306 s, current vocab size: 659\n",
      "2019-08-18 23:34:53,021 [dataprep.vocab] DEBUG: [27] New words: ['m', 'l</t>', 'dir', 'ec', 'ti', 'o</t>', 'v</t>', 'ri', 'ver</t>', 'import'] ..., total: 338\n",
      "2019-08-18 23:34:53,022 [dataprep.vocab] DEBUG: [27] Merging took 0.246 s, current vocab size: 478\n",
      "2019-08-18 23:34:53,054 [dataprep.vocab] INFO: [27] Merging vocabs (128 out of 5100)\n",
      "2019-08-18 23:34:53,082 [dataprep.vocab] DEBUG: [27] New words: ['a', 'us', 'af', 'w</t>', 'low', 'import', 'C', 'ore', 'Oper', '*</t>'] ..., total: 518\n",
      "2019-08-18 23:34:53,083 [dataprep.vocab] DEBUG: [27] Merging took 0.028 s, current vocab size: 871\n",
      "2019-08-18 23:34:53,191 [dataprep.vocab] INFO: [25] Merging vocabs (256 out of 5100)\n",
      "2019-08-18 23:34:53,206 [dataprep.vocab] DEBUG: [25] New words: ['oper', 'ator</t>', 'util</t>', 'Iterator</t>', 'List</t>', '1</t>', 'v', 'oc', 'ab', 'ul'] ..., total: 110\n",
      "2019-08-18 23:34:53,208 [dataprep.vocab] DEBUG: [25] Merging took 0.016 s, current vocab size: 332\n",
      "2019-08-18 23:34:53,680 [dataprep.vocab] INFO: [21] Merging vocabs (512 out of 5100)\n",
      "2019-08-18 23:34:53,693 [dataprep.vocab] DEBUG: [21] New words: ['oper', 'ator</t>', 'javax</t>', 'annotation</t>', 'Gener', 'ate', 'd</t>', 'Ex', '1</t>', 'S'] ..., total: 53\n",
      "2019-08-18 23:34:53,694 [dataprep.vocab] DEBUG: [21] Merging took 0.013 s, current vocab size: 187\n",
      "2019-08-18 23:34:54,204 [dataprep.vocab] INFO: [5] Merging vocabs (1004 out of 5100)\n",
      "2019-08-18 23:34:54,219 [dataprep.vocab] DEBUG: [5] New words: ['fi', 'js', 'on</t>', 'ook', 'JSON', 'to', 'string</t>', 'Token', 'x</t>', 'ore</t>'] ..., total: 45\n",
      "2019-08-18 23:34:54,220 [dataprep.vocab] DEBUG: [5] Merging took 0.015 s, current vocab size: 650\n",
      "2019-08-18 23:34:54,222 [dataprep.vocab] INFO: [5] Merging vocabs (1024 out of 5100)\n",
      "2019-08-18 23:34:54,238 [dataprep.vocab] DEBUG: [5] New words: ['og</t>', 'android</t>', 'sy', 'tem</t>', 'app</t>', 'Applic', 'ation</t>', 'os</t>', 'Bu', 'oth'] ..., total: 142\n",
      "2019-08-18 23:34:54,239 [dataprep.vocab] DEBUG: [5] Merging took 0.017 s, current vocab size: 626\n",
      "2019-08-18 23:34:56,209 [dataprep.vocab] INFO: [24] Merging vocabs (2048 out of 5100)\n",
      "2019-08-18 23:34:56,226 [dataprep.vocab] DEBUG: [24] New words: ['M', 'ter', 'B', 'an', 'ch', 'Key</t>', 'ch</t>', 'Selection</t>', 'Sp', 'ed</t>'] ..., total: 186\n",
      "2019-08-18 23:34:56,227 [dataprep.vocab] DEBUG: [24] Merging took 0.017 s, current vocab size: 329\n",
      "2019-08-18 23:35:03,917 [dataprep.vocab] INFO: [28] Merging vocabs (3052 out of 5100)\n",
      "2019-08-18 23:35:03,936 [dataprep.vocab] DEBUG: [28] New words: ['oper', 'ator</t>', 'lang</t>', 'annotation</t>', 'Doc', 'um', 'en', 'ted</t>', 'Type</t>', 'Ret'] ..., total: 391\n",
      "2019-08-18 23:35:03,937 [dataprep.vocab] DEBUG: [28] Merging took 0.019 s, current vocab size: 551\n",
      "2019-08-18 23:35:04,978 [dataprep.vocab] INFO: [5] Merging vocabs (4076 out of 5100)\n",
      "2019-08-18 23:35:04,994 [dataprep.vocab] INFO: [23] Merging vocabs (4096 out of 5100)\n",
      "2019-08-18 23:35:05,000 [dataprep.vocab] DEBUG: [5] New words: ['Message', 'Format</t>', 'Tar', 'Data', 'Property</t>', 'R', 'end', 'z', 'ou', 'Util</t>'] ..., total: 213\n",
      "2019-08-18 23:35:05,002 [dataprep.vocab] DEBUG: [5] Merging took 0.023 s, current vocab size: 626\n",
      "2019-08-18 23:35:05,009 [dataprep.vocab] DEBUG: [23] New words: ['oper', 'ator</t>', 'java</t>', 'lang</t>', 'annotation</t>', 'Doc', 'um', 'ted</t>', 'Ret', 'tion</t>'] ..., total: 291\n",
      "2019-08-18 23:35:05,011 [dataprep.vocab] DEBUG: [23] Merging took 0.016 s, current vocab size: 563\n",
      "2019-08-18 23:35:05,465 [dataprep.vocab] INFO: [7] Merging vocabs (4588 out of 5100)\n",
      "2019-08-18 23:35:05,492 [dataprep.vocab] DEBUG: [7] New words: ['de</t>', 'in</t>', 'q</t>', 'ra</t>', 'ite</t>', 'Map', 'ri', 'ple', 'Attribute', 'Column'] ..., total: 1086\n",
      "2019-08-18 23:35:05,493 [dataprep.vocab] DEBUG: [7] Merging took 0.027 s, current vocab size: 1968\n",
      "2019-08-18 23:35:06,117 [dataprep.vocab] INFO: [14] Merging vocabs (4844 out of 5100)\n",
      "2019-08-18 23:35:06,131 [dataprep.vocab] DEBUG: [14] New words: ['net</t>', 'g', 'tools</t>', 'gr', 'and</t>', 'tions</t>', 'java</t>', 'io</t>', 'IOException</t>', 'raph</t>'] ..., total: 243\n",
      "2019-08-18 23:35:06,132 [dataprep.vocab] DEBUG: [14] Merging took 0.014 s, current vocab size: 482\n",
      "2019-08-18 23:35:07,478 [dataprep.vocab] INFO: [12] Merging vocabs (4972 out of 5100)\n",
      "2019-08-18 23:35:07,500 [dataprep.vocab] DEBUG: [12] New words: ['com</t>', 'ax</t>', 'dis', 'rup', 't', 'or</t>', 'sup', 'port</t>', 'St', 'Entry</t>'] ..., total: 109\n",
      "2019-08-18 23:35:07,501 [dataprep.vocab] DEBUG: [12] Merging took 0.022 s, current vocab size: 228\n",
      "2019-08-18 23:35:07,543 [dataprep.vocab] INFO: [11] Merging vocabs (5036 out of 5100)\n",
      "2019-08-18 23:35:07,566 [dataprep.vocab] INFO: [28] Merging vocabs (5068 out of 5100)\n",
      "2019-08-18 23:35:07,573 [dataprep.vocab] DEBUG: [11] New words: ['j', 'm', 'x</t>', 'abstract</t>', 'Remote', 'Operation</t>', '<</t>', 'T</t>', '></t>', 'String</t>'] ..., total: 51\n",
      "2019-08-18 23:35:07,574 [dataprep.vocab] DEBUG: [11] Merging took 0.030 s, current vocab size: 157\n",
      "2019-08-18 23:35:07,587 [dataprep.vocab] DEBUG: [16] No vocabs available for merge. Terminating process..., mergers left: 30\n",
      "2019-08-18 23:35:07,587 [dataprep.vocab] DEBUG: [20] No vocabs available for merge. Terminating process..., mergers left: 29\n",
      "2019-08-18 23:35:07,587 [dataprep.vocab] DEBUG: [26] No vocabs available for merge. Terminating process..., mergers left: 31\n",
      "2019-08-18 23:35:07,589 [dataprep.vocab] DEBUG: [2] No vocabs available for merge. Terminating process..., mergers left: 28\n",
      "2019-08-18 23:35:07,592 [dataprep.vocab] DEBUG: [28] New words: ['ule</t>', 'Calend', 'Range</t>', 'act', '(', ')', '~', 'one</t>', 'Des', 'Lin'] ..., total: 469\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-08-18 23:35:07,593 [dataprep.vocab] DEBUG: [28] Merging took 0.026 s, current vocab size: 1733\n",
      "2019-08-18 23:35:07,592 [dataprep.vocab] DEBUG: [29] No vocabs available for merge. Terminating process..., mergers left: 27\n",
      "2019-08-18 23:35:07,595 [dataprep.vocab] DEBUG: [28] No vocabs available for merge. Terminating process..., mergers left: 24\n",
      "2019-08-18 23:35:07,595 [dataprep.vocab] DEBUG: [3] No vocabs available for merge. Terminating process..., mergers left: 23\n",
      "2019-08-18 23:35:07,594 [dataprep.vocab] DEBUG: [19] No vocabs available for merge. Terminating process..., mergers left: 25\n",
      "2019-08-18 23:35:07,595 [dataprep.vocab] DEBUG: [15] No vocabs available for merge. Terminating process..., mergers left: 26\n",
      "2019-08-18 23:35:07,603 [dataprep.vocab] INFO: [25] Merging vocabs (5084 out of 5100)\n",
      "2019-08-18 23:35:07,602 [dataprep.vocab] DEBUG: [18] No vocabs available for merge. Terminating process..., mergers left: 22\n",
      "2019-08-18 23:35:07,603 [dataprep.vocab] DEBUG: [4] No vocabs available for merge. Terminating process..., mergers left: 21\n",
      "2019-08-18 23:35:07,609 [dataprep.vocab] DEBUG: [9] No vocabs available for merge. Terminating process..., mergers left: 20\n",
      "2019-08-18 23:35:07,614 [dataprep.vocab] DEBUG: [17] No vocabs available for merge. Terminating process..., mergers left: 19\n",
      "2019-08-18 23:35:07,619 [dataprep.vocab] DEBUG: [11] No vocabs available for merge. Terminating process..., mergers left: 17\n",
      "2019-08-18 23:35:07,619 [dataprep.vocab] DEBUG: [25] New words: ['od', 'jo', 'b</t>', 'des', 'ign', 'compon', 'ents</t>', 'ar', 'a</t>', 'ig'] ..., total: 928\n",
      "2019-08-18 23:35:07,619 [dataprep.vocab] DEBUG: [14] No vocabs available for merge. Terminating process..., mergers left: 16\n",
      "2019-08-18 23:35:07,620 [dataprep.vocab] DEBUG: [25] Merging took 0.017 s, current vocab size: 1214\n",
      "2019-08-18 23:35:07,619 [dataprep.vocab] DEBUG: [8] No vocabs available for merge. Terminating process..., mergers left: 18\n",
      "2019-08-18 23:35:07,621 [dataprep.vocab] DEBUG: [25] No vocabs available for merge. Terminating process..., mergers left: 15\n",
      "2019-08-18 23:35:07,625 [dataprep.vocab] DEBUG: [21] No vocabs available for merge. Terminating process..., mergers left: 14\n",
      "2019-08-18 23:35:07,641 [dataprep.vocab] DEBUG: [31] No vocabs available for merge. Terminating process..., mergers left: 13\n",
      "2019-08-18 23:35:07,646 [dataprep.vocab] DEBUG: [6] No vocabs available for merge. Terminating process..., mergers left: 12\n",
      "2019-08-18 23:35:07,663 [dataprep.vocab] DEBUG: [10] No vocabs available for merge. Terminating process..., mergers left: 11\n",
      "2019-08-18 23:35:07,673 [dataprep.vocab] DEBUG: [23] No vocabs available for merge. Terminating process..., mergers left: 10\n",
      "2019-08-18 23:35:07,686 [dataprep.vocab] DEBUG: [32] No vocabs available for merge. Terminating process..., mergers left: 9\n",
      "2019-08-18 23:35:07,686 [dataprep.vocab] INFO: [27] Merging vocabs (5092 out of 5100)\n",
      "2019-08-18 23:35:07,701 [dataprep.vocab] DEBUG: [1] No vocabs available for merge. Terminating process..., mergers left: 8\n",
      "2019-08-18 23:35:07,710 [dataprep.vocab] DEBUG: [27] New words: ['com</t>', 'us', 'af', 'w</t>', 'utils</t>', 'js', '9</t>', 'Set</t>', 'annotation</t>', 'process'] ..., total: 1253\n",
      "2019-08-18 23:35:07,711 [dataprep.vocab] DEBUG: [27] Merging took 0.024 s, current vocab size: 1853\n",
      "2019-08-18 23:35:07,712 [dataprep.vocab] DEBUG: [27] No vocabs available for merge. Terminating process..., mergers left: 7\n",
      "2019-08-18 23:35:07,737 [dataprep.vocab] DEBUG: [5] No vocabs available for merge. Terminating process..., mergers left: 6\n",
      "2019-08-18 23:35:07,763 [dataprep.vocab] DEBUG: [7] No vocabs available for merge. Terminating process..., mergers left: 5\n",
      "2019-08-18 23:35:07,789 [dataprep.vocab] DEBUG: [12] No vocabs available for merge. Terminating process..., mergers left: 4\n",
      "2019-08-18 23:35:07,790 [dataprep.vocab] INFO: [30] Merging vocabs (5096 out of 5100)\n",
      "2019-08-18 23:35:07,819 [dataprep.vocab] DEBUG: [30] New words: ['current</t>', 'Service</t>', 'ched', 'ule', 'sis', 'li', 'Component', 'registry</t>', 'list</t>', 'ore</t>'] ..., total: 935\n",
      "2019-08-18 23:35:07,820 [dataprep.vocab] DEBUG: [30] Merging took 0.029 s, current vocab size: 1963\n",
      "2019-08-18 23:35:07,822 [dataprep.vocab] DEBUG: [30] No vocabs available for merge. Terminating process..., mergers left: 3\n",
      "2019-08-18 23:35:07,850 [dataprep.vocab] DEBUG: [22] No vocabs available for merge. Terminating process..., mergers left: 2\n",
      "2019-08-18 23:35:07,854 [dataprep.vocab] INFO: [24] Merging vocabs (5098 out of 5100)\n",
      "2019-08-18 23:35:07,882 [dataprep.vocab] DEBUG: [24] New words: ['Request</t>', 'ance', 'Manager</t>', 'ject', 'su', 'Run', 'date', 'Index</t>', 'dat', 'STAT'] ..., total: 769\n",
      "2019-08-18 23:35:07,884 [dataprep.vocab] DEBUG: [24] Merging took 0.028 s, current vocab size: 1983\n",
      "2019-08-18 23:35:07,885 [dataprep.vocab] DEBUG: [24] No vocabs available for merge. Terminating process..., mergers left: 1\n",
      "2019-08-18 23:35:07,887 [dataprep.vocab] INFO: [13] Merging vocabs (5099 out of 5100)\n",
      "2019-08-18 23:35:07,917 [dataprep.vocab] DEBUG: [13] New words: ['Token', 'source</t>', 'Prog', 'ress', 'Own', 'gener', 'Inf', 'en</t>', 'Read', 'Non'] ..., total: 631\n",
      "2019-08-18 23:35:07,918 [dataprep.vocab] DEBUG: [13] Merging took 0.030 s, current vocab size: 2000\n",
      "2019-08-18 23:35:07,920 [dataprep.vocab] DEBUG: Leaving 1 process to finish the merges\n",
      "2019-08-18 23:35:07,921 [dataprep.vocab] INFO: ===============     Finishing merges    ===============\n",
      "2019-08-18 23:35:07,942 [dataprep.vocab] INFO: 5% + 5%  ---> 10%\n",
      "2019-08-18 23:35:07,979 [dataprep.vocab] DEBUG: [13] New words: ['Request', 'tifi', 'INSTANC', 'Access</t>', '~</t>', 'Follow', '_0</t>', 'DER', 'native</t>', 'ide</t>'] ..., total: 45\n",
      "2019-08-18 23:35:07,980 [dataprep.vocab] DEBUG: [13] Merging took 0.035 s, current vocab size: 2045\n",
      "2019-08-18 23:35:07,981 [dataprep.vocab] INFO: 10% + 5%  ---> 15%\n",
      "2019-08-18 23:35:08,035 [dataprep.vocab] DEBUG: [13] New words: ['Bon', 'gorith', 'ck', 'Buff', 'ub</t>', 'ult', 'Bloc', 'endenc', 'feature', 'annel</t>'] ..., total: 16\n",
      "2019-08-18 23:35:08,036 [dataprep.vocab] DEBUG: [13] Merging took 0.053 s, current vocab size: 2061\n",
      "2019-08-18 23:35:08,038 [dataprep.vocab] INFO: 15% + 5%  ---> 20%\n",
      "2019-08-18 23:35:08,088 [dataprep.vocab] DEBUG: [13] New words: ['But', 'Servi', 'servi', 'andro', 'ui', 'JS', '000000', 'eclip', 'Dom', 'bot</t>'] ..., total: 14\n",
      "2019-08-18 23:35:08,089 [dataprep.vocab] DEBUG: [13] Merging took 0.049 s, current vocab size: 2075\n",
      "2019-08-18 23:35:08,091 [dataprep.vocab] INFO: 20% + 5%  ---> 25%\n",
      "2019-08-18 23:35:08,144 [dataprep.vocab] DEBUG: [13] New words: ['Mach', 'ogn', 'NS', 'toc', 'Bag', 'Constraints</t>'] ..., total: 6\n",
      "2019-08-18 23:35:08,145 [dataprep.vocab] DEBUG: [13] Merging took 0.052 s, current vocab size: 2081\n",
      "2019-08-18 23:35:08,146 [dataprep.vocab] INFO: 25% + 5%  ---> 30%\n",
      "2019-08-18 23:35:08,205 [dataprep.vocab] DEBUG: [13] New words: ['Serv', 'Cer', 'InstanceOf</t>', 'mbo', 'msg', 'ationsh'] ..., total: 6\n",
      "2019-08-18 23:35:08,207 [dataprep.vocab] DEBUG: [13] Merging took 0.058 s, current vocab size: 2087\n",
      "2019-08-18 23:35:08,208 [dataprep.vocab] INFO: 30% + 5%  ---> 35%\n",
      "2019-08-18 23:35:08,274 [dataprep.vocab] DEBUG: [13] New words: ['opensc', 'Il', 'alid', 'OCL'] ..., total: 4\n",
      "2019-08-18 23:35:08,276 [dataprep.vocab] DEBUG: [13] Merging took 0.065 s, current vocab size: 2091\n",
      "2019-08-18 23:35:08,278 [dataprep.vocab] INFO: 35% + 5%  ---> 40%\n",
      "2019-08-18 23:35:08,349 [dataprep.vocab] DEBUG: [13] New words: ['Templ', 'L2', '_rule'] ..., total: 3\n",
      "2019-08-18 23:35:08,351 [dataprep.vocab] DEBUG: [13] Merging took 0.071 s, current vocab size: 2094\n",
      "2019-08-18 23:35:08,352 [dataprep.vocab] INFO: 40% + 5%  ---> 45%\n",
      "2019-08-18 23:35:08,430 [dataprep.vocab] DEBUG: [13] New words: ['framewor', 'Virtual'] ..., total: 2\n",
      "2019-08-18 23:35:08,432 [dataprep.vocab] DEBUG: [13] Merging took 0.077 s, current vocab size: 2096\n",
      "2019-08-18 23:35:08,433 [dataprep.vocab] INFO: 45% + 5%  ---> 50%\n",
      "2019-08-18 23:35:08,518 [dataprep.vocab] DEBUG: [13] New words: ['raph', 'FOLLOW', 'ae'] ..., total: 3\n",
      "2019-08-18 23:35:08,520 [dataprep.vocab] DEBUG: [13] Merging took 0.084 s, current vocab size: 2099\n",
      "2019-08-18 23:35:08,521 [dataprep.vocab] INFO: 50% + 5%  ---> 55%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-08-18 23:35:08,612 [dataprep.vocab] DEBUG: [13] New words: ['wn', \"'\\\\\\\\u\"] ..., total: 2\n",
      "2019-08-18 23:35:08,613 [dataprep.vocab] DEBUG: [13] Merging took 0.090 s, current vocab size: 2101\n",
      "2019-08-18 23:35:08,615 [dataprep.vocab] INFO: 55% + 5%  ---> 60%\n",
      "2019-08-18 23:35:08,715 [dataprep.vocab] DEBUG: [13] New words: ['alue</t>', 'Meta', 'oi'] ..., total: 3\n",
      "2019-08-18 23:35:08,717 [dataprep.vocab] DEBUG: [13] Merging took 0.099 s, current vocab size: 2104\n",
      "2019-08-18 23:35:08,719 [dataprep.vocab] INFO: 60% + 5%  ---> 65%\n",
      "2019-08-18 23:35:08,839 [dataprep.vocab] DEBUG: [13] New words: [] ..., total: 0\n",
      "2019-08-18 23:35:08,840 [dataprep.vocab] DEBUG: [13] Merging took 0.117 s, current vocab size: 2104\n",
      "2019-08-18 23:35:08,842 [dataprep.vocab] INFO: 65% + 5%  ---> 70%\n",
      "2019-08-18 23:35:08,964 [dataprep.vocab] DEBUG: [13] New words: ['rst', 'Enti'] ..., total: 2\n",
      "2019-08-18 23:35:08,965 [dataprep.vocab] DEBUG: [13] Merging took 0.120 s, current vocab size: 2106\n",
      "2019-08-18 23:35:08,966 [dataprep.vocab] INFO: 70% + 5%  ---> 75%\n",
      "2019-08-18 23:35:09,267 [dataprep.vocab] DEBUG: [13] New words: ['Gro'] ..., total: 1\n",
      "2019-08-18 23:35:09,269 [dataprep.vocab] DEBUG: [13] Merging took 0.299 s, current vocab size: 2107\n",
      "2019-08-18 23:35:09,271 [dataprep.vocab] INFO: 75% + 5%  ---> 80%\n",
      "2019-08-18 23:35:09,624 [dataprep.vocab] DEBUG: [13] New words: ['Ax'] ..., total: 1\n",
      "2019-08-18 23:35:09,626 [dataprep.vocab] DEBUG: [13] Merging took 0.350 s, current vocab size: 2108\n",
      "2019-08-18 23:35:09,628 [dataprep.vocab] INFO: 80% + 5%  ---> 85%\n",
      "2019-08-18 23:35:10,717 [dataprep.vocab] DEBUG: [13] New words: [] ..., total: 0\n",
      "2019-08-18 23:35:10,720 [dataprep.vocab] DEBUG: [13] Merging took 1.087 s, current vocab size: 2108\n",
      "2019-08-18 23:35:10,722 [dataprep.vocab] INFO: 85% + 5%  ---> 90%\n",
      "2019-08-18 23:35:11,015 [dataprep.vocab] DEBUG: [13] New words: [] ..., total: 0\n",
      "2019-08-18 23:35:11,017 [dataprep.vocab] DEBUG: [13] Merging took 0.291 s, current vocab size: 2108\n",
      "2019-08-18 23:35:11,019 [dataprep.vocab] INFO: 90% + 5%  ---> 95%\n",
      "2019-08-18 23:35:11,198 [dataprep.vocab] DEBUG: [13] New words: [] ..., total: 0\n",
      "2019-08-18 23:35:11,200 [dataprep.vocab] DEBUG: [13] Merging took 0.177 s, current vocab size: 2108\n",
      "2019-08-18 23:35:11,202 [dataprep.vocab] INFO: 95% + 5%  ---> 100%\n",
      "2019-08-18 23:35:11,349 [dataprep.vocab] DEBUG: [13] New words: ['eck', 'atu'] ..., total: 2\n",
      "2019-08-18 23:35:11,350 [dataprep.vocab] DEBUG: [13] Merging took 0.146 s, current vocab size: 2110\n",
      "2019-08-18 23:35:11,370 [dataprep.vocab] DEBUG: [13] Vocab files are saved. Terminating the process...\n",
      "2019-08-18 23:35:11,396 [dataprep.vocab] INFO: Vocab is available at /home/lv71161/hlibbabii/.config/dataprep/1.0.0-alpha.8/vocab/java-small-test_19-02-09T13-18-23_java_-_U0E9su_java-bpe-training_nounicode-2000/vocab\n",
      "2019-08-18 23:35:11,398 [dataprep.vocab] INFO: Vocab stats is available at /home/lv71161/hlibbabii/.config/dataprep/1.0.0-alpha.8/vocab/java-small-test_19-02-09T13-18-23_java_-_U0E9su_java-bpe-training_nounicode-2000/vocabsize\n",
      "2019-08-18 23:35:11,451 [dataprep.api.corpus] INFO: Preprocessed dataset is ready at /tmp/scratch/prep-datasets/java-small-test_19-02-09T13-18-23_java_-_U0E9su_java-bpe-training_nounicode-2000_-_prep\n",
      "2019-08-18 23:35:11,645 [dataprep.infrastructure.stages] INFO: Checking first if vocabulary file exists: /home/lv71161/hlibbabii/.config/dataprep/1.0.0-alpha.8/vocab/java-small-test_19-02-09T13-18-23_java_-_U0E9su_java-bpe-training_nounicode-2000/vocab\n",
      "2019-08-18 23:35:11,645 [dataprep.infrastructure.stages] INFO: Vocabulary is already computed and up-to-date\n",
      "2019-08-18 23:35:11,646 [dataprep.api.corpus] INFO: Preprocessed dataset is ready at /tmp/scratch/prep-datasets/java-small-test_19-02-09T13-18-23_java_-_U0E9su_java-bpe-training_nounicode-2000_-_prep\n",
      "2019-08-18 23:35:11,654 [vocabstudy.common] DEBUG: Checking if train dataset exists: /tmp/scratch/prep-datasets/java-small-test_19-02-09T13-18-23_java_-_U0E9su_java-bpe-training_nounicode-2000_-_prep\n",
      "2019-08-18 23:35:11,655 [vocabstudy.common] INFO: Train dataset is found and is going to be removed to save space: /tmp/scratch/prep-datasets/java-small-test_19-02-09T13-18-23_java_-_U0E9su_java-bpe-training_nounicode-2000_-_prep. Removing ...\n",
      "\n",
      "========================   Split example   =========================\n",
      "\n",
      "2019-08-18 23:35:29,953 [dataprep.to_repr] INFO: Using bpe merges file: /home/lv71161/hlibbabii/.config/dataprep/1.0.0-alpha.8/bpe/java-bpe-training_19-08-01T10-29-09_java_-_nounicode/2000/merges.txt\n",
      "2019-08-18 23:35:29,972 [dataprep.to_repr] INFO: Using first 2000 merges.\n",
      "['void</t>', 'test', '_', 'Wor', 'd', 'U', 'eb', 'err', 'as', 'ch', 'un', 'g', 'Pr', 'int', 'er</t>', '(</t>', ')</t>', '{</t>', '\\n', '\\t', 'if</t>', '(</t>', 'e', 'ps</t>', '></t>', '=</t>', '0.', '3', '4', '5', 'e', '+', '4</t>', ')</t>', '{</t>', '<comment>', '\\t', '\\t', 'print', 'Wor', 'd</t>', '(</t>', '\"', '\"', ')</t>', ';</t>', '\\n', '\\t', '}</t>', '\\n', '}</t>']\n",
      "\n",
      "========================   Stats           =========================\n",
      "\n",
      "Train vocab: 2110\n",
      "Test vocab : 2110, identifiers: 1285 (0.61%)\n",
      "\n",
      "Train corpus size: 10863418\n",
      "Test corpus size : 10863418, identifiers: 3365217 (0.31%)\n",
      "\n",
      "OOV in test set (top 9223372036854775807): 0 (0.00%), oov tokens number: 0 (0.00%)\n",
      "OOV in test set (top 200000): 0 (0.00%), oov tokens number: 0 (0.00%)\n",
      "OOV in test set (top 100000): 0 (0.00%), oov tokens number: 0 (0.00%)\n",
      "OOV in test set (top 75000): 0 (0.00%), oov tokens number: 0 (0.00%)\n",
      "OOV in test set (top 50000): 0 (0.00%), oov tokens number: 0 (0.00%)\n",
      "OOV in test set (top 25000): 0 (0.00%), oov tokens number: 0 (0.00%)\n",
      "\n",
      "For identifiers: \n",
      "\n",
      "OOV in test set (top 9223372036854775807): 0 (0.00%), oov tokens number: 0 (0.00%)\n",
      "OOV in test set (top 200000): 0 (0.00%), oov tokens number: 0 (0.00%)\n",
      "OOV in test set (top 100000): 0 (0.00%), oov tokens number: 0 (0.00%)\n",
      "OOV in test set (top 75000): 0 (0.00%), oov tokens number: 0 (0.00%)\n",
      "OOV in test set (top 50000): 0 (0.00%), oov tokens number: 0 (0.00%)\n",
      "OOV in test set (top 25000): 0 (0.00%), oov tokens number: 0 (0.00%)\n",
      "[5, 37, 103, 805, 1160]\n"
     ]
    }
   ],
   "source": [
    "prep_function = PrepFunction(api.bpe, ['java-bpe-training_nounicode-2000'], {\"no_com\": True, \"max_str_length\": 14, \"no_unicode\": True})\n",
    "description = \"bpe 2k Hellendoorn and Devanbu strings no comments, no unicode\"\n",
    "run(prep_function, description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_function = PrepFunction(api.bpe, ['java-bpe-training_nounicode-5000'], {\"no_com\": True, \"max_str_length\": 14, \"no_unicode\": True})\n",
    "description = \"bpe 5k Hellendoorn and Devanbu strings no comments, no unicode\"\n",
    "run(prep_function, description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_function = PrepFunction(api.bpe, ['java-bpe-training_nounicode-10000'], {\"no_com\": True, \"max_str_length\": 14, \"no_unicode\": True})\n",
    "description = \"bpe 10k Hellendoorn and Devanbu strings no comments, no unicode\"\n",
    "run(prep_function, description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_function = PrepFunction(api.bpe, ['java-bpe-training_nounicode-20000'], {\"no_com\": True, \"max_str_length\": 14, \"no_unicode\": True})\n",
    "description = \"bpe 20k Hellendoorn and Devanbu strings no comments no unicode\"\n",
    "run(prep_function, description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_function = PrepFunction(api.bpe, ['java-bpe-training_nounicode-1000'], {\"no_unicode\": True})\n",
    "description = \"bpe 1k no unicode\"\n",
    "run(prep_function, description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_function = PrepFunction(api.bpe, ['java-bpe-training_nounicode-2000'], {\"no_unicode\": True})\n",
    "description = \"bpe 2k, no unicode \"\n",
    "run(prep_function, description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_function = PrepFunction(api.bpe, ['java-bpe-training_nounicode-5000'], {\"no_unicode\": True})\n",
    "description = \"bpe 5k, no unicode\"\n",
    "run(prep_function, description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_function = PrepFunction(api.bpe, ['java-bpe-training_nounicode-10000'], {\"no_unicode\": True})\n",
    "description = \"bpe 10k, no unicode\"\n",
    "run(prep_function, description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_function = PrepFunction(api.bpe, ['java-bpe-training_nounicode-20000'], {\"no_unicode\": True})\n",
    "description = \"bpe 20k nounicode\"\n",
    "run(prep_function, description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bpe 1k no strings no comments\n",
      "\n",
      "2019-08-16 14:56:36,553 [dataprep.infrastructure.stages] INFO: Checking first if vocabulary file exists: /home/lv71161/hlibbabii/.config/dataprep/1.0.0-alpha.8/vocab/java-minus-small-test_19-08-08T23-17-22_java_-_u009su_java-bpe-training_nounicode-1000/vocab\n",
      "2019-08-16 14:56:36,555 [dataprep.infrastructure.stages] INFO: Parsing...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-1e7c1d1c17bf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprep_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPrepFunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbpe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'java-bpe-training_nounicode-1000'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"no_com\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"no_str\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdescription\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"bpe 1k no strings no comments\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescription\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-2-9f6da480bade>\u001b[0m in \u001b[0;36mrun\u001b[0;34m(prep_function, description)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep_function\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mPrepFunction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescription\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mcalc_and_display_stats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescription\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mJAVA_DATASETS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mJAVA_KEYWORDS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'java'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/projects/log-recommender-dataprep/vocabstudy/common.py\u001b[0m in \u001b[0;36mcalc_and_display_stats\u001b[0;34m(prep_function, description, datasets, keywords, extension)\u001b[0m\n\u001b[1;32m    143\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0mdataset_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPATH_TO_DATASETS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m         \u001b[0mprep_corpus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprep_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCorpus\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextension\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mHOME\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'prep-datasets'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m         \u001b[0mprep_corpora\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep_corpus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0mvocabs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep_corpus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/log-recommender-dataprep/vocabstudy/common.py\u001b[0m in \u001b[0;36mprep_corpus\u001b[0;34m(corpus, **kwargs)\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mprep_corpus\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mCorpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m             return self.callable(corpus.path, *self.params, **self.options, **kwargs,\n\u001b[0;32m---> 60\u001b[0;31m                                  calc_vocab=True, extensions=corpus.extensions)\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mprep_corpus\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-2019.03/envs/metrics/lib/python3.7/site-packages/dataprep/api/corpus.py\u001b[0m in \u001b[0;36mbpe\u001b[0;34m(path, bpe_codes_id, extensions, no_spaces, no_unicode, no_com, no_str, max_str_length, output_path, calc_vocab)\u001b[0m\n\u001b[1;32m    181\u001b[0m                                     no_com=no_com, no_str=no_str, max_str_length=max_str_length)\n\u001b[1;32m    182\u001b[0m     return preprocess_corpus(path, prep_config, bpe_codes_id,\n\u001b[0;32m--> 183\u001b[0;31m                              extensions=extensions, output_path=output_path, calc_vocab=calc_vocab)\n\u001b[0m\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-2019.03/envs/metrics/lib/python3.7/site-packages/dataprep/api/corpus.py\u001b[0m in \u001b[0;36mpreprocess_corpus\u001b[0;34m(path, prep_config, bpe_codes_id, extensions, output_path, calc_vocab)\u001b[0m\n\u001b[1;32m    196\u001b[0m                              overriden_path_to_prep_dataset=output_path)\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcalc_vocab\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 198\u001b[0;31m         \u001b[0mstages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_until_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_bpe_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m         \u001b[0mpath_to_vocab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath_to_vocab_file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-2019.03/envs/metrics/lib/python3.7/site-packages/dataprep/infrastructure/stages.py\u001b[0m in \u001b[0;36mrun_until_vocab\u001b[0;34m(dataset, custom_bpe_config)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_path_ready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath_to_vocab_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0mrun_until_preprocessing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_bpe_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Computing vocab...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0mcalc_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-2019.03/envs/metrics/lib/python3.7/site-packages/dataprep/infrastructure/stages.py\u001b[0m in \u001b[0;36mrun_until_preprocessing\u001b[0;34m(dataset, custom_bpe_config)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrun_until_preprocessing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_bpe_config\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCustomBpeConfig\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0mrun_parsing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Preprocessing...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-2019.03/envs/metrics/lib/python3.7/site-packages/dataprep/infrastructure/stages.py\u001b[0m in \u001b[0;36mrun_parsing\u001b[0;34m(dataset)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparsed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mparse_projects\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0;32melif\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparsed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_outdated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparsed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marchive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mparse_projects\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-2019.03/envs/metrics/lib/python3.7/site-packages/dataprep/infrastructure/dataset.py\u001b[0m in \u001b[0;36mis_outdated\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mis_outdated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mis_path_outdated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfile_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mGenerator\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-2019.03/envs/metrics/lib/python3.7/site-packages/dataprep/infrastructure/dataset.py\u001b[0m in \u001b[0;36mis_path_outdated\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    293\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodif_file\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0mexpected_timestamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m         \u001b[0mactual_timestamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_timestamp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mexpected_timestamp\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mactual_timestamp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-2019.03/envs/metrics/lib/python3.7/site-packages/dataprep/dirutils.py\u001b[0m in \u001b[0;36mget_timestamp\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_timestamp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m     \u001b[0mlast_modif_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_dir_last_modification\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mlast_modif_time\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%y-%m-%dT%H-%M-%S\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-2019.03/envs/metrics/lib/python3.7/site-packages/dataprep/dirutils.py\u001b[0m in \u001b[0;36mget_dir_last_modification\u001b[0;34m(path, limit)\u001b[0m\n\u001b[1;32m     70\u001b[0m                         \u001b[0;32myield\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetmtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m     \u001b[0mmtime\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwalk_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromtimestamp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmtime\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-2019.03/envs/metrics/lib/python3.7/site-packages/dataprep/dirutils.py\u001b[0m in \u001b[0;36mwalk_path\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetmtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdirs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwalk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mdir\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdirs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mcounter\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-2019.03/envs/metrics/lib/python3.7/os.py\u001b[0m in \u001b[0;36mwalk\u001b[0;34m(top, topdown, onerror, followlinks)\u001b[0m\n\u001b[1;32m    408\u001b[0m             \u001b[0;31m# above.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mfollowlinks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mislink\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 410\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mwalk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopdown\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0monerror\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfollowlinks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    411\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m         \u001b[0;31m# Recurse into sub-directories\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-2019.03/envs/metrics/lib/python3.7/os.py\u001b[0m in \u001b[0;36mwalk\u001b[0;34m(top, topdown, onerror, followlinks)\u001b[0m\n\u001b[1;32m    366\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 368\u001b[0;31m                 \u001b[0mis_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mentry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    369\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m                 \u001b[0;31m# If is_dir() raises an OSError, consider that the entry is not\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "prep_function = PrepFunction(api.bpe, ['java-bpe-training_nounicode-1000'], {\"no_com\": True, \"no_str\": True, \"no_unicode\": True})\n",
    "description = \"bpe 1k no strings no comments no unicode\"\n",
    "run(prep_function, description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_function = PrepFunction(api.bpe, ['java-bpe-training_nounicode-2000'], {\"no_com\": True, \"no_str\": True, \"no_unicode\": True})\n",
    "description = \"bpe 2k no strings no comments no unicode\"\n",
    ", \"no_unicode\": Truerun(prep_function, description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ", \"no_unicode\": Trueprep_function = PrepFunction(api.bpe, ['java-bpe-training_nounicode-5000'], {\"no_com\": True, \"no_str\": True, \"no_unicode\": True})\n",
    "description = \"bpe 5k no strings no comments no unicode\"\n",
    "run(prep_function, description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ", \"no_unicode\": Trueprep_function = PrepFunction(api.bpe, ['java-bpe-training_nounicode-10000'], {\"no_com\": True, \"no_str\": True, \"no_unicode\": True})\n",
    "description = \"bpe 10k no strings no comments no unicode\"\n",
    "run(prep_function, description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_function = PrepFunction(api.bpe, ['java-bpe-training_nounicode-20000'], {\"no_com\": True, \"no_str\": True, \"no_unicode\": True})\n",
    "description = \"bpe 20k no strings no comments no unicode\"\n",
    "run(prep_function, description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ", \"no_unicode\": Trueprep_function = PrepFunction(api.bpe, ['java-bpe-training_nounicode-1000'], {\"no_com\": True, \"no_unicode\": True})\n",
    "description = \"bpe 1k no comments no unicode\"\n",
    "run(prep_function, description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ", \"no_unicode\": Trueprep_function = PrepFunction(api.bpe, ['java-bpe-training_nounicode-2000'], {\"no_com\": True, \"no_unicode\": True})\n",
    "description = \"bpe 2k no comments no unicode\"\n",
    "run(prep_function, description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ", \"no_unicode\": Trueprep_function = PrepFunction(api.bpe, ['java-bpe-training_nounicode-5000'], {\"no_com\": True, \"no_unicode\": True})\n",
    "description = \"bpe 5k no comments no unicode\"\n",
    "run(prep_function, description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ", \"no_unicode\": Trueprep_function = PrepFunction(api.bpe, ['java-bpe-training_nounicode-10000'], {\"no_com\": True, \"no_unicode\": True})\n",
    "description = \"bpe 10k no comments no unicode\"\n",
    "run(prep_function, description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ", \"no_unicode\": Trueprep_function = PrepFunction(api.bpe, ['java-bpe-training_nounicode-20000'], {\"no_com\": True, \"no_unicode\": True})\n",
    "description = \"bpe 20k no comments no unicode\"\n",
    "run(prep_function, description)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
