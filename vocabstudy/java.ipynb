{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataprep.api.corpus as api\n",
    "from vocabstudy.common import PrepFunction, calc_and_display_stats\n",
    "JAVA_KEYWORDS = {\"abstract\", \"assert\", \"boolean\", \"break\", \"byte\", \"case\", \"catch\", \"char\",\n",
    "            \"class\", \"const\", \"continue\", \"default\", \"do\", \"double\", \"else\", \"enum\", \"extends\", \"final\", \"finally\",\n",
    "            \"float\", \"for\", \"goto\", \"if\", \"implements\", \"import\", \"instanceof\", \"int\", \"interface\", \"long\", \"native\",\n",
    "            \"new\", \"package\", \"private\", \"protected\", \"public\", \"return\", \"short\", \"static\", \"strictfp\", \"super\",\n",
    "            \"switch\", \"synchronized\", \"this\", \"throw\", \"throws\", \"transient\", \"try\", \"void\", \"volatile\", \"while\",\n",
    "            \"true\", \"false\", \"null\"}\n",
    "\n",
    "JAVA_DATASETS = (\n",
    "    'allamanis/java-minus-small-test',\n",
    "    'allamanis/java-small-test'\n",
    ")\n",
    "\n",
    "def run(prep_function: PrepFunction, description: str) -> None:\n",
    "    calc_and_display_stats(prep_function, description, JAVA_DATASETS, JAVA_KEYWORDS, 'java')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.0.0-alpha.8'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dataprep\n",
    "\n",
    "dataprep.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unsplit, with comments and vocabulary. No filtering.\n",
      "\n",
      "2019-08-16 12:00:41,096 [dataprep.infrastructure.stages] INFO: Checking first if vocabulary file exists: /home/lv71161/hlibbabii/.config/dataprep/1.0.0-alpha.8/vocab/java-minus-small-test_19-08-08T23-17-22_java_-_uc10su/vocab\n",
      "2019-08-16 12:00:41,117 [dataprep.infrastructure.stages] INFO: Vocabulary is already computed and up-to-date\n",
      "2019-08-16 12:00:41,118 [dataprep.api.corpus] INFO: Preprocessed dataset is ready at /home/lv71161/hlibbabii/prep-datasets/java-minus-small-test_19-08-08T23-17-22_java_-_uc10su_-_prep\n",
      "2019-08-16 12:01:18,063 [dataprep.infrastructure.stages] INFO: Checking first if vocabulary file exists: /home/lv71161/hlibbabii/.config/dataprep/1.0.0-alpha.8/vocab/java-small-test_19-02-09T13-18-23_java_-_uc10su/vocab\n",
      "2019-08-16 12:01:18,089 [dataprep.infrastructure.stages] INFO: Vocabulary is already computed and up-to-date\n",
      "2019-08-16 12:01:18,090 [dataprep.api.corpus] INFO: Preprocessed dataset is ready at /home/lv71161/hlibbabii/prep-datasets/java-small-test_19-02-09T13-18-23_java_-_uc10su_-_prep\n",
      "Removing prepped dataset at /home/lv71161/hlibbabii/prep-datasets/java-minus-small-test_19-08-08T23-17-22_java_-_uc10su_-_prep\n",
      "\n",
      "========================   Split example   =========================\n",
      "\n",
      "['void', 'test_WordUeberraschungPrinter', '(', ')', '{', '\\n', '\\t', 'if', '(', 'eps', '>', '=', '0.345e+4', ')', '{', '/', '/', 'FIXME', '10l', '\\n', '<EOL>', '\\t', '\\t', 'printWord', '(', '\"', '.', '.', '.', 'Ãœberraschung', '0x12', '\"', ')', ';', '\\n', '\\t', '}', '\\n', '}']\n",
      "\n",
      "========================   Stats           =========================\n",
      "\n",
      "Train vocab: 11589391\n",
      "Test vocab : 100974, identifiers: 86612 (0.86%)\n",
      "\n",
      "Train corpus size: 2431144083\n",
      "Test corpus size : 10650037, identifiers: 3029114 (0.28%)\n",
      "\n",
      "OOV in test set (top 9223372036854775807): 42485 (42.08%), oov tokens number: 272902 (2.56%)\n",
      "OOV in test set (top 200000): 72243 (71.55%), oov tokens number: 500942 (4.70%)\n",
      "OOV in test set (top 100000): 77406 (76.66%), oov tokens number: 555580 (5.22%)\n",
      "OOV in test set (top 75000): 79629 (78.86%), oov tokens number: 591510 (5.55%)\n",
      "OOV in test set (top 50000): 82689 (81.89%), oov tokens number: 637874 (5.99%)\n",
      "OOV in test set (top 25000): 87810 (86.96%), oov tokens number: 706050 (6.63%)\n",
      "\n",
      "For identifiers: \n",
      "\n",
      "OOV in test set (top 9223372036854775807): 30713 (35.46%), oov tokens number: 236605 (7.81%)\n",
      "OOV in test set (top 200000): 59313 (68.48%), oov tokens number: 456520 (15.07%)\n",
      "OOV in test set (top 100000): 64240 (74.17%), oov tokens number: 508863 (16.80%)\n",
      "OOV in test set (top 75000): 66299 (76.55%), oov tokens number: 544362 (17.97%)\n",
      "OOV in test set (top 50000): 69151 (79.84%), oov tokens number: 590098 (19.48%)\n",
      "OOV in test set (top 25000): 74057 (85.50%), oov tokens number: 657481 (21.71%)\n",
      "[2874996, 6716742, 1755521, 209695, 32437]\n"
     ]
    }
   ],
   "source": [
    "prep_function = PrepFunction(api.nosplit)\n",
    "description = \"unsplit, with comments and vocabulary. No filtering.\"\n",
    "\n",
    "run(prep_function, description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering non-ASCII tokens\n",
      "\n",
      "2019-08-14 11:04:30,149 [dataprep.infrastructure.stages] INFO: Checking first if vocabulary file exists: /home/lv71161/hlibbabii/.config/dataprep/1.0.0-alpha.8/vocab/java-minus-small-test_19-08-08T23-17-22_java_-_Uc10su/vocab\n",
      "2019-08-14 11:04:30,177 [dataprep.infrastructure.stages] INFO: Vocabulary is already computed and up-to-date\n",
      "2019-08-14 11:04:30,179 [dataprep.api.corpus] INFO: Preprocessed dataset is ready at /home/lv71161/hlibbabii/prep-datasets/java-minus-small-test_19-08-08T23-17-22_java_-_Uc10su_-_prep\n",
      "2019-08-14 11:05:03,034 [dataprep.infrastructure.stages] INFO: Checking first if vocabulary file exists: /home/lv71161/hlibbabii/.config/dataprep/1.0.0-alpha.8/vocab/java-small-test_19-02-09T13-18-23_java_-_Uc10su/vocab\n",
      "2019-08-14 11:05:03,037 [dataprep.infrastructure.stages] INFO: Vocabulary is already computed and up-to-date\n",
      "2019-08-14 11:05:03,037 [dataprep.api.corpus] INFO: Preprocessed dataset is ready at /home/lv71161/hlibbabii/prep-datasets/java-small-test_19-02-09T13-18-23_java_-_Uc10su_-_prep\n",
      "Removing prepped dataset at /home/lv71161/hlibbabii/prep-datasets/java-minus-small-test_19-08-08T23-17-22_java_-_Uc10su_-_prep\n",
      "\n",
      "========================   Split example   =========================\n",
      "\n",
      "['void', 'test_WordUeberraschungPrinter', '(', ')', '{', '\\n', '\\t', 'if', '(', 'eps', '>', '=', '0.345e+4', ')', '{', '/', '/', 'FIXME', '10l', '\\n', '<EOL>', '\\t', '\\t', 'printWord', '(', '\"', '.', '.', '.', '<non-en>', '0x12', '\"', ')', ';', '\\n', '\\t', '}', '\\n', '}']\n",
      "\n",
      "========================   Stats           =========================\n",
      "\n",
      "Train vocab: 11418908\n",
      "Test vocab : 89185, identifiers: 86577 (0.97%)\n",
      "\n",
      "Train corpus size: 2431144083\n",
      "Test corpus size : 10650037, identifiers: 3029037 (0.28%)\n",
      "\n",
      "OOV in test set (top 9223372036854775807): 31158 (34.94%), oov tokens number: 237321 (2.23%)\n",
      "OOV in test set (top 200000): 60446 (67.78%), oov tokens number: 458410 (4.30%)\n",
      "OOV in test set (top 100000): 65607 (73.56%), oov tokens number: 511282 (4.80%)\n",
      "OOV in test set (top 75000): 67831 (76.06%), oov tokens number: 547073 (5.14%)\n",
      "OOV in test set (top 50000): 70888 (79.48%), oov tokens number: 593344 (5.57%)\n",
      "OOV in test set (top 25000): 76008 (85.23%), oov tokens number: 661442 (6.21%)\n",
      "\n",
      "For identifiers: \n",
      "\n",
      "OOV in test set (top 9223372036854775807): 30699 (35.46%), oov tokens number: 236576 (7.81%)\n",
      "OOV in test set (top 200000): 59263 (68.45%), oov tokens number: 456233 (15.06%)\n",
      "OOV in test set (top 100000): 64193 (74.15%), oov tokens number: 508717 (16.79%)\n",
      "OOV in test set (top 75000): 66255 (76.53%), oov tokens number: 544227 (17.97%)\n",
      "OOV in test set (top 50000): 69105 (79.82%), oov tokens number: 589954 (19.48%)\n",
      "OOV in test set (top 25000): 74010 (85.48%), oov tokens number: 657259 (21.70%)\n",
      "[2759470, 6667800, 1749998, 209256, 32384]\n"
     ]
    }
   ],
   "source": [
    "prep_function = PrepFunction(api.nosplit, [], {\"no_unicode\": True})\n",
    "description = \"Filtering non-ASCII tokens\"\n",
    "\n",
    "run(prep_function, description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering whitespace (+ non-ascii)\n",
      "\n",
      "2019-08-14 11:07:51,950 [dataprep.infrastructure.stages] INFO: Checking first if vocabulary file exists: /home/lv71161/hlibbabii/.config/dataprep/1.0.0-alpha.8/vocab/java-minus-small-test_19-08-08T23-17-22_java_-_Uc100u/vocab\n",
      "2019-08-14 11:07:51,972 [dataprep.infrastructure.stages] INFO: Vocabulary is already computed and up-to-date\n",
      "2019-08-14 11:07:51,972 [dataprep.api.corpus] INFO: Preprocessed dataset is ready at /home/lv71161/hlibbabii/prep-datasets/java-minus-small-test_19-08-08T23-17-22_java_-_Uc100u_-_prep\n",
      "2019-08-14 11:08:24,462 [dataprep.infrastructure.stages] INFO: Checking first if vocabulary file exists: /home/lv71161/hlibbabii/.config/dataprep/1.0.0-alpha.8/vocab/java-small-test_19-02-09T13-18-23_java_-_Uc100u/vocab\n",
      "2019-08-14 11:08:24,494 [dataprep.infrastructure.stages] INFO: Vocabulary is already computed and up-to-date\n",
      "2019-08-14 11:08:24,495 [dataprep.api.corpus] INFO: Preprocessed dataset is ready at /home/lv71161/hlibbabii/prep-datasets/java-small-test_19-02-09T13-18-23_java_-_Uc100u_-_prep\n",
      "Removing prepped dataset at /home/lv71161/hlibbabii/prep-datasets/java-minus-small-test_19-08-08T23-17-22_java_-_Uc100u_-_prep\n",
      "\n",
      "========================   Split example   =========================\n",
      "\n",
      "['void', 'test_WordUeberraschungPrinter', '(', ')', '{', 'if', '(', 'eps', '>', '=', '0.345e+4', ')', '{', '/', '/', 'FIXME', '10l', '<EOL>', 'printWord', '(', '\"', '.', '.', '.', '<non-en>', '0x12', '\"', ')', ';', '}', '}']\n",
      "\n",
      "========================   Stats           =========================\n",
      "\n",
      "Train vocab: 11418906\n",
      "Test vocab : 89184, identifiers: 86578 (0.97%)\n",
      "\n",
      "Train corpus size: 1892510212\n",
      "Test corpus size : 8341935, identifiers: 3029038 (0.36%)\n",
      "\n",
      "OOV in test set (top 9223372036854775807): 31158 (34.94%), oov tokens number: 237321 (2.84%)\n",
      "OOV in test set (top 200000): 60446 (67.78%), oov tokens number: 458458 (5.50%)\n",
      "OOV in test set (top 100000): 65608 (73.56%), oov tokens number: 511199 (6.13%)\n",
      "OOV in test set (top 75000): 67830 (76.06%), oov tokens number: 547008 (6.56%)\n",
      "OOV in test set (top 50000): 70888 (79.49%), oov tokens number: 593313 (7.11%)\n",
      "OOV in test set (top 25000): 76009 (85.23%), oov tokens number: 661447 (7.93%)\n",
      "\n",
      "For identifiers: \n",
      "\n",
      "OOV in test set (top 9223372036854775807): 30699 (35.46%), oov tokens number: 236576 (7.81%)\n",
      "OOV in test set (top 200000): 59263 (68.45%), oov tokens number: 456281 (15.06%)\n",
      "OOV in test set (top 100000): 64195 (74.15%), oov tokens number: 508635 (16.79%)\n",
      "OOV in test set (top 75000): 66254 (76.53%), oov tokens number: 544162 (17.96%)\n",
      "OOV in test set (top 50000): 69105 (79.82%), oov tokens number: 589923 (19.48%)\n",
      "OOV in test set (top 25000): 74011 (85.48%), oov tokens number: 657264 (21.70%)\n",
      "[2759470, 6667799, 1749998, 209257, 32382]\n"
     ]
    }
   ],
   "source": [
    "prep_function = PrepFunction(api.nosplit, [], {\"no_unicode\": True, \"no_spaces\": True})\n",
    "description = \"Filtering whitespace (+ non-ascii)\"\n",
    "\n",
    "run(prep_function, description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering comments (+ whitespace, + non-ascii)\n",
      "\n",
      "2019-08-14 11:09:04,071 [dataprep.infrastructure.stages] INFO: Checking first if vocabulary file exists: /home/lv71161/hlibbabii/.config/dataprep/1.0.0-alpha.8/vocab/java-minus-small-test_19-08-08T23-17-22_java_-_U0100u/vocab\n",
      "2019-08-14 11:09:04,159 [dataprep.infrastructure.stages] INFO: Vocabulary is already computed and up-to-date\n",
      "2019-08-14 11:09:04,160 [dataprep.api.corpus] INFO: Preprocessed dataset is ready at /home/lv71161/hlibbabii/prep-datasets/java-minus-small-test_19-08-08T23-17-22_java_-_U0100u_-_prep\n",
      "2019-08-14 11:09:38,090 [dataprep.infrastructure.stages] INFO: Checking first if vocabulary file exists: /home/lv71161/hlibbabii/.config/dataprep/1.0.0-alpha.8/vocab/java-small-test_19-02-09T13-18-23_java_-_U0100u/vocab\n",
      "2019-08-14 11:09:38,245 [dataprep.infrastructure.stages] INFO: Vocabulary is already computed and up-to-date\n",
      "2019-08-14 11:09:38,246 [dataprep.api.corpus] INFO: Preprocessed dataset is ready at /home/lv71161/hlibbabii/prep-datasets/java-small-test_19-02-09T13-18-23_java_-_U0100u_-_prep\n",
      "Removing prepped dataset at /home/lv71161/hlibbabii/prep-datasets/java-minus-small-test_19-08-08T23-17-22_java_-_U0100u_-_prep\n",
      "\n",
      "========================   Split example   =========================\n",
      "\n",
      "['void', 'test_WordUeberraschungPrinter', '(', ')', '{', 'if', '(', 'eps', '>', '=', '0.345e+4', ')', '{', '<comment>', 'printWord', '(', '\"', '.', '.', '.', '<non-en>', '0x12', '\"', ')', ';', '}', '}']\n",
      "\n",
      "========================   Stats           =========================\n",
      "\n",
      "Train vocab: 10813844\n",
      "Test vocab : 80334, identifiers: 78340 (0.98%)\n",
      "\n",
      "Train corpus size: 1261768048\n",
      "Test corpus size : 5851993, identifiers: 1947796 (0.33%)\n",
      "\n",
      "OOV in test set (top 9223372036854775807): 30304 (37.72%), oov tokens number: 222756 (3.81%)\n",
      "OOV in test set (top 200000): 56401 (70.21%), oov tokens number: 415208 (7.10%)\n",
      "OOV in test set (top 100000): 60840 (75.73%), oov tokens number: 461900 (7.89%)\n",
      "OOV in test set (top 75000): 62624 (77.95%), oov tokens number: 483114 (8.26%)\n",
      "OOV in test set (top 50000): 65056 (80.98%), oov tokens number: 532645 (9.10%)\n",
      "OOV in test set (top 25000): 69245 (86.20%), oov tokens number: 592727 (10.13%)\n",
      "\n",
      "For identifiers: \n",
      "\n",
      "OOV in test set (top 9223372036854775807): 29852 (38.11%), oov tokens number: 222014 (11.40%)\n",
      "OOV in test set (top 200000): 55491 (70.83%), oov tokens number: 413482 (21.23%)\n",
      "OOV in test set (top 100000): 59771 (76.30%), oov tokens number: 459885 (23.61%)\n",
      "OOV in test set (top 75000): 61481 (78.48%), oov tokens number: 480911 (24.69%)\n",
      "OOV in test set (top 50000): 63818 (81.46%), oov tokens number: 530245 (27.22%)\n",
      "OOV in test set (top 25000): 67842 (86.60%), oov tokens number: 589680 (30.27%)\n",
      "[2532907, 6487131, 1586806, 181371, 25629]\n"
     ]
    }
   ],
   "source": [
    "prep_function = PrepFunction(api.nosplit, [], {\"no_unicode\": True, \"no_spaces\": True, \"no_com\": True})\n",
    "description = \"Filtering comments (+ whitespace, + non-ascii)\"\n",
    "\n",
    "run(prep_function, description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering  strings (+ comments, + whitespace, + non-ascii)\n",
      "\n",
      "2019-08-16 12:01:58,564 [dataprep.infrastructure.stages] INFO: Checking first if vocabulary file exists: /home/lv71161/hlibbabii/.config/dataprep/1.0.0-alpha.8/vocab/java-minus-small-test_19-08-08T23-17-22_java_-_U0000u/vocab\n",
      "2019-08-16 12:01:58,621 [dataprep.infrastructure.stages] INFO: Vocabulary is already computed and up-to-date\n",
      "2019-08-16 12:01:58,622 [dataprep.api.corpus] INFO: Preprocessed dataset is ready at /home/lv71161/hlibbabii/prep-datasets/java-minus-small-test_19-08-08T23-17-22_java_-_U0000u_-_prep\n",
      "2019-08-16 12:02:23,453 [dataprep.infrastructure.stages] INFO: Checking first if vocabulary file exists: /home/lv71161/hlibbabii/.config/dataprep/1.0.0-alpha.8/vocab/java-small-test_19-02-09T13-18-23_java_-_U0000u/vocab\n",
      "2019-08-16 12:02:23,523 [dataprep.infrastructure.stages] INFO: Vocabulary is already computed and up-to-date\n",
      "2019-08-16 12:02:23,524 [dataprep.api.corpus] INFO: Preprocessed dataset is ready at /home/lv71161/hlibbabii/prep-datasets/java-small-test_19-02-09T13-18-23_java_-_U0000u_-_prep\n",
      "Removing prepped dataset at /home/lv71161/hlibbabii/prep-datasets/java-minus-small-test_19-08-08T23-17-22_java_-_U0000u_-_prep\n",
      "\n",
      "========================   Split example   =========================\n",
      "\n",
      "['void', 'test_WordUeberraschungPrinter', '(', ')', '{', 'if', '(', 'eps', '>', '=', '0.345e+4', ')', '{', '<comment>', 'printWord', '(', '<str-literal>', ')', ';', '}', '}']\n",
      "\n",
      "========================   Stats           =========================\n",
      "\n",
      "Train vocab: 9521607\n",
      "Test vocab : 70745, identifiers: 69274 (0.98%)\n",
      "\n",
      "Train corpus size: 1151554964\n",
      "Test corpus size : 5431529, identifiers: 1791408 (0.33%)\n",
      "\n",
      "OOV in test set (top 9223372036854775807): 27274 (38.55%), oov tokens number: 222901 (4.10%)\n",
      "OOV in test set (top 200000): 49948 (70.60%), oov tokens number: 386753 (7.12%)\n",
      "OOV in test set (top 100000): 53813 (76.07%), oov tokens number: 431548 (7.95%)\n",
      "OOV in test set (top 75000): 55361 (78.25%), oov tokens number: 449269 (8.27%)\n",
      "OOV in test set (top 50000): 57442 (81.20%), oov tokens number: 500056 (9.21%)\n",
      "OOV in test set (top 25000): 60996 (86.22%), oov tokens number: 551722 (10.16%)\n",
      "\n",
      "For identifiers: \n",
      "\n",
      "OOV in test set (top 9223372036854775807): 26987 (38.96%), oov tokens number: 222547 (12.42%)\n",
      "OOV in test set (top 200000): 49393 (71.30%), oov tokens number: 386023 (21.55%)\n",
      "OOV in test set (top 100000): 53126 (76.69%), oov tokens number: 430615 (24.04%)\n",
      "OOV in test set (top 75000): 54626 (78.85%), oov tokens number: 448268 (25.02%)\n",
      "OOV in test set (top 50000): 56637 (81.76%), oov tokens number: 498937 (27.85%)\n",
      "OOV in test set (top 25000): 60059 (86.70%), oov tokens number: 550285 (30.72%)\n",
      "[1899280, 5980484, 1451884, 166995, 22964]\n"
     ]
    }
   ],
   "source": [
    "prep_function = PrepFunction(api.nosplit, [], {\"no_unicode\": True, \"no_spaces\": True, \"no_com\": True, \"no_str\": True})\n",
    "description = \"Filtering  strings (+ comments, + whitespace, + non-ascii)\"\n",
    "\n",
    "run(prep_function, description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An additional choice, the model from Hellendoorn and Devanbu: keep strings shorter than 15 char (check SLP-core code), remove others, remove comments\n",
      "\n",
      "2019-08-14 11:11:13,725 [dataprep.infrastructure.stages] INFO: Checking first if vocabulary file exists: /home/lv71161/hlibbabii/.config/dataprep/1.0.0-alpha.8/vocab/java-minus-small-test_19-08-08T23-17-22_java_-_u0EFsu/vocab\n",
      "2019-08-14 11:11:13,738 [dataprep.infrastructure.stages] INFO: Vocabulary is already computed and up-to-date\n",
      "2019-08-14 11:11:13,738 [dataprep.api.corpus] INFO: Preprocessed dataset is ready at /home/lv71161/hlibbabii/prep-datasets/java-minus-small-test_19-08-08T23-17-22_java_-_u0EFsu_-_prep\n",
      "2019-08-14 11:11:46,076 [dataprep.infrastructure.stages] INFO: Checking first if vocabulary file exists: /home/lv71161/hlibbabii/.config/dataprep/1.0.0-alpha.8/vocab/java-small-test_19-02-09T13-18-23_java_-_u0EFsu/vocab\n",
      "2019-08-14 11:11:46,093 [dataprep.infrastructure.stages] INFO: Vocabulary is already computed and up-to-date\n",
      "2019-08-14 11:11:46,094 [dataprep.api.corpus] INFO: Preprocessed dataset is ready at /home/lv71161/hlibbabii/prep-datasets/java-small-test_19-02-09T13-18-23_java_-_u0EFsu_-_prep\n",
      "Removing prepped dataset at /home/lv71161/hlibbabii/prep-datasets/java-minus-small-test_19-08-08T23-17-22_java_-_u0EFsu_-_prep\n",
      "\n",
      "========================   Split example   =========================\n",
      "\n",
      "['void', 'test_WordUeberraschungPrinter', '(', ')', '{', '\\n', '\\t', 'if', '(', 'eps', '>', '=', '0.345e+4', ')', '{', '<comment>', '\\t', '\\t', 'printWord', '(', '\"\"', ')', ';', '\\n', '\\t', '}', '\\n', '}']\n",
      "\n",
      "========================   Stats           =========================\n",
      "\n",
      "Train vocab: 10939739\n",
      "Test vocab : 82567, identifiers: 69273 (0.84%)\n",
      "\n",
      "Train corpus size: 1594485207\n",
      "Test corpus size : 7311181, identifiers: 1791407 (0.25%)\n",
      "\n",
      "OOV in test set (top 9223372036854775807): 32150 (38.94%), oov tokens number: 235288 (3.22%)\n",
      "OOV in test set (top 200000): 59315 (71.84%), oov tokens number: 413556 (5.66%)\n",
      "OOV in test set (top 100000): 63834 (77.31%), oov tokens number: 460376 (6.30%)\n",
      "OOV in test set (top 75000): 65694 (79.56%), oov tokens number: 482442 (6.60%)\n",
      "OOV in test set (top 50000): 68131 (82.52%), oov tokens number: 531641 (7.27%)\n",
      "OOV in test set (top 25000): 72186 (87.43%), oov tokens number: 589038 (8.06%)\n",
      "\n",
      "For identifiers: \n",
      "\n",
      "OOV in test set (top 9223372036854775807): 26987 (38.96%), oov tokens number: 222547 (12.42%)\n",
      "OOV in test set (top 200000): 49640 (71.66%), oov tokens number: 389303 (21.73%)\n",
      "OOV in test set (top 100000): 53339 (77.00%), oov tokens number: 432971 (24.17%)\n",
      "OOV in test set (top 75000): 54864 (79.20%), oov tokens number: 454049 (25.35%)\n",
      "OOV in test set (top 50000): 56867 (82.09%), oov tokens number: 501155 (27.98%)\n",
      "OOV in test set (top 25000): 60266 (87.00%), oov tokens number: 553965 (30.92%)\n",
      "[2727133, 6490997, 1523145, 174527, 23937]\n"
     ]
    }
   ],
   "source": [
    "prep_function = PrepFunction(api.nosplit, [], {\"no_com\": True, \"full_strings\": True, \"max_str_length\": 14})\n",
    "description = \"An additional choice, the model from Hellendoorn and Devanbu: keep strings shorter than 15 char (check SLP-core code), remove others, remove comments\"\n",
    "\n",
    "run(prep_function, description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Unsplit, remove non-ascii, remove whitespace, remove comments, remove strings longer than 15 chars] + Word splitting via conventions\n",
      "\n",
      "2019-08-14 11:12:19,725 [dataprep.infrastructure.stages] INFO: Checking first if vocabulary file exists: /home/lv71161/hlibbabii/.config/dataprep/1.0.0-alpha.8/vocab/java-minus-small-test_19-08-08T23-17-22_java_-_U0E10u/vocab\n",
      "2019-08-14 11:12:19,727 [dataprep.infrastructure.stages] INFO: Vocabulary is already computed and up-to-date\n",
      "2019-08-14 11:12:19,729 [dataprep.api.corpus] INFO: Preprocessed dataset is ready at /home/lv71161/hlibbabii/prep-datasets/java-minus-small-test_19-08-08T23-17-22_java_-_U0E10u_-_prep\n",
      "2019-08-14 11:12:25,575 [dataprep.infrastructure.stages] INFO: Checking first if vocabulary file exists: /home/lv71161/hlibbabii/.config/dataprep/1.0.0-alpha.8/vocab/java-small-test_19-02-09T13-18-23_java_-_U0E10u/vocab\n",
      "2019-08-14 11:12:25,592 [dataprep.infrastructure.stages] INFO: Vocabulary is already computed and up-to-date\n",
      "2019-08-14 11:12:25,593 [dataprep.api.corpus] INFO: Preprocessed dataset is ready at /home/lv71161/hlibbabii/prep-datasets/java-small-test_19-02-09T13-18-23_java_-_U0E10u_-_prep\n",
      "Removing prepped dataset at /home/lv71161/hlibbabii/prep-datasets/java-minus-small-test_19-08-08T23-17-22_java_-_U0E10u_-_prep\n",
      "\n",
      "========================   Split example   =========================\n",
      "\n",
      "['void', '<w>', 'test', '_', 'Word', 'Ueberraschung', 'Printer', '</w>', '(', ')', '{', 'if', '(', 'eps', '>', '=', '0.345e+4', ')', '{', '<comment>', '<w>', 'print', 'Word', '</w>', '(', '\"', '\"', ')', ';', '}', '}']\n",
      "\n",
      "========================   Stats           =========================\n",
      "\n",
      "Train vocab: 1270257\n",
      "Test vocab : 16450, identifiers: 14739 (0.90%)\n",
      "\n",
      "Train corpus size: 1812960637\n",
      "Test corpus size : 8383149, identifiers: 3016823 (0.36%)\n",
      "\n",
      "OOV in test set (top 9223372036854775807): 1247 (7.58%), oov tokens number: 50442 (0.60%)\n",
      "OOV in test set (top 200000): 2206 (13.41%), oov tokens number: 60404 (0.72%)\n",
      "OOV in test set (top 100000): 2918 (17.74%), oov tokens number: 67197 (0.80%)\n",
      "OOV in test set (top 75000): 3317 (20.16%), oov tokens number: 71773 (0.86%)\n",
      "OOV in test set (top 50000): 4028 (24.49%), oov tokens number: 79559 (0.95%)\n",
      "OOV in test set (top 25000): 5836 (35.48%), oov tokens number: 129028 (1.54%)\n",
      "\n",
      "For identifiers: \n",
      "\n",
      "OOV in test set (top 9223372036854775807): 951 (6.45%), oov tokens number: 50064 (1.66%)\n",
      "OOV in test set (top 200000): 1765 (11.98%), oov tokens number: 59728 (1.98%)\n",
      "OOV in test set (top 100000): 2375 (16.11%), oov tokens number: 66329 (2.20%)\n",
      "OOV in test set (top 75000): 2700 (18.32%), oov tokens number: 70786 (2.35%)\n",
      "OOV in test set (top 50000): 3273 (22.21%), oov tokens number: 78256 (2.59%)\n",
      "OOV in test set (top 25000): 4777 (32.41%), oov tokens number: 126981 (4.21%)\n",
      "[476518, 552034, 173295, 48302, 20108]\n"
     ]
    }
   ],
   "source": [
    "prep_function = PrepFunction(api.basic, [],\n",
    "                             {\"no_unicode\": True, \"no_spaces\": True, \"no_com\": True, \"max_str_length\": 14})\n",
    "description = \"[Unsplit, remove non-ascii, remove whitespace, remove comments, remove strings longer than 15 chars] + Word splitting via conventions\"\n",
    "\n",
    "run(prep_function, description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Unsplit, remove non-ascii, remove whitespace, remove comments, remove strings longer than 15 chars] + Word splitting via conventions, and remove case.\n",
      "\n",
      "2019-08-16 14:54:02,956 [dataprep.infrastructure.stages] INFO: Checking first if vocabulary file exists: /home/lv71161/hlibbabii/.config/dataprep/1.0.0-alpha.8/vocab/java-minus-small-test_19-08-08T23-17-22_java_-_U0E10l/vocab\n",
      "2019-08-16 14:54:02,967 [dataprep.infrastructure.stages] INFO: Vocabulary is already computed and up-to-date\n",
      "2019-08-16 14:54:02,967 [dataprep.api.corpus] INFO: Preprocessed dataset is ready at /home/lv71161/hlibbabii/prep-datasets/java-minus-small-test_19-08-08T23-17-22_java_-_U0E10l_-_prep\n",
      "2019-08-16 14:54:08,592 [dataprep.infrastructure.stages] INFO: Checking first if vocabulary file exists: /home/lv71161/hlibbabii/.config/dataprep/1.0.0-alpha.8/vocab/java-small-test_19-02-09T13-18-23_java_-_U0E10l/vocab\n",
      "2019-08-16 14:54:08,602 [dataprep.infrastructure.stages] INFO: Vocabulary is already computed and up-to-date\n",
      "2019-08-16 14:54:08,604 [dataprep.api.corpus] INFO: Preprocessed dataset is ready at /home/lv71161/hlibbabii/prep-datasets/java-small-test_19-02-09T13-18-23_java_-_U0E10l_-_prep\n",
      "Removing prepped dataset at /home/lv71161/hlibbabii/prep-datasets/java-minus-small-test_19-08-08T23-17-22_java_-_U0E10l_-_prep\n",
      "\n",
      "========================   Split example   =========================\n",
      "\n",
      "['void', '<w>', 'test', '_', '<Cap>', 'word', '<Cap>', 'ueberraschung', '<Cap>', 'printer', '</w>', '(', ')', '{', 'if', '(', 'eps', '>', '=', '0.345e+4', ')', '{', '<comment>', '<w>', 'print', '<Cap>', 'word', '</w>', '(', '\"', '\"', ')', ';', '}', '}']\n",
      "\n",
      "========================   Stats           =========================\n",
      "\n",
      "Train vocab: 1098305\n",
      "Test vocab : 10439, identifiers: 8726 (0.84%)\n",
      "\n",
      "Train corpus size: 2160127794\n",
      "Test corpus size : 10030252, identifiers: 2954550 (0.29%)\n",
      "\n",
      "OOV in test set (top 9223372036854775807): 990 (9.48%), oov tokens number: 35904 (0.36%)\n",
      "OOV in test set (top 200000): 1558 (14.92%), oov tokens number: 50552 (0.50%)\n",
      "OOV in test set (top 100000): 1964 (18.81%), oov tokens number: 56987 (0.57%)\n",
      "OOV in test set (top 75000): 2195 (21.03%), oov tokens number: 59813 (0.60%)\n",
      "OOV in test set (top 50000): 2559 (24.51%), oov tokens number: 65285 (0.65%)\n",
      "OOV in test set (top 25000): 3436 (32.92%), oov tokens number: 76542 (0.76%)\n",
      "\n",
      "For identifiers: \n",
      "\n",
      "OOV in test set (top 9223372036854775807): 694 (7.95%), oov tokens number: 35526 (1.20%)\n",
      "OOV in test set (top 200000): 1146 (13.13%), oov tokens number: 49908 (1.69%)\n",
      "OOV in test set (top 100000): 1482 (16.98%), oov tokens number: 56219 (1.90%)\n",
      "OOV in test set (top 75000): 1666 (19.09%), oov tokens number: 58971 (2.00%)\n",
      "OOV in test set (top 50000): 1936 (22.19%), oov tokens number: 64291 (2.18%)\n",
      "OOV in test set (top 25000): 2532 (29.02%), oov tokens number: 74875 (2.53%)\n",
      "[441824, 475548, 133762, 33519, 13652]\n"
     ]
    }
   ],
   "source": [
    "prep_function = PrepFunction(api.basic, [],\n",
    "                             {\"no_unicode\": True, \"no_spaces\": True, \"no_com\": True, \"max_str_length\": 14,\n",
    "                              \"no_case\": True})\n",
    "description = \"[Unsplit, remove non-ascii, remove whitespace, remove comments, remove strings longer than 15 chars] + Word splitting via conventions, and remove case.\"\n",
    "\n",
    "run(prep_function, description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Unsplit, remove non-ascii, remove whitespace, remove comments, remove strings longer than 15 chars] + split via conventions, but keep case.+ Split numbers\n",
      "\n",
      "2019-08-16 14:54:12,001 [dataprep.infrastructure.stages] INFO: Checking first if vocabulary file exists: /home/lv71161/hlibbabii/.config/dataprep/1.0.0-alpha.8/vocab/java-minus-small-test_19-08-08T23-17-22_java_-_U0E20l/vocab\n",
      "2019-08-16 14:54:12,025 [dataprep.infrastructure.stages] INFO: Vocabulary is already computed and up-to-date\n",
      "2019-08-16 14:54:12,026 [dataprep.api.corpus] INFO: Preprocessed dataset is ready at /home/lv71161/hlibbabii/prep-datasets/java-minus-small-test_19-08-08T23-17-22_java_-_U0E20l_-_prep\n",
      "2019-08-16 14:54:14,775 [dataprep.infrastructure.stages] INFO: Checking first if vocabulary file exists: /home/lv71161/hlibbabii/.config/dataprep/1.0.0-alpha.8/vocab/java-small-test_19-02-09T13-18-23_java_-_U0E20l/vocab\n",
      "2019-08-16 14:54:14,798 [dataprep.infrastructure.stages] INFO: Vocabulary is already computed and up-to-date\n",
      "2019-08-16 14:54:14,799 [dataprep.api.corpus] INFO: Preprocessed dataset is ready at /home/lv71161/hlibbabii/prep-datasets/java-small-test_19-02-09T13-18-23_java_-_U0E20l_-_prep\n",
      "Removing prepped dataset at /home/lv71161/hlibbabii/prep-datasets/java-minus-small-test_19-08-08T23-17-22_java_-_U0E20l_-_prep\n",
      "\n",
      "========================   Split example   =========================\n",
      "\n",
      "['void', '<w>', 'test', '_', '<Cap>', 'word', '<Cap>', 'ueberraschung', '<Cap>', 'printer', '</w>', '(', ')', '{', 'if', '(', 'eps', '>', '=', '<w>', '0', '.', '3', '4', '5', 'e', '+', '4', '</w>', ')', '{', '<comment>', '<w>', 'print', '<Cap>', 'word', '</w>', '(', '\"', '\"', ')', ';', '}', '}']\n",
      "\n",
      "========================   Stats           =========================\n",
      "\n",
      "Train vocab: 622735\n",
      "Test vocab : 9105, identifiers: 8726 (0.96%)\n",
      "\n",
      "Train corpus size: 2199424158\n",
      "Test corpus size : 10075383, identifiers: 2957288 (0.29%)\n",
      "\n",
      "OOV in test set (top 9223372036854775807): 700 (7.69%), oov tokens number: 35537 (0.35%)\n",
      "OOV in test set (top 200000): 1154 (12.67%), oov tokens number: 49115 (0.49%)\n",
      "OOV in test set (top 100000): 1524 (16.74%), oov tokens number: 53213 (0.53%)\n",
      "OOV in test set (top 75000): 1703 (18.70%), oov tokens number: 57646 (0.57%)\n",
      "OOV in test set (top 50000): 1993 (21.89%), oov tokens number: 62221 (0.62%)\n",
      "OOV in test set (top 25000): 2634 (28.93%), oov tokens number: 74035 (0.73%)\n",
      "\n",
      "For identifiers: \n",
      "\n",
      "OOV in test set (top 9223372036854775807): 694 (7.95%), oov tokens number: 35526 (1.20%)\n",
      "OOV in test set (top 200000): 1091 (12.50%), oov tokens number: 48913 (1.65%)\n",
      "OOV in test set (top 100000): 1441 (16.51%), oov tokens number: 52954 (1.79%)\n",
      "OOV in test set (top 75000): 1615 (18.51%), oov tokens number: 57377 (1.94%)\n",
      "OOV in test set (top 50000): 1888 (21.64%), oov tokens number: 61818 (2.09%)\n",
      "OOV in test set (top 25000): 2495 (28.59%), oov tokens number: 73522 (2.49%)\n",
      "[147169, 314901, 116031, 31437, 13197]\n"
     ]
    }
   ],
   "source": [
    "prep_function = PrepFunction(api.basic, [],\n",
    "                             {\"no_unicode\": True, \"no_spaces\": True, \"no_com\": True, \"max_str_length\": 14,\n",
    "                              \"no_case\": True, \"split_numbers\": True})\n",
    "description = \"[Unsplit, remove non-ascii, remove whitespace, remove comments, remove strings longer than 15 chars] + split via conventions, but keep case.+ Split numbers\"\n",
    "run(prep_function, description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Unsplit, remove non-ascii, remove whitespace, remove comments, remove strings longer than 15 chars] + split via conventions, but keep case. + Split numbers + Ronin\n",
      "\n",
      "2019-08-16 14:56:11,400 [dataprep.infrastructure.stages] INFO: Checking first if vocabulary file exists: /home/lv71161/hlibbabii/.config/dataprep/1.0.0-alpha.8/vocab/java-minus-small-test_19-08-08T23-17-22_java_-_U0E30l/vocab\n",
      "2019-08-16 14:56:11,401 [dataprep.infrastructure.stages] INFO: Vocabulary is already computed and up-to-date\n",
      "2019-08-16 14:56:11,401 [dataprep.api.corpus] INFO: Preprocessed dataset is ready at /home/lv71161/hlibbabii/prep-datasets/java-minus-small-test_19-08-08T23-17-22_java_-_U0E30l_-_prep\n",
      "2019-08-16 14:56:12,655 [dataprep.infrastructure.stages] INFO: Checking first if vocabulary file exists: /home/lv71161/hlibbabii/.config/dataprep/1.0.0-alpha.8/vocab/java-small-test_19-02-09T13-18-23_java_-_U0E30l/vocab\n",
      "2019-08-16 14:56:12,657 [dataprep.infrastructure.stages] INFO: Vocabulary is already computed and up-to-date\n",
      "2019-08-16 14:56:12,658 [dataprep.api.corpus] INFO: Preprocessed dataset is ready at /home/lv71161/hlibbabii/prep-datasets/java-small-test_19-02-09T13-18-23_java_-_U0E30l_-_prep\n",
      "Removing prepped dataset at /home/lv71161/hlibbabii/prep-datasets/java-minus-small-test_19-08-08T23-17-22_java_-_U0E30l_-_prep\n",
      "\n",
      "========================   Split example   =========================\n",
      "\n",
      "['void', '<w>', 'test', '_', '<Cap>', 'word', '<Cap>', 'ueberraschung', '<Cap>', 'printer', '</w>', '(', ')', '{', 'if', '(', 'eps', '>', '=', '<w>', '0', '.', '3', '4', '5', 'e', '+', '4', '</w>', ')', '{', '<comment>', '<w>', 'print', '<Cap>', 'word', '</w>', '(', '\"', '\"', ')', ';', '}', '}']\n",
      "\n",
      "========================   Stats           =========================\n",
      "\n",
      "Train vocab: 363291\n",
      "Test vocab : 7558, identifiers: 7179 (0.95%)\n",
      "\n",
      "Train corpus size: 2233565327\n",
      "Test corpus size : 10266581, identifiers: 3040958 (0.30%)\n",
      "\n",
      "OOV in test set (top 9223372036854775807): 262 (3.47%), oov tokens number: 9460 (0.09%)\n",
      "OOV in test set (top 200000): 340 (4.50%), oov tokens number: 9903 (0.10%)\n",
      "OOV in test set (top 100000): 488 (6.46%), oov tokens number: 11500 (0.11%)\n",
      "OOV in test set (top 75000): 572 (7.57%), oov tokens number: 12147 (0.12%)\n",
      "OOV in test set (top 50000): 722 (9.55%), oov tokens number: 14211 (0.14%)\n",
      "OOV in test set (top 25000): 1096 (14.50%), oov tokens number: 20203 (0.20%)\n",
      "\n",
      "For identifiers: \n",
      "\n",
      "OOV in test set (top 9223372036854775807): 256 (3.57%), oov tokens number: 9449 (0.31%)\n",
      "OOV in test set (top 200000): 312 (4.35%), oov tokens number: 9841 (0.32%)\n",
      "OOV in test set (top 100000): 421 (5.86%), oov tokens number: 11288 (0.37%)\n",
      "OOV in test set (top 75000): 497 (6.92%), oov tokens number: 11920 (0.39%)\n",
      "OOV in test set (top 50000): 634 (8.83%), oov tokens number: 13942 (0.46%)\n",
      "OOV in test set (top 25000): 964 (13.43%), oov tokens number: 19735 (0.65%)\n",
      "[102926, 168520, 58905, 20910, 12030]\n"
     ]
    }
   ],
   "source": [
    "prep_function = PrepFunction(api.basic, [],\n",
    "                             {\"no_unicode\": True, \"no_spaces\": True, \"no_com\": True, \"max_str_length\": 14,\n",
    "                              \"no_case\": True, \"split_numbers\": True, \"ronin\": True})\n",
    "description = \"[Unsplit, remove non-ascii, remove whitespace, remove comments, remove strings longer than 15 chars] + split via conventions, but keep case. + Split numbers + Ronin\"\n",
    "run(prep_function, description)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_function = PrepFunction(api.bpe, ['java-bpe-training_nounicode-2000'], {\"no_com\": True, \"max_str_length\": 14})\n",
    "description = \"bpe 2k Hellendoorn and Devanbu strings no comments\"\n",
    "run(prep_function, description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_function = PrepFunction(api.bpe, ['java-bpe-training_nounicode-5000'], {\"no_com\": True, \"max_str_length\": 14})\n",
    "description = \"bpe 5k Hellendoorn and Devanbu strings no comments\"\n",
    "run(prep_function, description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_function = PrepFunction(api.bpe, ['java-bpe-training_nounicode-10000'], {\"no_com\": True, \"max_str_length\": 14})\n",
    "description = \"bpe 10k Hellendoorn and Devanbu strings no comments\"\n",
    "run(prep_function, description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_function = PrepFunction(api.bpe, ['java-bpe-training_nounicode-1000'], {\"no_com\": True, \"max_str_length\": 14})\n",
    "description = \"bpe 1k Hellendoorn and Devanbu strings no comments\"\n",
    "run(prep_function, description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_function = PrepFunction(api.bpe, ['java-bpe-training_nounicode-20000'], {\"no_com\": True, \"max_str_length\": 14})\n",
    "description = \"bpe 20k Hellendoorn and Devanbu strings no comments\"\n",
    "run(prep_function, description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_function = PrepFunction(api.bpe, ['java-bpe-training_nounicode-2000'], {})\n",
    "description = \"bpe 2k\"\n",
    "run(prep_function, description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_function = PrepFunction(api.bpe, ['java-bpe-training_nounicode-5000'], {})\n",
    "description = \"bpe 5k\"\n",
    "run(prep_function, description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_function = PrepFunction(api.bpe, ['java-bpe-training_nounicode-10000'], {})\n",
    "description = \"bpe 10k\"\n",
    "run(prep_function, description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_function = PrepFunction(api.bpe, ['java-bpe-training_nounicode-1000'], {})\n",
    "description = \"bpe 1k\"\n",
    "run(prep_function, description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_function = PrepFunction(api.bpe, ['java-bpe-training_nounicode-20000'], {})\n",
    "description = \"bpe 20k\"\n",
    "run(prep_function, description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bpe 1k no strings no comments\n",
      "\n",
      "2019-08-16 14:56:36,553 [dataprep.infrastructure.stages] INFO: Checking first if vocabulary file exists: /home/lv71161/hlibbabii/.config/dataprep/1.0.0-alpha.8/vocab/java-minus-small-test_19-08-08T23-17-22_java_-_u009su_java-bpe-training_nounicode-1000/vocab\n",
      "2019-08-16 14:56:36,555 [dataprep.infrastructure.stages] INFO: Parsing...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-1e7c1d1c17bf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprep_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPrepFunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbpe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'java-bpe-training_nounicode-1000'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"no_com\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"no_str\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdescription\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"bpe 1k no strings no comments\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescription\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-2-9f6da480bade>\u001b[0m in \u001b[0;36mrun\u001b[0;34m(prep_function, description)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep_function\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mPrepFunction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescription\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mcalc_and_display_stats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescription\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mJAVA_DATASETS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mJAVA_KEYWORDS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'java'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/projects/log-recommender-dataprep/vocabstudy/common.py\u001b[0m in \u001b[0;36mcalc_and_display_stats\u001b[0;34m(prep_function, description, datasets, keywords, extension)\u001b[0m\n\u001b[1;32m    143\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0mdataset_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPATH_TO_DATASETS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m         \u001b[0mprep_corpus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprep_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCorpus\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextension\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mHOME\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'prep-datasets'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m         \u001b[0mprep_corpora\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep_corpus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0mvocabs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep_corpus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/log-recommender-dataprep/vocabstudy/common.py\u001b[0m in \u001b[0;36mprep_corpus\u001b[0;34m(corpus, **kwargs)\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mprep_corpus\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mCorpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m             return self.callable(corpus.path, *self.params, **self.options, **kwargs,\n\u001b[0;32m---> 60\u001b[0;31m                                  calc_vocab=True, extensions=corpus.extensions)\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mprep_corpus\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-2019.03/envs/metrics/lib/python3.7/site-packages/dataprep/api/corpus.py\u001b[0m in \u001b[0;36mbpe\u001b[0;34m(path, bpe_codes_id, extensions, no_spaces, no_unicode, no_com, no_str, max_str_length, output_path, calc_vocab)\u001b[0m\n\u001b[1;32m    181\u001b[0m                                     no_com=no_com, no_str=no_str, max_str_length=max_str_length)\n\u001b[1;32m    182\u001b[0m     return preprocess_corpus(path, prep_config, bpe_codes_id,\n\u001b[0;32m--> 183\u001b[0;31m                              extensions=extensions, output_path=output_path, calc_vocab=calc_vocab)\n\u001b[0m\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-2019.03/envs/metrics/lib/python3.7/site-packages/dataprep/api/corpus.py\u001b[0m in \u001b[0;36mpreprocess_corpus\u001b[0;34m(path, prep_config, bpe_codes_id, extensions, output_path, calc_vocab)\u001b[0m\n\u001b[1;32m    196\u001b[0m                              overriden_path_to_prep_dataset=output_path)\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcalc_vocab\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 198\u001b[0;31m         \u001b[0mstages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_until_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_bpe_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m         \u001b[0mpath_to_vocab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath_to_vocab_file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-2019.03/envs/metrics/lib/python3.7/site-packages/dataprep/infrastructure/stages.py\u001b[0m in \u001b[0;36mrun_until_vocab\u001b[0;34m(dataset, custom_bpe_config)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_path_ready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath_to_vocab_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0mrun_until_preprocessing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_bpe_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Computing vocab...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0mcalc_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-2019.03/envs/metrics/lib/python3.7/site-packages/dataprep/infrastructure/stages.py\u001b[0m in \u001b[0;36mrun_until_preprocessing\u001b[0;34m(dataset, custom_bpe_config)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrun_until_preprocessing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_bpe_config\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCustomBpeConfig\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0mrun_parsing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Preprocessing...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-2019.03/envs/metrics/lib/python3.7/site-packages/dataprep/infrastructure/stages.py\u001b[0m in \u001b[0;36mrun_parsing\u001b[0;34m(dataset)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparsed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mparse_projects\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0;32melif\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparsed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_outdated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparsed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marchive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mparse_projects\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-2019.03/envs/metrics/lib/python3.7/site-packages/dataprep/infrastructure/dataset.py\u001b[0m in \u001b[0;36mis_outdated\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mis_outdated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mis_path_outdated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfile_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mGenerator\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-2019.03/envs/metrics/lib/python3.7/site-packages/dataprep/infrastructure/dataset.py\u001b[0m in \u001b[0;36mis_path_outdated\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    293\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodif_file\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0mexpected_timestamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m         \u001b[0mactual_timestamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_timestamp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mexpected_timestamp\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mactual_timestamp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-2019.03/envs/metrics/lib/python3.7/site-packages/dataprep/dirutils.py\u001b[0m in \u001b[0;36mget_timestamp\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_timestamp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m     \u001b[0mlast_modif_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_dir_last_modification\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mlast_modif_time\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%y-%m-%dT%H-%M-%S\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-2019.03/envs/metrics/lib/python3.7/site-packages/dataprep/dirutils.py\u001b[0m in \u001b[0;36mget_dir_last_modification\u001b[0;34m(path, limit)\u001b[0m\n\u001b[1;32m     70\u001b[0m                         \u001b[0;32myield\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetmtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m     \u001b[0mmtime\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwalk_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromtimestamp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmtime\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-2019.03/envs/metrics/lib/python3.7/site-packages/dataprep/dirutils.py\u001b[0m in \u001b[0;36mwalk_path\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetmtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdirs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwalk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mdir\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdirs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mcounter\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-2019.03/envs/metrics/lib/python3.7/os.py\u001b[0m in \u001b[0;36mwalk\u001b[0;34m(top, topdown, onerror, followlinks)\u001b[0m\n\u001b[1;32m    408\u001b[0m             \u001b[0;31m# above.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mfollowlinks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mislink\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 410\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mwalk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopdown\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0monerror\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfollowlinks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    411\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m         \u001b[0;31m# Recurse into sub-directories\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-2019.03/envs/metrics/lib/python3.7/os.py\u001b[0m in \u001b[0;36mwalk\u001b[0;34m(top, topdown, onerror, followlinks)\u001b[0m\n\u001b[1;32m    366\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 368\u001b[0;31m                 \u001b[0mis_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mentry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    369\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m                 \u001b[0;31m# If is_dir() raises an OSError, consider that the entry is not\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "prep_function = PrepFunction(api.bpe, ['java-bpe-training_nounicode-1000'], {\"no_com\": True, \"no_str\": True})\n",
    "description = \"bpe 1k no strings no comments\"\n",
    "run(prep_function, description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_function = PrepFunction(api.bpe, ['java-bpe-training_nounicode-2000'], {\"no_com\": True, \"no_str\": True})\n",
    "description = \"bpe 2k no strings no comments\"\n",
    "run(prep_function, description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_function = PrepFunction(api.bpe, ['java-bpe-training_nounicode-5000'], {\"no_com\": True, \"no_str\": True})\n",
    "description = \"bpe 5k no strings no comments\"\n",
    "run(prep_function, description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_function = PrepFunction(api.bpe, ['java-bpe-training_nounicode-10000'], {\"no_com\": True, \"no_str\": True})\n",
    "description = \"bpe 10k no strings no comments\"\n",
    "run(prep_function, description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_function = PrepFunction(api.bpe, ['java-bpe-training_nounicode-20000'], {\"no_com\": True, \"no_str\": True})\n",
    "description = \"bpe 20k no strings no comments\"\n",
    "run(prep_function, description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_function = PrepFunction(api.bpe, ['java-bpe-training_nounicode-1000'], {\"no_com\": True})\n",
    "description = \"bpe 1k no comments\"\n",
    "run(prep_function, description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_function = PrepFunction(api.bpe, ['java-bpe-training_nounicode-2000'], {\"no_com\": True})\n",
    "description = \"bpe 2k no comments\"\n",
    "run(prep_function, description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_function = PrepFunction(api.bpe, ['java-bpe-training_nounicode-5000'], {\"no_com\": True})\n",
    "description = \"bpe 5k no comments\"\n",
    "run(prep_function, description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_function = PrepFunction(api.bpe, ['java-bpe-training_nounicode-10000'], {\"no_com\": True})\n",
    "description = \"bpe 10k no comments\"\n",
    "run(prep_function, description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_function = PrepFunction(api.bpe, ['java-bpe-training_nounicode-20000'], {\"no_com\": True})\n",
    "description = \"bpe 20k no comments\"\n",
    "run(prep_function, description)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
